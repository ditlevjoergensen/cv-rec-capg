colleague,page_number,page_text
Antonio_Arfe,1,"Antonio ArfeSenior Big Data EngineerSenior Data Engineer Antonio is an experienced SoftwareData Engineer interested in anything technically challenging. He has worked on a wide range of IT projects at Enterprise level, gathering a solid experience in productionizing infrastructure applications and data pipelines to support Data Scientists.He worked on two main areas Design, implement and maintain infrastructure applications that should run for years, be highly available and fault tolerant  Build data pipelines and productionize advanced analytics models in constant need of changes and new featuresHIGHLIGHTS  Explain any kind of Distributed software system to technical and nontechnical audiences. Help data scientists productionize their models Catch errors before implementation starts CICD mechanisms Teamwork in international environmentENGAGEMENTS05.2020   Worldwide furniture retailer, Customer Support IntelligenceProject description Productionise AIML infrastructure and model pipelines for the Customer Support Intelligence teamRole Senior Data EngineerResponsibilities  Productionise MLAI pipelines, from sourcing data to creating insights Extract  Manipulate data on the Cloud to make them available to BI dashboards.Skills Google Cloud Build, Google Cloud Functions, GCP Cloud AI, Google Cloud Composer, GoogleCloud Dataflow, Apache Airflow, Google BigQuery, CICD03.2020  04.2020 Capgemini Danmark AS, COVID 19 DashboardProject description Solution to extract new Insights and Visuualizations from the official COVID data released by the authorities.Role Senior Data EngineerCV  Antonio Arfe   2022 Capgemini. All rights reserved. 17"
Antonio_Arfe,2,"Responsibilities  PowerBI Dashboard published internally on MS Teams Application to automate the extraction of data from a graphical picture in the pdf. The application was containerized to make it available across WindowsUnix environments Stored the data in a easytouse source Created several scripts to automate most of the daily actionsSkills Power BI, Python, Docker, Azure DevOps, Bash Script, Powershell Scripting05.2019  10.2019 Leading Nordic Bank, Big data Platform Performance OptimizationProject description Find the root causes of heavy resource utilization and clusters unresponsiveness 15 tenants.Stabilize business critical flows and improve UX for online queries.Role Senior Big Data Platform EngineerResponsibilities Analysis Look at data from 10.000 daily jobs running on the cluster over time. Expensive jobs high CPUsec and memsec consumption Preemption impact Wasted resources jobs constantly failing Cluster heat map to find peakslack hoursTools and solutions Rearrange Yarn queues Automated tool to stop highly failing jobs SemiAutomated heatmap to help schedule jobs at nonpeak hoursSkills Apache Yarn, Apache Oozie, Apache Hive, Python, Bash Script, Cloudera Manager, Cloudera CDH, MS Access05.2019  10.2019 Leading Nordic Bank, Big Data Platform Proactive MonitoringProject description Implement proactive monitoring and automated preventive actions to optimize resource utilization and reduce bottlenecks.Role Senior Big Data Platform EngineerResponsibilities  Identify whats most critical to monitor while 15 live tenants on the platform Early warnings Monitor metrics trends and send out warning messages before alerts become incidents. Automated actions to be taken based on warnings. E.g. pause and report to the owner a scheduled job has been failingSkills Apache Yarn, Apache Oozie, Apache Hive, Apache HDFS, Bash Script, Python, Cloudera CDH,Cloudera Manager02.2018  04.2019 Danske Bank AS, Advanced Analytics Model FrameworkProject description Design and implement a framework to help data scientists speed up development and deployment in PROD of AIML models.Role Senior Big Data Platform EngineerCV  Antonio Arfe   2022 Capgemini. All rights reserved. 27"
Antonio_Arfe,3,"Responsibilities  Code template and code organization guidelines Automated CICD with final PROD review Model verification framework Model lifecycle definition Scheduling and monitoringRole Stakeholder ManagerResponsibilities  I worked in between stakeholders and engineering team to keep track of communication and decisions Helped stakeholders plan their work around our release schedule Kept a feature release calendar and broadcasted service communications for features  maintenance  I visited possible stakeholders to showcase and advertise our departments capabilitiesSkills Chef, Jenkins, Python, Artifactory, Apache Airflow11.2018  04.2019 Danske Bank AS, The Elephant in the enclaveProject description Redesign and reimplement Hadoop cluster network topology for 4 environments, using enclaves and firewall rules. Role Senior Big Data Platform EngineerResponsibilities  Encapsulate the Hadoop nodes, the Airflow cluster, Users edge nodes, CICD nodes into separate microsegments inside an enclave Implement firewall rules to keep it open for users but secured from intruders. Used a private cloud infrastructure of 100 RedHat servers spanning 4 environments. Each environment networks topology mirrors the production setup. NonProd used to test platform and services upgrades against users applications.Skills Apache Hadoop, Networking  Monitoring09.2017  09.2018 Danske Bank AS, Hadoop Edge Nodes provisioningProject description Create a strategy and a design to provision Hadoop Edge Nodes on demand, for analysts and data scientists.Role Senior Big Data Platform EngineerResponsibilities  Designed the provisioning strategy and implemented it with Chef Worked out an automated monitoring mechanism using Jenkins and bash scripts.  Monitor the Hadoop services are up  running from a user perspective. Different tools and versions needed to be available in different environments. Edge nodes contain all the latest tools Data Scientists need to perform Big Data AnalyticsRole Stakeholder ManagerResponsibilities  Kept track of communications with stakeholders concerning new feature releases and fixes. Kept a feature release calendar and broadcasted service communications He visited several possible stakeholders to showcase and advertise our departments capabilitiesCV  Antonio Arfe   2022 Capgemini. All rights reserved. 37"
Antonio_Arfe,4,"Skills Chef, Jenkins, Apache Spark, Apache PySpark, Anaconda12.2016  04.2017 Danske Bank AS, Real time Fraud Scoring on customer transactionsProject description Identify fraudolent transactions, in real time, from different channels card transactions, bank transfers etc.Role Software EngineerResponsibilities  System Infrastructure  storing all the scored transactions into the internal payment system.  The system can handle 500.000 transactionsday with peaks of 60100 transactions per seconds. Integration end to end from the queues to the mainframe, including security. Full CICD Load and performance testSkills RabbitMQ, JavaScript, GIT, Maven, Bash Script05.2016  01.2017 Danske Bank AS, Data lake ingestion FrameworkProject description Create a Data lake ingestion framework on Hadoop to allow data scientists and analysts to build AIML models on the latest data from PROD.Role Senior Big Data EngineerResponsibilities  The framework run around 3000 data flows per day, ingesting 1 million records and a few GB of data every day. Data are ingested from sources like RDBMS and flat files New source data are mirrored in the data lake with a delay as little as 15 minutes. Built in automated mechanism to resume in case of any failureRole Task ManagerResponsibilities  He helped the 4people team plan and organize the work. He managed the communication with the stakeholders concerning deadlines and features He kept track of the backlog and prioritized the tasks to be doneSkills Apache Hadoop, Apache Hive, Apache Oozie, Apache Sqoop, Apache HDFS, JavaScript, Stakeholder Management01.2015  06.2016 Danske Bank AS, Internal Web Services  Build  DeployProject description Build an Enterprise wide infrastructure to have developers develop, build and deploy web services across languages and platforms e.g. Java, PL1, C.Role Software EngineerResponsibilities  Design  implementation of WebService Interface in Java. Deployed on IBM WAS.  The WebService sits between the developers tools and the governance process implemented inIBM WSRR Implemented Java client to call the WSRR API to reflect the web service deployment status in the registryCV  Antonio Arfe   2022 Capgemini. All rights reserved. 47"
Antonio_Arfe,5,"Skills JavaScript, IBM WSRR, WSDL, IBM WAS, Eclipse IDE, Organizational Implementation06.2013  02.2015 Danske Bank AS, Internal Web Services registry  development processProject description Develop an Enterprise wide Infrastructure for Internal WebServices including build  deploy automation, development process and registry.Role Software EngineerResponsibilities  Development process and design  implement the registry based on IBM WSRR.  500 Developers use the registry  process Organizational Implementation roadshows. Technical and nontechnical sessions all over Denmark. Design and implement the Development and Governance process for WebServices via Java Web ServiceSkills IBM WSRR, JavaScript, Organizational Implementation, Change ManagementEDUCATION  2012 MSc in Software EngineeringAalborg University  2009 BSc in Computer Science EngineeringUniversity of Napols Federico II  UninaCOURSES04.2020 Architecting Serverless Big Data Solutions Using Google Dataflow03.2020 Google Cloud Platform Big Data and Machine Learning Fundamentals12.2019 AZ300 Azure Architecture Technologies Exam prep09.2019 Google Cloud Platform Fundamentals Core Infrastructure05.2017 Enterprise Foundations of Apache Cassandra  DS20105.2017 Apache Cassandra Data Modeling DS220CERTIFICATIONS02.2020 Azure Architect Technologies11.2017 Danske Bank Talent Programme06.2017 APM202 Code Instrumentation  Visibility Course06.2017 APM201 Diagnostics  Troubleshooting Fundamentals Course06.2017 APM200 Essentials Course06.2015 Danske Bank Graduate ProgrammeCLOUDCV  Antonio Arfe   2022 Capgemini. All rights reserved. 57"
Antonio_Arfe,6,Google CloudGoogle Cloud ComposerGoogle Cloud DataflowCloudera CDHCloudera ManagerGCP Cloud AIDATABASESGoogle BigQuerySKILLSApache AirflowPowershell ScriptingCICDData PipelinesCommunicationApache OozieBash ScriptApache HiveApache YarnPythonJavaChefStakeholder ManagementOrganizational ImplementationApache SqoopApache HDFSArtifactoryNetworking  MonitoringTask ManagementPresentation SkillsGoogle Cloud BuildIBM WASEMPLOYMENTS05.2019   Capgemini05.2017  04.2019 Danske Bank10.2015  04.2017 Danske Bank06.2013  09.2015 Danske Bank06.2011  08.2011 Aalborg University and University of Southern DenmarkLANGUAGESEnglish Good CommandItalian Mother tongueDanish FluentCV  Antonio Arfe   2022 Capgemini. All rights reserved. 67
Antonio_Arfe,7,CV  Antonio Arfe   2022 Capgemini. All rights reserved. 77
Ashish_Meshram,1,"Ashish MeshramSenior ConsultantSenior Consultant, Data Architect, Data EngineerPassionate Data Engineer with strong knowledge of the distributed systems on cloud and onprem. Expert in handling batch and streaming data using various tools. Proficient in designing and developing secured and costeffective data solutions for clients consist of Data Lake, Data Warehouse, Streaming Analytics, Master Data Management, Global Data Cache, and Data Pipelines. Adept at delivering performant solutions using Agile methodology. Certified AWS Solutions Architect Associate, with a sheer understanding of security, high availability, and big data analyticsapplications on AWS and Azure. Able to process data in Terrabytes within sustainable time and compute resources with the use of serverless technology native to AWS and Azure. Experienced in building up a cloud account from scratch using infrastructure on code IOC.Highlights AWS Certified Solutions Architect Associate Adept in handling streaming and batch big data using cloudnative services 5 years of experience in Software Development, Data Warehousing, and Data Analysis Skilled in deploying Machine Learning application to production Developed feature store for periodical features generation Skilled in programming languages like Python, Java with proficiency in Spark, Kafka, AWS, Flask, etc Experienced in working with Agile methodologies on SAFE Anonymized data using advanced Anonymization techniques Kanonymity, Ldiversity, and Tcloseness Developed reusable Terraform modules for building infrastructure on AWS and Azure Skilled in Data Migration for Oracle, Postgres, Teradata, MySQL, Redshift, Snowflake, Glue, Hadoop, etc Highly motivated, resultsoriented, and take pride in being a problem solverENGAGEMENTS08.2021  08.2022 International Travel Agency, Partner Loyalty Program Project description A Loyalty analytics program for a significant travel and hospitality platform calculates the partners performance based on metrics provided by the business. Calculations are performed on the Kubernetes cluster, and jobs are orchestrated with ARGO and Oozie.Role Senior Data EngineerResponsibilities  Designed and Developed the uplevel data quality module for a loyalty program Decreased total run time of metric calculations from 2 days to 3 hours by adapting reusable modules Developed custom modules for integration between hive tables and MySQL Increased Data quality by adding custom statistics to the datasets Delivered fasttrack migration of Oozie jobs to ArgoCV  Ashish Meshram   2022 Capgemini. All rights reserved. 16"
Ashish_Meshram,2,"Skills Apache PySpark, Argo, Oozie, SQL, Python, Kubernetes08.2021  01.2022 Danish Pharmaceutical  Firm, Enterprise Data Governance Project description Enterprise Data Governance team aims to provide ownership and access strategies to the manufacturing data for predictive maintenance of the machines and generating live dashboards that help avoid human interaction on the production site.Role Senior Data EngineerResponsibilities  Analysis of current available realtime data pipeline to move data from production sites to AWS data lake and low latency sink Reporting of current data issues and mitigation plans to avoid the problems reported to enhancethe data quality and standards Strategic implementation of the roles for data ownership to provide endtoend practical data governance framework.Skills Amazon Web services  Build , Administration and integration05.2021  06.2021 Danish Insurance  Banking Firm, Enterprise Data PlatformProject description Enterprise Data Platform aims to provide a reliable and scalable data platformon cloud platform using modern cutting edge technologies. EDP comprises Data Ingestion, Data Lake, and Data Warehouse on Azure Cloud that replicates business scenarios from Legacy Data Warehouse built on Informatica.Role Senior Data EngineerResponsibilities  Developed custom metadata driven pipelines to move data from Oracle, SQLServer  and DB2 database in Azure DataFactory Designed metadata driven pipelines to ingest data from API endpoints Debugged and Optimized DataBricks Notebooks for optimal executionSkills Azure Data Factory, Azure SQL database, Azure Databricks, Azure DevOps11.2020  02.2021 Danish Insurance  Banking Firm, Advanced AnalyticsProject description Advanced analytics platform performs machine learning operations to predictvarious metrics for the internal customer as well as external clients. Applications are deployed to the Azure cloud with the synchronization between onprem application and cloud migrated infrastructure. Feature store is created using Azure SQL, Container Registry, App Services, Data Lake, Functions, and TerraformRole Machine Learning EngineerResponsibilities  Developed major pipelines built on onprem to Azure Productionize feature store on Azure using opensource and cloud Infrastructure on code using Terraform  Designed and developed data pipelines from various sources using Azure services or customdeveloped applications CICD automation using GitLabCV  Ashish Meshram   2022 Capgemini. All rights reserved. 26"
Ashish_Meshram,3," Developed applications using Azure app service  Architectural solutions provided based on security and client policiesSkills Azure, Docker, Gitlab, Terraform, Python, Azure AppInsight, Azure API Management, Azure ACR, Azure Data Lake, Apache Airflow10.2019  10.2020 Swedish Luxury Car Manufacturer, Master Data ManagementProject description Data Management platform, aiming to create an advanced data analytics system for a client that is capable of providing a single source of data. Designed and developed serverless data pipelines using AWS and Azure services like Lambda, Functions, Batch, Azure DevOps for CICD, Data Factory. Written reusable Terraform modules. Migrated data pipeline components from AWS to Azure.Role Data ArchitectResponsibilities  Designed and developed data pipelines from various sources using AWS services or customdeveloped applications Applied the best architectural techniques to redesign previous applications  Written automation tests for CICD Infrastructure on code using Terraform and serverless Developed serverless applications using Lambda and Batch Designed workflows using AWS Glue servicesRole Data Architect  EngineerResponsibilities  Migrated major pipelines built on AWS to Azure Designed and developed data pipelines from various sources using Azure services or customdeveloped applications CICD automation using Azure DevOps and SonarQube Infrastructure on code using Terraform and serverless Developed serverless applications using Azure Functions Performed Kubernetes POC for API and transformationRole Data ArchitectResponsibilities  Designed system architecture on azure for MDM platform data ingress and egress Designed and developed pipelines in Azure DataFactory Deployed all components in azure as the infrastructure on code using terraform Made strategic decision on connecting customers cloud platform with saas MDM platform Involved in team collaboration on designing private network and subnets Developed generic modules for automation with the Data engineering teamSkills AWS Glue, AWS Lake Formation, AWS Lambda, AWS Batch, Terraform, Azure DevOps, AWS API Gateway, Azure Data Factory, Azure Data Lake01.2019  08.2019 Danish Telecom Company,  Decomission of 2G  3G Project description Derive KPIs from high velocity and volume network data to decommission the2g and 3g services in Denmark, anonymizing big data with compliance to GDPR for network enhancement. Designed and developed a faulttolerant architecture for ingesting data in TBs CV  Ashish Meshram   2022 Capgemini. All rights reserved. 36"
Ashish_Meshram,4,"every hour. Optimized spark jobs to run efficiently.Role Data EngineerResponsibilities  Designed Architecture to ingest and transform big data using microbatches and batches on AWS using cloudnative services. Maintained Data Integrity with robust checkpointing at S3 Designed a lowcost data storage solution using various storage classes in S3 Anonymized customer data using advance anonymization algorithms Optimized Spark jobs to run more efficiently in serverless pattern Skills AWS EMR, AWS S3, DataIku, Bash Script, Apache PySpark, AWS Cloudwatch, EMRFS09.2017  01.2019 Danish Telecom Company, Streaming Analytics Project description Realtime analytics on data from purchase and order management tools across the Nordic region, Particularly helpful in getting a deep understanding of live data to make realtime decisions for sales, orders. Combined Kafka, Spark, Elastic stack to get realtime data andvisualization.Role Software EngineerResponsibilities  Develop streaming pipelines from Kafka to Spark and load data into elasticsearch for further visualization and text search Created API using python flask and AWS API gateway for providing data to clients outside the organization network Managed Kafka cluster including initial setup and testing with advance monitoring of cluster health and network.Skills Kafka, Apache Spark, Docker, AWS, AWS API Gateway, AWS EC2, Python, Flask, AWS DynamoDBEDUCATION2010  2015 BSc in Electrical EngineeringKDK College of EngineeringCERTIFICATIONS02.2020 AWS Certified Solutions Architect  AssociateSKILLSJavaPostgreSQLAWS DynamoDBDataIkuApache PySparkAzure ACRAzure Data LakeCV  Ashish Meshram   2022 Capgemini. All rights reserved. 46"
Ashish_Meshram,5,"DATABASESAzure SQL databaseANALYTICSSqoopKafkaApache PySparkSOFTWARE DEVELOPMENTHibernateBash ScriptCSSJavaScript UIDockerAWSCLOUDAWS BatchAWS EMRAWS GlueAWS Lake FormationEMRFSFlaskHTML5Apache SparkAWS S3Azure DevOpsAWS RDSAWS RedshiftAWS LambdaTerraformAWS KinesisAWS API GatewayAWS EC2Azure DevOps CICD Pipeline SetupAzure Event HubAzure AppInsightAzure DatabricksAzure Data FactoryAzurePandasAWS CloudwatchAzure API ManagementAmazon Web services  Build , Administration and integrationCV  Ashish Meshram   2022 Capgemini. All rights reserved. 56"
Ashish_Meshram,6,SQLPythonOozieEMPLOYMENTS07.2015  05.2016 Freelance05.2016  08.2019 Tech Mahindra09.2019  06.2020 Capgemini DenmarkLANGUAGESEnglish Good CommandCV  Ashish Meshram   2022 Capgemini. All rights reserved. 66
Ayman_Eleya_Zaki,1,"Ayman Eleya ZakiSenior ConsultantIntegration Specialist, FullStack Developer, Data EngineerAyman is an experienced senior consultant and has been working across many industries Insurance, Wholesale Fashion Trade, public systems and architectural engineering. Ayman has more than five years experience with professional software development.  Ayman has been working as a FullStack Developer for almost 3.5 years with main focus on .NET technologies. In addition, Ayman had worked exclusively as system integration specialist for more than 2 years using Dell Boomi technology. His main role varied from understanding the customer needs to designing the suitable architecture, and finally delivering a wellfunctioning integration. Ayman gained fair knowledge as data engineer. For a period of almost 6 months, Ayman helped with maintaining DWH solutions and built some analytical tools using Power BI.Ayman has great communication and analysis skills, also he is details oriented. Ayman can take responsibilities and lead junior developers. Ayman is familiar with Scrum and CICD. Ayman has masters degree in Machine Learning and Data Science.ENGAGEMENTS10.2021   Volvo Trucks, PL Data StrategyProject description Ayman is working as a tech lead and data architect. Ayman is helping his client to build their data strategy platform using the Azure stack. Aymans main tasks are architecting and optimizing the platform based on best practices. Moreover, Ayman is acting as a technical advisor for other projects.Role Tech Lead  Data ArchitectResponsibilities Data Engineer, Data Architect, Tech leadSkills Technical Lead, Data Architecture, Performance Assessment  Optimization, Technical Documentation, Python, Apache PySpark, SQL, Azure Data Factory02.2020  06.2020 Internal Project, Data Migration and AnalyticsProject description Migrating all data from Jira to another internal project management system.Building analytical tool using Power BI to help the managers to get insight about the status of the different projects and the allocated resources to these projects.Role Data EngineerResponsibilities Ayman applied ETL pattern to migrate data from JIRA to another internal project CV  Ayman Eleya Zaki   2022 Capgemini. All rights reserved. 15"
Ayman_Eleya_Zaki,2,"management system. As Jira was very advanced compared to the other system, various data transformation techniques were applied in order to migrate the data into the other system. The project was implemented using C.Role Data ScientistResponsibilities Ayman built analytical tool using Power BI to help the managers with Visualizing the status of the cases, time consumption and remained work of the cases Visualizing time consumed by each developer based on the project and the client Visualizing the time spent on the cases against the planedestimated time. Predicting when the project is expected to be delivered and comparing the prediction with the actual deadline so the managers can react on that in good time.In this project Ayman worked on both structured MS SQL and unstructured data CSV files to build the required visualizations.Skills C, Power BI, Data Analysis, REST API, MS SQL, ETL01.2019  05.2019 HK, HKData WarehouseRole Data EngineerResponsibilities Aymans role was to maintain and expand the existing DWH solution. Ayman communicated with the stakeholders to gather the necessary information about the tasks to be implemented. Ayman prepared the technical documentations such as analysis, solution description and estimate. Ayman worked on mainly with implementing more SSIS packages for data extraction. In this project, Ayman fair knowledge about ETL, DWH, and Power BI.Role Data EngineerSkills SQL Server Integration Services  SSIS, Power BI, SQL Server Analysis Services  SSAS, DWH, CICD, MS SQL, ETL07.2017  12.2018 FashionTrade.com, FashionTrade IntegrationsProject description FashionTrade is an online B2B fashion wholesale marketplace where brands and retailers can connect and do their wholesale business online. The main goal of this project was to build system integrations between FashionTrade REST API and other fashion brands so theycan offer their goods on FashionTrade marketplace so that the retailers can order and but what they need.Role ETL DeveloperResponsibilities Ayman communicated with the stakeholders and several brands to gather the necessary technical information of the systems to be integrated with FashionTrade. Aymans responsibilities were to analyze the systemsendpoints and the data to be transmitted, build PoCs,prepare the documentations, design the integration architecture with focus on the ETL pattern, reusability and scalability. And finally, implementing, testing, and deploying the integrations to production. Additionally, he provided the client with the necessary documentations for operating and maintaining the systems on Dell Boomi platform.Role Lead DeveloperResponsibilities Ayman was the technical lead and he led and assisted 2 developers. Aymans roleCV  Ayman Eleya Zaki   2022 Capgemini. All rights reserved. 25"
Ayman_Eleya_Zaki,3,"was to assign the tasks to other developer, moreover, assuring that their work is tested and functioning as described in the task description.Skills Dell Boomi Integration Platform, Integration Architecture, Technical Documentation, CICD, Test Automation05.2019  01.2020 Falck AS, Falck IntegrationsProject description Falck has committed several agreements with other insurance partners TRYG, UNDO, ALKA and others in such a way that Falck will receive the claims from the clients of all partners, and then send them further to the relevant partner to process the claim. Finally, the partners will update Falck with the necessary information and status related to each claim after processing it. Hence, Falck and the partners wished to build bidirectional integrations so the information can be exchanged between the systems smoothly.Role ETL DeveloperResponsibilities Ayman communicated with the stakeholders and their insurance partners to gather the necessary information of the systems to be integrated. Aymans responsibilities were toanalyze the systemsendpoints and the data to be transmitted, build PoCs, prepare the documentations, design the integration architecture with focus on the ETL pattern, reusability and scalability. And finally, implementing, testing, and deploying the integrations to production.Additionally, Ayman helped Falck with expanding other integrations highly complex architecture with functionalities to validate the data properly to minimize the protentional of the system to rundown due to some unhandled errors in the data.Skills Dell Boomi Integration Platform, Agile, Integration Architecture, Technical Documentation07.2020  08.2021 Confidential Public Sector client, SharePoint, .NET Applications, and RPAProject description The client has more then 50 applications that are mainly implemented using SharePoint and .NET technologies. These applications needed to be maintained, expanded, and modernized to be able to meet the clients needs.Role Senior ConsultantResponsibilities Ayman worked on several projects, mainly using SharePoint and .NET. Ayman hada direct contact with the clients. Aymans role was to maintain together with a team the existing applications according to the clients needs. The size of the tasks varied from small tasks 8 hrs to relatively large tasks 400 hrs.  Additionally, Ayman was part of a team consisting of 34 developer to build a new application. Together with the team, Ayman actively participated in all phases of System Development Life Cycle. The task size was  1800 hrs.Role RPA DeveloperResponsibilities Aymans role was to maintain existing RPA solutions that automate some critical manual flows. Additionally, Ayman built several robots to provide more automation to other part of the organization.   Skills .NET, SharePoint, CICD, Octopus Deploy, Technical Documentation, Entity Framework, MS SQL, Database Design, REST API, Dependency injection, Temporal Tables, LINQ, Web Applications, Bootstrap 4, CSS3, JavaScript, jQuery, MVC Framework, System Architecture, SOLID objectCV  Ayman Eleya Zaki   2022 Capgemini. All rights reserved. 35"
Ayman_Eleya_Zaki,4,"oriented design, Team Foundation Server, UiPath, UiPath Orchestrator, HTML5, C .NET, Code Review, Ajax01.2016  03.2017 Sweco, RenoWebProject description RenoWeb is a system that collects and handles all relevant processes for waste collection  ex. registration of waste emptying, management of equipment, agreements with the individual household and settlement of the services provided.In RenoWeb you can handle citizen inquiries quickly and efficiently in connection with the collection of all sorts of waste found in the municipality.Role  Full Stack DeveloperResponsibilities Ayman worked as inhouse developer together with a team consists of 15 members on developing and maintaining a webbased system called RenoWeb  for handling the daily work of garbagewaste. Aymans daily tasks were to expand the system with the necessary functionalities needed for improving the system and to maintain the system to assure better performance.Skills C .NET, SQL, HTML5, CSS, JavaScript, jQuery, REST API, Entity Framework, WCF  Windows Communication Foundation, Ajax11.2014  12.2015 Sweco, BIOFOSProject description BIOFOS is Denmarks largest wastewater company. BIOFOS utilized a laboratory system for handling data from their sampling locations and analysis process in the context of monitoring and operating.Role Student AssistantResponsibilities Ayman developed new reporting functionalities to a laboratory system for generating PDF or CSV reports.Ayman replaced UI Telerik component with new DataTable and jQuery components which is more userfriendly.Ayman expanded the system with new functionalities, additionally, Ayman optimized the databaseand backend functions using MS SQL, C and .Net.Ayman redesigned the existing UI and implemented a newer UI which is more modern looking anduserfriendly.Skills DataTables, jQuery UI, JavaScript, jQuery, HTML5, CSSEDUCATION1998  2003 BSc in Architectural EngineeringHelwan University2012  2015 Business Bachelor of Software DevelopmentTechnical University of Denmark DTU2018  2021 MSc in Machine Learning and Data ScienceTechnical University of Denmark DTUCV  Ayman Eleya Zaki   2022 Capgemini. All rights reserved. 45"
Ayman_Eleya_Zaki,5,COURSES10.2021  Creating Mapping Data Flows on Azure Data Factory09.2021 Microsoft Azure Data Engineering DP20308.2021 Spark and Python for Big Data with PySpark06.2021 Machine Learning AZ HandsOn Python In Data Science09.2021 Microsoft Azure Fundamentals AZ900CERTIFICATIONS09.2021 Azure Fundamentals09.2021 Azure Data Engineer AssociateDell Boomi Associate Developer CertificationDell Boomi Professional Developer CertificationDell Boomi Professional ArchitectDell Boomi Professional API Design and Management CertificationFRAMEWORKSMVC FrameworkDATABASESDatabase DesignMACHINE LEARNING  DATASklearnPyTorchMatplotlibMachine LearningETLPower BIData ExplorationData CleaningData ConversionData WarehousingAnacondaLANGUAGESArabic Mother tongueEnglish FluentDanish FluentCV  Ayman Eleya Zaki   2022 Capgemini. All rights reserved. 55
Aziz_Ari,1,"Aziz AriConsultantPassionate MLData Engineer with a sheer understanding of advanced analytics and big data analytics applications on Azure. Trained in interdisciplinary collaboration and participatory design processes with the ability to translate processes between business and developers. Experienced in building sustainable data driven solutions from scratch using infrastructure on code IOC.ENGAGEMENTS05.2020  02.2021 A. P. Mller Mrsk, Container Investment ModelProject description Improvement of the existing ROFO model by developing of time series models for forecasting demand of containers across different regions where Maersk is doing business. Role Data ScientistResponsibilities I designed the pipeline and developed an autoregressive model that was able substantially reduce forecasting error. This resulted in yearly savings of about 10 million USD for the company.Skills Agile Development, Time Series Modelling, Data Prep, Statsmodels07.2020  08.2021 A. P. Mller Mrsk, Standard Cost YieldProject description The aim of this project was to improve the accuracy of monthly unit costs forecasts for shipment handling at several origindestination pairs. The solution had to be scalable and sustainable as thousands of OD pairs was involved.Role Data ScientistResponsibilities This role required extensive feature engineering and aggregation steps prior to model generation. Several thousand models was to be trained and deployed in a single solution, which was possible to handle with big data technologies. Skills Machine Learning, PySpark SQL, PySpark ML, Pandas, Numpy, Azure Databricks, Azure Data Factory, Scikitlearn, MLFlow, Data Cleaning, Data Exploration08.2019  04.2020 A. P. Mller Mrsk, Ship ManagerCV  Aziz Ari   2022 Capgemini. All rights reserved. 14"
Aziz_Ari,2,"Project description The aim of this project was to automate manual reporting processes that were taking place out in Maersks fleet. There are several monthly machinery reports filled by the vessel crew and then reported back to Maersks HQ, which then is stored in onpremises systems and finally manually reviewed.Role DeveloperResponsibilities Azizs role was to ingest the data to cloud systems and then automate the final reviewing process to decrease the manual efforts required. The manual reviewing process was then fully automated and reported to the ship managers that manages maintenance of vessel machinery.Skills Python, ETL, Pandas, Numpy, DataOps, PySpark SQL07.2019  04.2020 A. P. Mller Mrsk, PaaS OnboardingProject description This project aimed to onboard business and tech users to an allinone analytics cloud platform that was developed by a third party company. Role Data Enablement AnalystResponsibilities Azizs role in this project was to make sure that users were able to access various data sources and leverage the capabilities of the platform to a full extend. The platform offered several point and click capabilities as well as advanced DevOps features for tech users.Skills CoDesign, Interviewing, Enablement, Interdiciplinary Communication, Data Analysis, Data Visualization, Data Exploration, PostgreSQL, PySpark SQL, DataOps, Python, Numpy, Pandas, Scikitlearn, PySpark ML, ETL04.2018  07.2019 Rockwool Group, Master Data CleanupProject description This project was about identifying how well the vendors were maintaining their material master data. The project did contribute to better monitoring and classifying of vendors that maintained their data and vendors that did a poor job of doing so.Role Data AnalystResponsibilities Aziz had the responsibility of collecting data from SAP systems, processing it through Python and Excel VBA, and finally preparing a Power BI dashboard for the decision makers.Skills SAP, Power BI, Power Pivot, Power Query, VBA Excel, MS Excel, Python, Pandas, Numpy03.2018  06.2019 Kbenhanvs Kommune, Koncern IT, ERP DataProject description This project was focused around updating and maintaining data that was usedfor ERP systems in Koncern ITRole Data AnalystResponsibilities Azizs role in this project was to query views and validate and extract data based on requests from the business.CV  Aziz Ari   2022 Capgemini. All rights reserved. 24"
Aziz_Ari,3,"Skills TSQL, MS Excel, VBA Excel, Python, PandasEDUCATION2017  2019 MSc in EngineeringAalborg University2014  2017 BSc in Civil EngineeringAalborg UniversityCLOUDAzure Data FactorySKILLSPythonMS ExcelApache PySparkMachine LearningDatabricksPower BIAzure DevOpsPySpark SQLPySpark MLPandasScikitlearnETLTSQLNumpyVBA ExcelVBPower PivotData ExplorationPostgreSQLKanbanMLFlowAzure DatabricksJIRACoDesignData AnalysisData PrepData VisualizationDataOpsEMPLOYMENTS05.2020  07.2021 A.P. Mller MrskCV  Aziz Ari   2022 Capgemini. All rights reserved. 34"
Aziz_Ari,4,07.2019  05.2020 A.P. Mller Mrsk04.2018  07.2019 Rockwool Group03.2018  07.2019 Koncern ITLANGUAGESDanish Mother tongueTurkish Mother tongueEnglish Mother tongueCV  Aziz Ari   2022 Capgemini. All rights reserved. 44
Branislav_Machava,1,"Branislav MachavaAzure Data Engineer Data lake, Databricks, Pyspark, Azure DevOps, Snowflake, Terraform, ADF, Azure Function, EventHub Data Engineer with 5 years of experience building and maintaining complex data solutions. Experienced in designing, developing and operating Data Warehouse, Data platform and Data products. Good understanding of best practices in software development and data modeling together with strong proficiency in multiple programing languages, DevOps tools and infrastructure empowers Branislav to deliver endtoend data solutions.ENGAGEMENTS11.2021   Henkel, Henkel Data Foundation PlatformProject description Platform designed to provide single access point to data assets from various departments coupled together with azure resources provisioner to ease data science and data engineering set up. Designed as selfservice using multiple technologies Javascript frontend, C backend, Data Lake, ComosDB, Terraform for resource provisioning. Involved in developing new features, enhancements of existing one and various bug fixes. Also has been responsible for communication with offshore DE team and assisting operations team when needed. Role Solution ArchitectResponsibilities Part of the team of Architects, involved in defining Platform Architecture, Access management and scope of the project. Supporting project migration ADLS gen1 to gen2 and alsosupporting maintenance team. Role Senior Big Data Platform EngineerResponsibilities Implementation of concepts previously defined while working as an Architect, various bug fixes and improvements to the platform. Working in multiple programing languages C, Python, Javascript build on top of Azure stack.  Skills Data Architecture, Terraform, Infrastructure Architecture, Azure Databricks, Azure, Python, C .NET Core, Azure Data Lake, Cosmos DB, Apache PySpark10.2018  10.2020 FLSmidth AS, Snowflake DWProject description Data Warehouse build on top of Snowflake and Delta Lake utilizing External tables, build from ground up, with emphasis on maintainability. Different data pipelines utilizing various technologies snowpipe, dbt, ADF, Spark and various data product powerbi dashboards, flask application. CV  Branislav Machava   2022 Capgemini. All rights reserved. 13"
Branislav_Machava,2,"Role Data EngineerResponsibilities Modeling and transforming data using SQL, dbt and ADF. Maintaining Access, Data quality and building application on top of snowflake streamlit, powerBi. Role Data ArchitectResponsibilities Define and develop Data models based on the specification from various business unit. Defining access concept, ingestion concept and integration with Alation data catalogue. Skills Snowflake, Python, Azure DevOps, Terraform, SQL, Data Vault 2.0 Methodology, Apache PySpark, Databricks06.2021  10.2021 FLSmidth AS, QCX Events Project description Design and development of data extraction pipeline for unreliable data source. Utilizing multiple technologies from Azure function and ADF for extraction, dbt for modeltransformation to snowflake as a storage and presentation layer. Delivered complete solution according to the client specification with automated infrastructure provisioning and full CICD pipeline. Role Data EngineerResponsibilities Defining Architecture, provisioning of it through Terraform, building Azure function and ADF pipeline together with dbt presentation layer. CICD for the whole project. Skills Azure, Azure AD, Terraform, Azure CICD, Azure Function, Snowflake, dbt, dbt vault, Python07.2020  10.2021 FLSmidth AS, Asset KPIs Project description Migration of existing pyspark pipelines to dbt and SQL.Role Data EngineerResponsibilities Developed SQL pipelines operated on top of dbt to transform and calculate KPIs defined by business analyst. Project has been a migration of existing project pyspark to sql. Skills PySpark SQL, SQL, Python, Pandas, Koalas, Azure CICD09.2019  06.2020 FLSmidth AS, Measurements ingestionProject description Developed a central pipeline to collect measurements from various IoT sensors on equipment around the globe. Base data set for multiple project. Role Data EngineerResponsibilities Developed and maintained pyspark based pipeline to ingest measurements near real time from various iot sensors. Build utilizing EventHub, Databricks as a runner of custom made pyspark package, ADF for orchestration and Data Lake as a single source of truth. CV  Branislav Machava   2022 Capgemini. All rights reserved. 23"
Branislav_Machava,3,"Integration with snowflake as a snowflake external table and CICD to automate deployment. Skills Azure, Azure Data Factory, Databricks, Python, Tox, Apache PySparkEDUCATION2018  2020 Technical University of Denmark DTUVIA University CollegeCERTIFICATIONS05.2022 Azure Data Engineer Associate02.2019 Agile Project Management AgilePMSTRONG SKILLS AzureSQLSnowflakeApache PySparkC .NET CoreAzure DevOpsTerraformAzure Data FactoryAzure DatabricksAzure CICDAzure Data LakeEMPLOYMENTS11.2021   Henkel08.2020  10.2021 FLSmidth AS09.2019  07.2020 FLSmidth AS07.2017  08.2019 Spainholiday.com02.2017  06.2017 Spainholiday.comLANGUAGESSlovak Mother tongueEnglish Good CommandCV  Branislav Machava   2022 Capgemini. All rights reserved. 33"
Daniel_Masson,1,"Daniel MassonManaging ConsultantDaniel has over 20 years of experience in Data warehousingbusiness intelligence.Daniel is distinguished by Good business understanding. Good modelling and solution skills. Extroverted and can handle all types of stakeholders. Selfpropelled and selfmotived. Want to take advantage of the opportunities that lies either in data or new technology. Many years of operational responsibility.His ETL skills, data analytics and technology combined with a commercial education have allowed him to work closely withclients on the design, prototyping, development, implementation and operation of data management, data warehouse and analytics solutions.Due to good business understanding, he is used to being a close sparring partner to the business and to gathering business requirements, designing data models, performing tests and implementation.Core competencies ETL DW Architect SQL Have knowledge of both the private and public sectors Miscellaneous Informatica Power Center versions latest 10.4, SQL server 2017ENGAGEMENTS11.2020  12.2021 UFST The IT and Development Agency of the Danish Ministry of Taxation, ICI Data warehouseProject description Primary objective Transition to a new internal team where the primary purpose was to improve the existing DW environment in terms of data load. The multiple sources systems were creating problems because of load interdependencies and general slow loads. General sparring with the existing Solution Architect.  Role Senior Solution ArchitectResponsibilities  CreatedIntroduced the new Delta load method. Load performance bettered by66. Developeddesigned Control environment that for automatic testingRole TeacherResponsibilities  Teaching new employees SQL Teaching new employees Informatica PowercenterRole DeveloperCV  Daniel Masson   2022 Capgemini. All rights reserved. 15"
Daniel_Masson,2,"Responsibilities  Developed new DIMFCTMarts in Informatica Powercenter Informatica migration from 10.2 to 10.4 Deployment of new code between environments. Operation of the solution.Skills Informatica PowerCenter, JIRA, Confluence, MS SQL Server 2017, SQL, Agile Development, Scrum06.2017  10.2020 UFST The IT and Development Agency of the Danish Ministry of Taxation, ICI Production management Data WarehouseProject description Primary objective Design, develop and operate the new data warehouse to initiate efforts in relation to the prioritization of which liabilities that shouldcould be recovered from whom. Taking into account number of tax employees at work and the number of unfinished work. As the primary source system PSRM was still under construction, the Data warehouse solution had to undergo certain iterations, that took the new reality into account. Role Senior Solution ArchitectResponsibilities  Designed the solution in cooperation with business experts. Developeddesigned Lots of DSAARKHUBDIMFCTMarts. Designed a new Delta load method that take took into account that we didnt have timestamps in all table to to use in the delta load process. Initiator to using CDC Attunity to find and handle deletes. Role Informatica  DeveloperResponsibilities  Deployment of new code between environments. Informatica Expert. Helping external consultants and newly hired internal colleagues. ETL framework in Confluence with dos and donts.   Operation of the solution.Role TeacherResponsibilities  Teaching new employees SQL Teaching new employees Informatica PowercenterSkills Informatica PowerCenter, JIRA, Confluence, SQL, Teaching, Agile Development, Scrum01.2017  04.2017 DSB, RIM Travel and Revenue modelProject description Primary objective  Evaluation of the then solution, which was slow to run andwhere the risk of errors was high, why there was a need to develop a simpler, more agile and robust solution with audit trails owned by the business. Based on the parameters entered by the business, Informatica generates a series of SQL statements that are looped through, thereby calculating data and filling into a series of fact tables.Role Senior Solution ArchitectResponsibilities  Analyzing the weaknesses in the old solution Needs analysis and claims specification in interaction with the business. Design, development and documentation. CV  Daniel Masson   2022 Capgemini. All rights reserved. 25"
Daniel_Masson,3,"Skills Informatica PowerCenter, SQL Server 2012, Jenkins, SQL04.2014  12.2016 JPPolitikens Hus, Change DW granularityProject description Primary objective The primary link table with newspaper subscriptions had to change granularity from containing the purchased product to the delivered products. Role Senior Solution ArchitectResponsibilities  Modeled the solution In addition, type 2 history was added to a number of selected satellites Performance optimized, so that load times decreased by 35.  Changed granularity in different link tables and addition of new satellites. Redesigned marts.Role DeveloperResponsibilities  Part of the Developer team with daily stands and everythingSkills Informatica PowerCenter, Data Vault 2.0 Methodology, SQL Server 2012, JIRA, Agile Development, Scrum02.2016  12.2016 JPPolitikens Hus, Sales Force Marketing CloudProject description Primary objective  To collect information about the customer from various subscription solutions digital and paper and weblogs with the aim of creating a unified customer profile. Salesforce being a new solution needed a flexible solution because of often changes in data requests. Waiting for the usual deployment schedules was not an option. A dynamic solution was built in Informatica that autocreated sql statements based input from a control table and executed these at the end of the Informatica job.Role Senior Solution ArchitectResponsibilities  Solution architect on the data warehouses delivery to Sales Force. Delta load of the daily changes from here to Sales Force Marketing Cloud.  In addition, ITs man in the project team for Sales Force Marketing Cloud.Skills SQL Server 2012, Informatica PowerCenter, Powershell Scripting06.2015  01.2016 JPPolitikens Hus, Digital data in DWProject description Primary objective So far the DW had only included data from the old legacy system BORDAS containing papersubscriptions. As there were more and more alternative ways of selling news, the objective was to establish other digital subscriptions data and information on readers as a new part of the DW.Role Senior Solution ArchitectResponsibilities  Designing the digital solution in cooperation with different newspaper departments Politiken, Ekstrabladet and Jyllandsposten. Deciding which sources and informationto include. Role DeveloperCV  Daniel Masson   2022 Capgemini. All rights reserved. 35"
Daniel_Masson,4,"Responsibilities  The addition of digital sources in the data warehouse up to and including the ARK layer. Skills Informatica PowerCenter, SQL Server 2012, PowerShell05.2013  03.2014 DSB, STCKProject description Primary objective Due to the interaction between DSB and Banedanmark, the effective roadmap is not always known. The project therefore went, across three sources, to identify which timetabled trip had actually been used and the arrival and departure of the trains.Role DeveloperResponsibilities  Informatica Developer. DSAARKFCTDIM mappings in dialogue with businessSkills Informatica PowerCenter, MS SQL Server 2008, Business Objects, Jenkins02.2013  04.2013 DTU, EU PEPPER project Police Enforcement Policy and Programmes on European RoadsProject description EU project prepared for DTU as Part of the PEPPER project Police Enforcement Policy and Programmes on European Roads containing the Danish bid for a future data warehouse design.Role Solution ArchitectResponsibilities Part of a two man team that wrote the report on how to design a DW solution that models traffic. Part of the delivery was a DB containing all tables.  Skills SQL Server 201201.2002  12.2012 Movia, PasFrem DWProject description Primary objective Design, develop and operate Movias data warehouse.Over a period of 10 years designed, developed and operated Movias DW in cooperation with the different stakeholders, with at the end  50 Business reports delivered to 7 different departments.The last year at Movia went on to hand over the data warehouse to Movias own IT department and train them in the use of Informatica and the existing frameworkRole Senior Solution ArchitectResponsibilities  Designed and developed the DW in Informatica and reports in Business Objects Number of passengers listed official passenger numbers. Based on the sample samples of the count buses, data are listed for monthly passenger numbers, taking into account both seasonal variations and the surrounding measurements. Driving time measurements from the Abuses used to assess the quality of the laid timetables. Budget data in relation to payment of the different operators running the buses. Used in draft budgets in relation to the municipalities. Travel card data, both passenger and driving time measurements. Reports crosschecking  the official Travel Card numbers.CV  Daniel Masson   2022 Capgemini. All rights reserved. 45"
Daniel_Masson,5," Automatic generation and envoy of reports with yesterdays sale of cash tickets in the Travel Card system to the various garages, so that the cash balance could be calculated over the individual drivers.Role DeveloperResponsibilities Operated the different solutions developedSkills Informatica PowerCenter, SQL Server, Business Objects, Teaching09.2014  04.2015 DSB, Travel Card CheckoutProject description Primary objective To find from which stops travel card customers have travelled from and to with each operator bus, train or metro where specifically to is missing. The solution ended up providing a 95 success rate which is considered being good considering that the travel card employees said it couldnt be done and dropped the projectRole Solution ArchitectResponsibilities  Designed and developed the solution and implemented it in the existing the mappings.Skills Informatica PowerCenter, SQL Server 2008FRAMEWORKSCV  Daniel Masson   2022 Capgemini. All rights reserved. 55"
Daria_Korzel,1,Daria KorzelCV  Daria Korzel   2022 Capgemini. All rights reserved. 11
Devichand_Das,1,"Devichand DasConsultantETL Developer, Data Engineer, Data Visualization, Data Migration, ML DeveloperDevichand is an experienced IT consultant who has 10 years of diversified IT experience, which includes experience in Business Intelligence, Data Analytics, Data Mining, Data warehousing, Data Visualizationsreporting and Machine learning algorithms with Python language.ENGAGEMENTS03.2019  01.2022 Medtronic, MDT DATALAKEProject description Medtronic is a global producer of medical devices and therapies, such as insulin pumps, pacemakers, and diabetes therapies. Objective of the project is to collect and maintain all the Diabetes pump related and commercial data from differentdifferent source systems to a single warehouseDATALAKE. Further use this data for building Models, insights, and visualizationsRole Senior Data EngineerResponsibilities Developed and maintaining ETL Pipes to bring data from different source systems, parsing the data and loading into target System.Moved our whole existing landscape from Onprem to AWS Cloud and Snowflake.Created multiple adhoc reports and insights using Python as per client requirement.Developed dashboards using power BI for Patients using Different kind of devices, No of SnapshotsUploads per month, Active User etc.Working on the Developement of Predictive Model using XGBoost algorithm on AWS Sagemaker.Actively involved in the data cleaning and data preparation.Daily Involved in the Scrum Calls directly with Clients for work progress updates.Strong analytical, documentation, problemsolving, communication, learning and team skills.Skills Informatica Intelligent Cloud Service IICS, DB2 Database, SQLServer2008 Analy Services, AWS S3, Snowflake, Jupyter Notebooks, Python, ServiceNow, Power BI, AWS Redshift, AWS Lambda, AWS Sagemaker, Oracle Database09.2016  03.2019 PepsiCo, NABCRM MigrationProject description PepsiCo maintains different applications for their different line of business in MSCRM cloud application for handling their lead generation and account management process. They have FSD application for their distributors and iPRO for the retail and Food Service business.  ARMS system has been replaced with FSD and Siebel system with iPRO. Now they are going to do business using single application called NAB CRM. Cognizant is expected to provide solution for CV  Devichand Das   2022 Capgemini. All rights reserved. 14"
Devichand_Das,2,"the data migration from these two applications to NAB CRM with data model matching exactly to FSD.Role Data Migration SpecialistResponsibilities Understanding requirements, mapping documents, doing Migration of Mappingsin Informatica from Siebel to Teradata as Source.E2E Development and Testing of deliverables.Performed unit and integration of testing of developed Mappings for requirementData validation as per requirement after completion of jobs.Involved in performance tuning by optimizing the sources, targets, mappings and sessions.Skills Informatica PowerCenter, Integration Services SSIS, Teradata, UNIX, Autosys Job Scheduling03.2015  08.2016 Australia Gas Light, Power Direct Multi branding Project description The PowerDirect business has been a whollyowned subsidiary of AGL since 2007. Under AGLs ownership, PowerDirect has been operated as a relatively separate entity, utilizing systems infrastructure, frontline personnel and offices distinct from AGLs own. AGL has arequirement to continue to operate the PowerDirect brand, and maintain the flexibility of using this brand to market products and offers which are separate from those of AGL.The Complex Migration of PowerDirect customer data to the AGL SAP solutionRole Informatica  DeveloperResponsibilities Requirement Gathering, Data Map Analysis, Business Impact Analysis, High level design, Development, Unit Testing, System testing, Implementation, migration.Testing the transformation logic and creation of UTC for every ETL mappings and Technical document as well. Involved in performance tuning by optimizing the sources, targets, mappings, and sessions.Skills Informatica PowerCenter, MySQL, UNIX02.2012  03.2015 Pfizer, VEEVA ELTProject description The VEEVA system was designed for scheduled and automated interfaces withminimal manual intervention. However, most of the interfaces required manual monitoring and data manipulation for handling errors while it passed through data model. Data backlogs andor discrepancies were created because of performance issues in key interfaces.Role ETL DeveloperResponsibilities Analyzing the existing code, monitoring the run timecomplexity of    jobs, working on workflows and mappings to optimize the code at sessionmappingsourcetarget level.Performance Tuning of workflows and sessions in Informatica and of Views in Oracle.Development of new Mappings and workflows to optimize and reengineer the VEEVA systemSkills Infomatica Powercenter, Oracle 10G, Veeva, UNIXCV  Devichand Das   2022 Capgemini. All rights reserved. 24"
Devichand_Das,3,EDUCATION2007  2011 Bachelor in EngineeringNagpur UniversityCOURSES2022 Azure for the Data EngineerCERTIFICATIONS05.2022 Azure Solutions Architect Expert03.2022 Azure Data Engineer Associate04.2022 Azure Administrator AssociateCLOUDInformatica Intelligent Cloud Service IICSAzure Data FactoryDATABASESDB2 DatabaseOracle Database AdministrationOracle DatabaseSKILLSIntegration Services SSISAWS S3PythonNumpySklearnPyhton Natural Language Processing library Nltk modulePower BIVeevaUNIXMySQLTeradataAutosys Job SchedulingSQLServer2008 Analy ServicesSnowflakeJupyter NotebooksServiceNowPandasAzure DatabricksCV  Devichand Das   2022 Capgemini. All rights reserved. 34
Devichand_Das,4,EMPLOYMENTS03.2019  01.2022 Infosys Ltd08.2016  03.2019 Cognizant Technology Solutions03.2015  08.2016 Accenture02.2012  03.2015 Infosys LtdLANGUAGESEnglish FluentHindi Mother tongueFrench Basic knowledgeCV  Devichand Das   2022 Capgemini. All rights reserved. 44
Dinesh_Kumar_Padala,1,Dinesh Kumar PadalaCV  Dinesh Kumar Padala   2022 Capgemini. All rights reserved. 11
Ditlev_J_rgensen,1,"Ditlev JrgensenSenior Data ScientistSQL, ETL, Data Cleaning, Data MigrationAs a Data Engineer Ditlev has worked on ETL pipelines used on a Data  AI platform specialized in Fraud Detection. Ditlev has done extensive data exploration, data mining, feature extraction, ETL and data cleaning.Ditlev has also helped develop a data monitoring tool to follow how data drifts and changes over time. Through this, he designed and developed a website where web architecture and SPLUNKSQLquery optimization were key skills. He has also done big platform logging for generating the data used for data monitoring. A big part was creating great visualizations and Dashboards where Plotly Dash was the primary visualization tool used. Ditlev has through his work as a software developer, worked with the agile processes such as SCRUM, DevOps, CICD and codedata versioning control. Ditlev has worked on a Data and AI platform built to monitor and control the payments of the public Danish welfare state. He has through his work gained extensive knowledge of working with public data from hundreds of sources and combining everything into an effective data pipeline delivering valuable insights to customers and stakeholders with many different technical backgrounds.ENGAGEMENTS01.2022  09.2022 ATPs Data and Analytics department, Data and AI monitoring toolProject description Data change from day to day which can have great and even fatal results on ML models in production. So the purpose of this project was to design and develop an effective and optimized tool to monitor billions of rows of data and alert users of any drifts or big changes in data. Alerting users of missing data and general data quality was also needed. Everything had tobe webbased so anyone from anywhere could access the tool and quickly get an overview of any potential problems.  Role Data EngineerResponsibilities As a Data Engineer Ditlev optimized SPLUNK and SQL queries used for extracting statistical logs from the Data and AI platform to follow the trends and drifts of data over time. Ditlev then built a webbased tool for extracting, cleaning and transforming the statistical logs so they could be visualized online and in reports. Ditlev developed alerts so users were informed if data drifted more than expected or if there were issues with the data quality. Role Data ScientistResponsibilities As a Data Scientist, Ditlev was the lead on the monitoring project. His main responsibilities were understanding the different models and their uniqueness and then translating this informationknowledge into data which could be visualized in a way that gave a clear view of a models performance. The work was carried out in SCRUM teams mainly using CV  Ditlev Jrgensen   2022 Capgemini. All rights reserved. 15"
Ditlev_J_rgensen,2,"python and SQL. The visualization task was solved using Plotly Dash.Skills SQL, ETL, Data Visualization, Data Validation, Data Cleaning, Splunk, Web Application development, Python, Plotly Dash01.2021  09.2021 ATPs Data and Analytics Department, Fraud within CompaniesProject description The company analysis was, in its simplicity, a model aimed at finding atypical companies. Comprehensive data exploration was carried out, especially using SQL. Later, different models were tested here among deep neural networks developed in Python. There were several test rounds with the customer where the interpretation of output and visualization were core tasks.Role Data ScientistResponsibilities As a Data Scientist, Ditlev in cooperation with a colleague was responsible for finding atypical companies within specific sectors  with a focus on finding companies which committed fraud against the Danish welfare state. Ditlevs main responsibility was the development of a new model but most of the work entailed data exploration as a new data sourcewas added specifically for the project. The project was made in collaboration with a client so therewere test rounds and modelfinetuning in collaboration with the client. In the end, the model was incorporated into the current setup and deployed as a biproduct supporting a model already in production. Skills Data Exploration, Data Analysis, Neural Networks, Deep Learning, Deep Neural Network, Python, Plotly Dash, SQL, Data Visualization, Model Development, Machine Learning, Software Development, Project Management, Project Leadership, Project Coordination, Test Automation, Customer Relations09.2019  01.2020 Danish Agency for Higher Education and Science UFM, State Education GrantProject description Ditlev, in collaboration with the Danish Agency for Education and Research, developed a model for controlling the payment of state granted education funds. The product wasendtoend where data went through standard ETL principles before being crunched in the model.Data exploration and analysis was the main part of the project, but the production involved Software Programming in Python and SQL. Automatic Tests were developed for every part of the project and model outputs where tests in collaboration with the customer. Role Business AnalystResponsibilities As a Business Analyst, it was Ditlevs job to explore data and find relevant features that could be used in the model. Most of the work was done in a DevOps setup with SCRUM, CICD and GIT. The model was developed in Python where data was handled using SQL. With the best KISS principles and extensive business knowledge Ditlev coded criteria where he was able to find lots of fraudulent cases which he then through detailed information and visualizations clearly communicated to clients why cases were fraudulent.Skills Python, SQL, Data Extraction, Data Cleaning, Test Automation, Data Analysis, Software Development, Software Architecture, Numpy, Scikitlearn, Pandas, Customer Experience, Test Automation Framework, Scrum Agile Project Management, Daily Scrum, Agile Development, DevOps, Azure DevOps CICD Pipeline Setup, Azure DevOps, GITCV  Ditlev Jrgensen   2022 Capgemini. All rights reserved. 25"
Ditlev_J_rgensen,3,"09.2019  09.2022 ATPs Data and Analytics Department, Data and AI platformProject description SPARK is the Data and AI platform developed by ATP. It aims to check all payments made by the Danish public welfare system for fraud. The platform required constant work as new features were added regularly. And with any big software platform bugs needed to be removed and optimization was always needed  especially when working the terabytes of data. Role Software DeveloperResponsibilities As a Software Developer, Ditlev worked in a SCRUM team updating, bugfixing or improving the architecture or use cases of the data and AI platform. The work also entailed implementing new models or adding new features to the platform. Most of the work was done in SQL and Python where test Automation and Software Architecture development was the primary skills used. The work also entailed data exploration and data analysis as the platforms main responsibility was getting data ready for features or machine learning models. DevOps was a big part of the project with GIT, CICD processes such as review and gatekeeping. Skills Software Development, Software Architecture, SQL, DevOps, Azure DevOps CICD Pipeline Setup, CICD, Data Engineering, Data Governance, Data Exploration, Data Management, MS SQL Server  SSMSEDUCATION2017  2019 Geophysics and Space EngineeringTechnical University of Denmark DTU2013  2017 Geophysics and Space EngineeringTechnical University of Denmark DTUCOURSES07.2019 Learning Hadoop07.2019 Advanced SQL for Data ScientistsCERTIFICATIONS09.2022 AZ900 Azure FundamentalsDATA ANALYTICSData ExtractionFraud DetectionClustering AlgorithmsData ExplorationData TransformationDeep LearningProject LeadershipProject CoordinationCustomer RelationsCV  Ditlev Jrgensen   2022 Capgemini. All rights reserved. 35"
Ditlev_J_rgensen,4,Customer ExperienceScikitlearnGITIsolation Forest AlgorithmsOutlier DetectionSOFTWARE ENGINEERINGSoftware DevelopmentWeb ServicesThreadingSoftware ArchitectureMicroservices ArchitectureData ExplorationData AnalysisNeural NetworksDeep Neural NetworkPythonPlotly DashSQLData VisualizationModel DevelopmentMachine LearningProject ManagementTest AutomationWeb Application developmentData EngineeringData ExtractionData CleaningPandasNumpyScrum Agile Project ManagementDaily ScrumAgile DevelopmentDevOpsAzure DevOps CICD Pipeline SetupAzure DevOpsCICDData GovernanceData ManagementMS SQL Server  SSMSPython Flask Web Application FrameworkTest Automation FrameworkWebsite DesignEMPLOYMENTS09.2022   Capgemini09.2020  09.2022 ATP09.2019  09.2020 ATPCV  Ditlev Jrgensen   2022 Capgemini. All rights reserved. 45
Ditlev_J_rgensen,5,LANGUAGESDanish Mother tongueEnglish Good CommandCV  Ditlev Jrgensen   2022 Capgemini. All rights reserved. 55
Drisya_Thumba,1,"Drisya ThumbaDrisya has 8 years in Data Science. Drisya has experience in Machine Learning, Data Engineering and has handson experience with Python  R for developing endtoend analytics solutions and dashboard reporting. Drisya has handson experience with data modelling, ETL, data preparation and processing. Additionally, Drisya has experience in applied advanced analytics, operations research and  machine learning techniques in research and academics problems.EDUCATION2012  2017 Ph.D. Futures StudiesUniversity of Kerala2008  2010 M. Tech. in Technology ManagementUniversity of Kerala2003  2007 B. Tech. in Computer Science  Information TechnologyMahatma Gandhi UniversityCERTIFICATIONS06.2022 Azure FundamentalsSKILLSPythonJava 11RJavaScriptMySQLEUREQAPython DashGITHUBMATLABShell ScriptingEMPLOYMENTS06.2020  05.2022 University of Southern Denmark08.2017  03.2020 University of Kerala10.2007  09.2008 EuphonTecCV  Drisya Thumba   2022 Capgemini. All rights reserved. 12"
Drisya_Thumba,2,LANGUAGESEnglish Good CommandHindi FluentMalayalam Mother tongueDanish Basic knowledgeCV  Drisya Thumba   2022 Capgemini. All rights reserved. 22
Emil_Djursner_Rasmussen,1,"Emil Djursner RasmussenData consultantDWH, SSIS, ETL, Data EngineerEmil is a Data Engineer and passionate business and IT professional with several years of experience as a consultant. He has specifically experience with data migration, data warehousing and ETL.  He has experience working with public and private customers. Through his experience, Emil has gained an understanding of the business and the technical aspect and their interaction, which enables him to understand how data can be used to deal with a customers business needs and wishes, and thereby present a solution proposal. Emil has specific experience with ETL SSIS, SQL, Visual Studio, Azure DevOps, GitHub, Cognos, Data Warehousing, and some experience with Azure Data Factory and PowerBI.ENGAGEMENTS12.2021  04.2022 Styrelsen for It og Lring STIL, Data WarehouseProject description Traditional onpremise datawarehouse project where Netcompany was responsible for ETL and maintenance of STILs datawarehouse.Role Data EngineerResponsibilities Emil was responsible for maintaining the data warehouse and conducting ETL through SSIS. Development of ETL SSIS processes were done in Visual Studio and SQL SSMS. Azure DevOps was used for testing of code and processes. Agile development in sprints using SAFe and Jira. In addition, Emil has also been responsible for preparing documentation of architecture in Enterprise Architect and Confluence.Skills Data Warehousing, ETL, SQL Server, SSIS, Agile Software Development01.2021  12.2021 Evida , MS Dynamic365 migration project for Evida DKProject description Data Migration project from Evidas legacy systems to Microsofts Dynamics 365 for Finance and Operations platform.Role Data EngineerResponsibilities Throughout the project, Emil was responsible for designing and developing ETL with SQL in SSMS and designed and carried out ETL SSIS development in Visual Studio 2019. In addition, Emil was also tasked with migrating data from older systems to Microsoft Dynamics 365FO.CV  Emil Djursner Rasmussen   2022 Capgemini. All rights reserved. 13"
Emil_Djursner_Rasmussen,2,"Further, Emil was responsible for makingworkshops with customers for better domain knowledge.Skills Microsoft Dynamics 365 Finance and Operation, Data Migration Validation, Integration Services SSIS, Visual Studio, SQL05.2019  12.2020 Danish National Bank, MS Dynamics 365 migration projectProject description Platform migration project from AX2009 to Dynamics 365 for Finance and Operations with transformations of the platform to match customer needs.Role Software DeveloperResponsibilities In the project, Emil was responsible for designing and programming C   X  code for the Dynamics 365 for Finance and Operations solutiom to meet customers requirements.Emil also got the task to maintain Microsoft Best Practices for the solution, where he performed code reviews, troubleshooting, testing and documentation of the D365FO the solution.Skills Microsoft Visual C, Visual Studio, X, Microsoft Dynamics 365 Finance and OperationEDUCATION2017  2019 MSc in Business Administration and Information SystemsCopenhagen Business School2015  2017 BSc in Business Administration and Information TechnologyCopenhagen Business SchoolCERTIFICATIONS07.2022 Azure Fundamentals05.2022 Azure Data Fundamentals05.2020 Exam MB300 Microsoft Dynamics 365 Core Finance and OperationsSKILLSPower BIData WarehousingSSISAgile Software DevelopmentData Migration ValidationIntegration Services SSISVisual StudioSQLMicrosoft Visual CEMPLOYMENTSCV  Emil Djursner Rasmussen   2022 Capgemini. All rights reserved. 23"
Emil_Djursner_Rasmussen,3,05.2022   Capgemini Denmark01.2021  04.2022 Netcompany AS05.2019  12.2020 Netcompany AS01.2017  04.2019 Q8 Denmark AS02.2019  05.2019 Novo Nordisk ASLANGUAGESDanish Mother tongueEnglish Good CommandNorwegian FluentSwedish FluentCV  Emil Djursner Rasmussen   2022 Capgemini. All rights reserved. 33
Eugenia_Borgia,1,"Eugenia BorgiaConsultantFinancial Crime Prevention, AML, KYC operations, Risk Assessment, Scrum Master, Business Analyst, Stakeholder ManagementI am a passionate Business Analyst with 5 experience in KYC, AML,  Enhanced Due Diligence EDD, and fraud checks and processes. I have been working on analysing and proposing solution and improvements. Eugenia is a confident, friendly person with great communication and interpersonal skills, along with a willingness to give her best in every situation. She has shown an excellent ability to diagnose problems and find alternative solutions. Her assignments included working as aBusiness Analyst, touching on KYC, AML, as well as Fraud. She has a good understanding of how antimoney laundering and fraud work in a global scenario and how important it is for every financial company to have a good alignment with Regulatory Governance. ENGAGEMENTS09.2019  02.2022 Rebel Penguin, Anti Money Laundering Project description Screen and Monitor accounts and assesses different risk levelsCheck documents KYC and Enhanced Due Diligence EDDReport the suspicious activities to the MLRO and work with him in the deepest investigationImplementing Ongoing Monitoring Procedures to risk profiles and enhancing compliance conductRole Anti Money Laundering Officer07.2016  09.2019 Rebel Penguin, Risk and Fraud Analysis Project description Monitor transactions and money flow. Dealing With KYC. Identify and report improvement areasRole Fraud analystEDUCATION2006  2010 BSc in Business EconomicsUniversity of Palermo2010  2012 MA in Communication of Science and Sustainable InnovationMilano BicoccaCV  Eugenia Borgia   2022 Capgemini. All rights reserved. 12"
Eugenia_Borgia,2,CERTIFICATIONS12.2021 Certificate in Internal Controls and Risk Management04.2022 Foundational Certificate in Anti Money Laundering AML and Know Your Customer KYC04.2022 Certified ScrumMaster03.2022 FinTech Security and Regulation RegTech02.2022 Introduction to Data Analytics03.2022 Risk ManagementSKILLSRisk and FraudAnti Money LaunderingBusiness AnalysisScrum MasterKnow Your Customer KYCStakeholder ManagementFinancial Crime DetectionKYC RegulationCompliance AnalysisAgileScrumWorkshop FacilitationFaciliating Interactive WorkshopFacilitation of WorkshopsStakeholder AnalysisStakeholderEMPLOYMENTS07.2016  09.2018 Gaming Innovation Group09.2018  02.2022 Gaming Innovation Group GIGLANGUAGESItalian Mother tongueSpanish FluentEnglish FluentCV  Eugenia Borgia   2022 Capgemini. All rights reserved. 22
Hamza_Minhas,1,"Hamza MinhasData EngineerData Modelling, ETL systempipeline , Data Warehousing, MDMHamza is an ambitious Data Engineer who has about 4 years of experience in data engineering. His expertise lies in the development, data warehouse, MDM implementation, database management, data migration, data modelling and SSRS reports of enterprise applications.Hamza has extensively worked on executing ETL systems, developing ETL pipelines and performing data modelling using Azure Data Factory and Databricks. He has worked with big data and has advanced knowledge of data warehouse operations and the dedication to see issues through to the end. Hamza has excellent problemsolving skills and can work both within a team and independently. He is looking to use his experience and knowledge to aid in a companys development.ENGAGEMENTS06.2021  02.2022 Roads and Transport Authority, Master Data ManagementProject description Designed and developed MDM for Road  Transport Authority, UAE.Acquired data from 10 sources, applied Data Quality rules, Transform, Merge and Match, Data Load,created customer 360 UI, and built dashboard using MicroStrategy.Role Data EngineerResponsibilities Analyze and interpret complex data on all target systems and provide resolutions to data issues.Setting up data pipeline from source layer to MDM StagingData extraction from client sources, data transformation using ETL tools for further analysis.Applying data cleansing mechanism while importing hence ensuring the veracity of data.Experience in working with data, business intelligence, and analytics.Designing strategies for testing data conformity, accuracy, duplication, consistency, validity, andcompleteness.Skills ETL, Data Extraction, Data Cleaning, Data Transformation, SQL, MicroStrategy, Informatica Data Quality IDQ12.2020  06.2021 Global Rescue LLC, Marketing DataProject description Move Marketing related data from OnPremises to Cloud for better AnalyticsRole DeveloperCV  Hamza Minhas   2022 Capgemini. All rights reserved. 13"
Hamza_Minhas,2,"Responsibilities Created new Database for Marketing in Azure DataBricksMove data from OnPremises to Cloud using SPARKApply Data Cleansing and ProcessingSkills Azure Databricks, Apache PySpark12.2020  06.2021 Global Rescue LLC, Marketing Data DashboardProject description Creation of dashboards and report generation for helping in decision making.Role BI DeveloperResponsibilities  Implemented new dashboard Skills Microsoft SQL Server Reporting Services SSRS01.2020  12.2020 Global Rescue LLC, Enurture campaignProject description Designed and developed workflows that filter the leadspotential members and contacts confirmed members based on their contact activity throughemails and generate automated customized emailsRole DeveloperResponsibilities  Developed workflows Automate the marketing email processSkills C, MS SQL, Dynamics CRM06.2019  09.2019 Global Rescue LLC, Subscription Management DashboardProject description Dashboard created for the marketing team administrators to manage user subscriptions.Role DevelperResponsibilities  Developed customized dashboard Customization on MS Dynamic CRM Intergrade third party tool ClickDimensions  Skills C .NET, DataTables, Data Modelling, JavaScript, jQuery09.2019  12.2019 Global Rescue LLC, Zoom webinar integrationProject description Synchronized Zoom webinars registered users with the users of systems. Alsocreated customized zoom webinars email notification templates.CV  Hamza Minhas   2022 Capgemini. All rights reserved. 23"
Hamza_Minhas,3,"Role DeveloperResponsibilities  Get Data from Zoom using APIs Developed dashboard using zoom synced dataSkills Zoom, C .NET, MS SQL, HTML5, CSSGlobal Rescue LLC, Email TemplatesProject description Developed customized email templates for Marketing and Sales team.Skills HTML5, CSS, Inky Email FoundationEDUCATION2014  2018 BSc in Computer EngineeringNational University of Sciences  Technology NUSTCOURSESGoogle Cloud Fundamentals Core InfrastructureData Warehouse Concepts, Design, and Data IntegrationBig data 101Data Engineering for EveryoneCERTIFICATIONSAzure FundamentalsAzure Data FundamentalsDP203 Data Engineering on Microsoft AzureEMPLOYMENTS06.2021  02.2022 TechVista Systems06.2018  06.2021 Global Rescue LLCLANGUAGESEnglish FluentHindi FluentUrdu FluentPunjabi Mother tongueDanish Basic knowledgeGerman Basic knowledgeCV  Hamza Minhas   2022 Capgemini. All rights reserved. 33"
Hatef_Abdollahi,1,"Hatef AbdollahiMachine Learning ConsultantMachine Learning Engineer, Data Engineering, Feature EngineeringHatef has over 4 years of experience in telco and IT. He is genuinely interested in Machine Learning and Artificial Intelligence in general and has been involved in complete lifecycle of several relevant projects from ideation to solution delivery. Hatef is very efficient and precise in his communication with the clients and always strives to contribute with energy and enthusiasm in different stages and processes of the project. He has great analytical capability and is thorough in proposing solutions. Hatef is skilled in Digital Signal Processing and Machine Learning techniques applied to performance optimization of a broad range of telecommunication systems. Hatef is proficient in Python and MATLAB programming languages and is able to provide substantial assistance in projects related to optimization of processes and systems. Hatef is a strong information technology professional with two Bachelors of Engineering B.Eng., and a Master of Science MSc focused in Telecommunication Engineering. Hatef has had several industrial collaboration projects during his academic studies in which he has developed systems implementing object recognition, emotion recognition to support children diagnosed with neurodevelopmental disorder NDD through gamification, and finally he has developed a network performance estimation and optimization tool to be used in industrial settings by network operators.Hatef has conducted 3 years of academic research in the DEIB department of Polytechnic university of Milan and the Photonics department of Technical University of Denmark DTU in research field of Machine Learning techniques for network design optimization and communication over the nonlinear fiberoptic channel.Hatef has passed Cisco Certified Network Associate CCNA training early in his career and is fluent with the program objectives. He has experience in outofthebox installation of Cisco switches and other network equipment. Hatef is an experienced and wellversed machine learning professional with strong focus in delivering specific ML solutions. He has extensive experience in analyzing complex data structures, performing feature engineering, developing ML algorithms in close collaboration with his clients. He is experienced in data storytelling, stakeholder management and enjoys being a team player. He Possesses extensive analytical skills and strong attention to detail.ENGAGEMENTS09.2015  08.2016 Everly hotel Putrajaya, Unattended or Missing object recognitionProject description Design and implementation of a smart monitoring CCTV system capable of detecting missing or unattended objects fromin the hotel premises. During the course of the project, the consultant was in charge of the design and development of the final solution using Python and OpenCV toolkit. Role Lead DeveloperResponsibilities The consultant has designed and developed the final solution entirely on his ownand has packaged and delivered the solution to the customer through an industrial agreement between the Asia Pacific University APU and Everly Hotel Putrajaya. Skills Python, OpenCV, Image Processing, Digital Signal Processing, Software Development, CV  Hatef Abdollahi   2022 Capgemini. All rights reserved. 14"
Hatef_Abdollahi,2,"Python Flask Web Application Framework, HTML, CSS3, JavaScript03.2019  12.2020 QoT Estimation of Unestablished LightpathsProject description The consultant has been involved in this project as a master thesis student. This project was about using Machine Learning techniques such as regression for Quality of Transmission estimation of unestablished lightpaths in optical communication networks.Role Research  Knowledge SpecialistResponsibilities The Consultant was the lead researcher in this project at the end of which he was able to develop a completely original and novel QoT estimation tools to be utilized by network operators. The tool developed by the consultant provides the network operators with more accurate and informative details to facilitate and improve the decisionmaking processes involved in network design and budgeting. Skills Python, Understanding of Machine learning algorithms, Statistical Calculations, Model Optimization, Network Communications, Network Monitoring, Deep Learning, Data Engineering, Feature Engineering, Data Mining, Academic Research, Academic Writing11.2019  01.2020 Vodafone Italia, VoLTE Project description Delivery of Voice over LTE solution to the subscribers of Vodafone Deutschland in Italy and Vodafone Italia in Germany.Role Junior ConsultantEngineerResponsibilities The consultant was responsible for assisting the client team in the test center with their technical requirements in testing the newly deployed protocols in Voice Core Network, conducting both qualitative and quantitative analyses. Additionally, the consultant was responsible for logging and documenting the development stages and tests as the project progressed. The consultant was also in charge of configuring network equipment. Skills Voice Services  Mobile Phone and Mobility Management, Test Cases creation, Test Automation, Network Equipment Configuration, Telephony Application Server, Virtual Network Operator02.2020  04.2020 Nokia Italia, Migration to VNOProject description The project was about migration from legacy voice core network equipment to next generation network equipment and enabling virtual network operator services. In particular, the Telephony Application Server equipment was targeted during the project and the team in which the consultant was active handled related configurations. Role Automation SpecialistResponsibilities The consultant was mainly responsible for the automation of data migration from the legacy to the NGN. During the course of the project, the consultant developed multiple scripts which enabled the automation of variety of tasks such as data acquisition, data entry, graph visualization, data storage and etc. It was the intention of the employer to prepare a collage of the consultants scripts to sell to the client. CV  Hatef Abdollahi   2022 Capgemini. All rights reserved. 24"
Hatef_Abdollahi,3,"Skills Python, Regex, Pandas, Numpy, HTML, ETL04.2021  04.2022 Machine Learning techniques for communication over the fiber optic channelProject description This project explored novel signaling schemes, which were optimized by taking into account the nonlinear response of the optical fiber channel. A number of schemes were investigated both numerically and experimentally, focusing on endtoend learning approaches by applying machine learning techniques such as autoencoders.Role Research  Knowledge SpecialistResponsibilities The consultant was responsible for pushing the stateoftheart on endtoend learning, combining several research disciplines ranging from digital signal processing, machine learning and optical technologies. The consultant worked on optimization of the transmitted signals specifically for the nonlinear fiber channel, learning the full transformation applied by the this channel, i.e. between transmitter and receiver, and thus optimize the signaling scheme at the transmitter side to maximize the received signal quality.Skills Python, Deep Learning, Understanding of Machine learning algorithms, Digital Signal Processing, Numerical Optimization, Algorithm Development, MATLAB, Autoencoders, Anaconda, Pandas, Numpy, Scikitlearn, SciPy, Matplotlib, PlotlyEDUCATION2012  2016 Bachelor of EngineeringAsia Pacific University of Technology and Innovation2012  2016 Bachelor of EngineeringStaffordshire University2017  2020 MScPolitecnico di MilanoCOURSES05.2022 Build, Train, and Deploy Machine Learning Models with Amazon SageMaker05.2022 Cleaning and Exploring Big Data using PySpark05.2022 AWS Certified Machine Learning Specialty Learning Plan05.2022 Learning SQL by Ben Forta05.2022 SQL and PostgreSQL for Data Analytics05.2022 AWS Technical Essentials05.2022 AWS Cloud Practitioner Essentials06.2022 AWS Solution Architect  Associate Learning Plan07.2022 Data Engineering with AWS Machine LearningCERTIFICATIONS06.2022 AWS Certified Cloud Practitioner CLFC01CV  Hatef Abdollahi   2022 Capgemini. All rights reserved. 34"
Hatef_Abdollahi,4,08.2022 AWS Certified Solutions Architect  Associate SAAC0208.2022 Microsoft Certified Azure Fundamentals AZ90009.2022 Microsoft Certified Azure AI Fundamentals AI90009.2022 Microsoft Certified Azure Data Fundamentals DP900DATABASESTelephony Application ServerEMPLOYMENTS09.2015  08.2016 Everly Hotel Putrajaya11.2019  12.2020 Altran Italia04.2021  04.2022 Denmark Technical UniversityLANGUAGESPersian Mother tongueEnglish FluentItalian Good CommandGerman Basic knowledgeDanish Basic knowledgeCV  Hatef Abdollahi   2022 Capgemini. All rights reserved. 44
Jacob_Karlstr_m,1,"Jacob KarlstrmData EngineerJacob is an intelligent and ambitious data engineer. His expertise lies in delivering endtoend solutions that empower business operations and decisionmaking. He has professional experience of working with data in production settings withstringent quality demands and has substantial experience of working with Python and SQL. Jacob has outstanding problemsolving skills and is driven by a strong team spirit. In his previous engagements, he has proved to have a highly developed ability of fast learning.ENGAGEMENTS03.2022  07.2022 Confidential Client Photonics Chipset Developer, Automated Inline Device Testing SetupProject description The aim of this project was to set up new inline electrical characterization of a new variant of the customers device. The project included programming measurement equipment, automating data collection to an MySQL database, and setting up an automated report generation system.Role Test EngineerResponsibilities Jacob was the main developer in this project and built a waferlevel automated test setup according to the customers specifications. Throughout the project Jacob worked in close contact with the customer and provided several improvements to the customers initial specification to ensure the extracted data would provide as useful parameters as possible.Skills Python, SQL, LabView, Electronics, Data Analysis11.2021  07.2022 Confidential Client MEMS Switch Developer, Transfer of Automated Inline and Final TestingProject description Inline and final testing of MEMS devices was previously done by the client, and the goal of this project was to transfer the testing to Silexs own fab to be run by operators. The project involved altering the customers legacy code and adjusting it to fit Silexs production workflow and systems.Role Test EngineerResponsibilities A the main developer in this project, Jacob was in charge of planning, risk analysis, software development and qualification. Jacob worked in close contact with the customer to ensure a smooth transition and to ensure the new system fulfilled all requirements in regards to quality. Skills Python, C, Electronics, SQL, Risk AnalysisCV  Jacob Karlstrm   2022 Capgemini. All rights reserved. 13"
Jacob_Karlstr_m,2,"10.2021  07.2022 Confidential Client MEMS Microphone Developer, Automated Final Testing SetupProject description The project included running and improving already set up automated testingof already established products, as well as setting up new tests for new product variants. Role Test EngineerResponsibilities Jacob was the main responsible engineer for setting up electrical testing of the customers products. He was responsible for designing measurement procedures, defining measurement parameters, programming measurement instruments, automating wafer probing equipment, and creating systems for automatic report generation. Skills Python, SQL, Electronics, LabView12.2020  10.2021 Silex Microsystems AB, Software and Database Development for Inline Process ControlProject description Chemical Mechanical Planarization was recently added as a process in Silexs semiconductor fab, and a need emerged for software to analyze and predict the process. Dedicated software, including a GUI for operators, as well a measurement database were set up and taken into production.Role Project LeadResponsibilities After seeing the need of such a system, Jacob took the initiative to start this project and worked as the main developer. He created a database for measurement data and process parameters, developed software for data acquisition  analysis, and designed an interactive user interface for process operators and other process engineers.Skills Qt Crossplatform Application Framework, Python, SQL, Data Analysis01.2020  08.2020 Lund University, Automatic Cell Counting  Characterization SoftwareProject description The aim of this project was to develop software for automatic processing and segmentation of fluorescence microscopy images of neural cells. The final software had functionalities for automatically counting and evaluating shape and orientation of cell nuclei, and summarizing results in diagrams. Role Software DeveloperResponsibilities Jacob took the initiative for this project as he saw a need for automating timeconsuming tasks which were previously done manually. He was responsible for all coding, documentation and testing of the software in the project.Skills Python, Image Segmentation, Image Processing, Qt Crossplatform Application Framework06.2018  12.2019 Lund University, Design of Electronic Control Interface for Gold Nanoparticle GeneratorProject description The control interface which had been used for nanoparticle generating equipment was not working as expected. The goal of this project was to design and build a new and improved interface with all desired functionalities.CV  Jacob Karlstrm   2022 Capgemini. All rights reserved. 23"
Jacob_Karlstr_m,3,"Role Electronics Design EngineerResponsibilities Jacob was responsible for carrying out the whole project. He assessed the old system to find weaknesses, and designed and constructed a new modularized interface. Skills PCB Design, Electronics, CADEDUCATION2015  2020 Master of Science in Engineering NanoscienceLund UniversityCERTIFICATIONS09.2022 Microsoft Certified Azure Data Fundamentals DP90009.2022 Microsoft Certified Azure Fundamentals AZ90010.2021 Six Sigma Yellow Belt CertificateEMPLOYMENTS10.2020  07.2022 Silex Microsystems AB07.2018  12.2019 Lund University08.2013  01.2014 FOI Swedish Defense Research AgencyLANGUAGESSwedish Mother tongueEnglish FluentChinese Basic knowledgeCV  Jacob Karlstrm   2022 Capgemini. All rights reserved. 33"
Jan_Neldeberg,1,"Jan NeldebergSenior Consultant  Business AnalystJan has 12 years of experience within the financial sector, where 8 years are around projects within a complex area. He has taken on these projects from both the business and the IT angle, and thus able to see things from different angles. He is used to work in an agile setup within IT, as well as work the agile way.Throughout his career in the financial sector, he has acquired great insights and valuable knowledge on complex setups and requirements as well of stakeholder management and communicating on multiple levels.He is a problem solver, and able to break down complex setups in order to connect the dots by engaging relevant stakeholders.ENGAGEMENTS2022   Novo Nordisk ASProject description BA for Data catalog for NNI data privacyWorking in an agile setup with Azure DevOps as the handling system for epics, features etc. 2020  2022 Nordea, Business AnalystProject description Maintaining and improving existing KYC tool for high risk customers.BA, SME and UX on designing a newupdated KYC tool for high risk customers Skills Project Management, Stakeholder Management, Process Management, Process Optimization, Agile setup, Agile, Compliance, Data Analysis, Problem Solving, Mentoring, Coaching, Workshop Facilitation2016  2020 Nordea, KYCComplianceProject description Compliance related work KYCAML analysis, network management on high risk customer segments2014  07.2015 Nets, AML ConsultantProject description AML analysis of customers SME and PMVDevelopment of internal processes related to AML including uncovering of problem areas to be CV  Jan Neldeberg   2022 Capgemini. All rights reserved. 13"
Jan_Neldeberg,2,"fixed, and help fixing themDevelopment of documents for AML related work processes, guidance etc.Communication link between AML and Business Unit EDUCATION2011  2012 MBA in Business Relations ManagementUniversity of Southern Denmark SDU2008  2009 Academy education within financial counselingCopenhagen Business Academy2007  2008 MBA in Business relations Management part 1University of Southern Denmark SDU2003  2006 BSc in International Business AdministrationUniversity of Southern Denmark SDUTOOLSSAPSKILLSBusiness AnalysisCompliance for Financial InstitutionsAnti Money LaunderingKYC RegulationBankers AlmanacSWIFT AnalyzerHOST Nets  payment system ComplianceSWIFT Compliance Analytics  SWIFT KYC RegistryKYCProject ManagementStakeholder ManagementAgileData AnalysisProblem SolvingCoachingWorkshop FacilitationEMPLOYMENTS2020  2022 Nordea2018  2020 Nordea2016  2018 Nordea2015  2016 Coop Bank2014  2015 Nets Group2010  2012 Danske BankCV  Jan Neldeberg   2022 Capgemini. All rights reserved. 23"
Jan_Neldeberg,3,2008  2010 Danske BankLANGUAGESDanish Mother tongueEnglish Good CommandGerman FluentCV  Jan Neldeberg   2022 Capgemini. All rights reserved. 33
Jayant_Pant,1,"Jayant PantConsultantJayant is an ambitious Data Engineer who has past 8 years of experience in Data Warehouse and Data Lake management.He is currently undertaking Masters in Data Science in IU International University of Applied Science, Berlin, alongside his current job. He will be completing his masters mid2022.Jayant is well versed in performing EDA, data mining, data modelling and visualization in collaboration with business users,analytics and data science teams. He has strong experience in Big Data ecosystem, such as HDFS, Hadoop, PySpark, Hive, MapReduce, Airflow and has excellent python skills.CV  Jayant Pant   2022 Capgemini. All rights reserved. 11"
Jes_Melbye_Chergui,1,Jes Melbye CherguiManaging ConsultantCV  Jes Melbye Chergui   2022 Capgemini. All rights reserved. 11
Julian_Eikhaug,1,"Julian EikhaugAssociate ConsultantDeveloping Machine Learning Models, Python programming, ML and Business interactionWith an educational background from both business and data science, Julian is a Data Engineer that has a solid understanding of conventional business areas and mechanisms. Meanwhile, he will contribute on a technical level with skills such as programming Python, R, PySpark, SQL, building machine learning and deep learning models, XAI methods, NLP methods, BIsolutions and other work within the ETLpipeline. In terms of industries, Julian is particularly excited about the renewable energy sector and financial services sector, but also has an interest in the CPRD realm. His interest in renewables reflects his experience in the DI team of a consultancy working within renewable energy. In this role, he contributed with the development and daily operation of various BIsolutions relating both to financial and technical data, working both on backend and frontend tasks. In his master thesis, Julian developed ML and DL models for credit scoring specifically modelling the probability of default in collaboration with a large Danish bank. By applying such models and techniques in a highly regulated domain, he also developed knowledge within the field of Explainable AI XAI.Julian is a social team player which adapts easily to the given team  depending on the situation he can assist in managing or focus on executing the delivery.ENGAGEMENTS02.2018  08.2020 Deloitte, Finance DepartmentProject description Support function of Deloitte Norway working with internal financials and accounting.Role Finance AssistantResponsibilities Responsible for processing invoices and contributing in the process of finding suitable cost allocation.01.2022  06.2022 Danish Bank, Credit scoring using MLProject description Master thesis. Developed ML and DL models for credit scoring specifically modelling the probability of default. The model in operations serves two main purposes. Firstly, the model is used as an input in calculating the Risk Weighted Assets RWA which again is used tocalculate the Minimum Capital Requirement buffer which the bank is subjected to set aside as collateral security for their loan exposure. Secondly, the model is used as decision support for including or excluding new customers. Because the domain is highly regulated the project also explored the field of Explainable AI XAI in order to abate the issue of opaque models.Role DeveloperResponsibilities Created various ML and neural network models. Also, researched theory and regulations underpinning design choices.07.2021  06.2022 PEAK Wind Renewable Services, BI Solution for Asset ManagerCV  Julian Eikhaug   2022 Capgemini. All rights reserved. 13"
Julian_Eikhaug,2,"Project description Delivering extensive data reporting platform on Power BI to an Asset Manager owning various renewable energy assets around the world. Dashboards relating both to financial and technical performance of the assets. Working with multiple data providers, asset operators and assets. Role Frontend DeveloperResponsibilities Designing various graph functionalities in Power BIRole Backend DeveloperResponsibilities Created Python scripts coordinating and consolidating data from various sources.Organizing SQL table setup.  07.2021  06.2022 PEAK Wind Renewable Services, Operation and maintenance of data platformProject description Day to day operation and maintenance of data platform. Handling change request, bugs and other adhoc tasks relating to areas across the ETL pipeline relating to the BI solutions.   07.2021  06.2022 PEAK Wind Renewable Services, Automation of reporting processesProject description Improving efficiency of manual reporting processes using Python scripts to automate the process.Role DeveloperEDUCATION2017  2020 BSc in Business AdministrationNorwegian Business School2019  2020 ExchangeCatlica Lisbon School of Business  Economics2020  2022 MSc in Business Administration and Data ScienceCopenhagen Business SchoolEMPLOYMENTS02.2018  08.2020 Deloitte Norway AS07.2021  07.2022 Peak Wind Renewable ServicesLANGUAGESNorwegian Mother tongueEnglish FluentSwedish Basic knowledgeCV  Julian Eikhaug   2022 Capgemini. All rights reserved. 23"
Julian_Eikhaug,3,Danish Basic knowledgeCV  Julian Eikhaug   2022 Capgemini. All rights reserved. 33
Kristina_Kj_r_Hedegaard,1,"Kristina Kjr HedegaardConsultantSolutionoriented Data ScientistKristina is an ambitious, passionate Data Scientist, who has expertise in data analysis, machine learning and deep learning from different industries. She has strong programming skills in R, Python, and experience in model development, data cleaning, data exploration, feature engineering, regression, neural networks, classification and clustering algorithms.Her masters in MathematicsEconomics gives her a strong theoretical background in mathematics, which enables her to quickly understand complex problems. Moreover, she has a wide knowledge of economics, is a motivated teamplayer, and has been working in close cooperation with different companies. Her analytical mind thrives in solving practical business problems. Kristina is proactive and well organized. As a person she is curious, so she is fast to understand a new problem and find a suitable solution. She is passionate to learn something new, and she finds challenges and changes exciting.ENGAGEMENTS07.2021  09.2022 Ikano Bank, Machine Learning to Increase Data InsightProject description The purpose of the project is to help the customer to get an overview of theirsystem data and make better use of their data to avoid errors. The project is on their cloud setup on AWS. In the project she works on multiple use cases using project management, machine learning and data analytics.Role Data ScientistResponsibilities Kristina works on this project as a Data Scientist, where she is responsible for the entire ML process on the various use cases. Her work consists of helping to define the projects, analyze the data, transform the data, create and train the ML models, put the models into production, present the results from the models and maintain them. In her daily work, she uses different ML and AI models to predict errors using python coding. On the project, she works with the following AWS services SageMaker, Glue, Lambda, Cloudwatch, CodeCommit and S3 Storage in a Scaled Agile Framework SAFe setup.Role Project ManagerResponsibilities On two of the use cases she works as a Project Manager, where she is scoping and planning the projects. To deliver the ML solution she creates the backlog for the project and prioritize the backlog for the team. The role also include risk management and process improvements. CV  Kristina Kjr Hedegaard   2022 Capgemini. All rights reserved. 14"
Kristina_Kj_r_Hedegaard,2,"Skills Machine Learning, Python, Neural Networks, Data, Data Analysis, Data Architecture, Data Cleaning, Data Collection, Data Engineering, Data Exploration, Data Extraction, Dashboards, QlikSense, Big Data, Jupyter Notebooks, Forecasting, Understanding of Machine learning algorithms, AWS, AWS Cloud, AWS S3, AWS Sagemaker, AWS Lambda, AWS Glue, Project Management, Planning03.2021  04.2021 The Danish Agency for Labour Market and Recruitment, Migration of Data Warehouse from Legacy System to CloudBased ComputingProject description Helping the client get an overview of migration options of their Data Warehouse from a Legacy System to CloudBased Computing. She did a manual migration from SAS to Apache Spark in Python on some of the clients ETL workflows and tested automatic optionsfrom external vendors as well.Role Project ManagerResponsibilities Project manager with responsibility for structuring the work, leading the team and had the communication with the client for migration their current system. She organized and led the daily standup meetings, drove the reporting, and planned, led and documented workshops. Role Data ScientistResponsibilities She was working on Databricks with PySpark to establish ETL pipelines in Azure Cloud. She did datapreparation, transformations, normalizations, explorations, and visualization. With data stored in Azure Data Lake she tested and validated the new flows. Skills Data Warehousing, Apache Spark, SAS, Project Management, Python, Azure11.2020  02.2021 North, AI Analysis Tool for gamingProject description NORTH would like to utilize internal and external data to better understand players gaming behavior and apply stateoftheart AI algorithms to scout for new talents. We developed an analysis tool for tracking skills and performance enhancement, scouting of new players and predicting winning rates.Role Data ScientistResponsibilities Design and development in Python of a notebook to compute data features to measure player performance in CounterStrike egames. Created a dashboard for the customer, where it was possible to choose specific players and see their statistics in different maps and also compare the different players. Role Data EngineerResponsibilities Design and development in Golang Go Programming Language of a program to extract logs of events out of binary Demo files that are records of CounterStrike professional matches.Skills Dashboards, Plotly Dash, Python, Go, Pandas, Analytical Problem Solving, Statistical Calculations, Jupyter Notebooks, Data Analysis, Data ExplorationCV  Kristina Kjr Hedegaard   2022 Capgemini. All rights reserved. 24"
Kristina_Kj_r_Hedegaard,3,"01.2020  06.2020 Telenor AS, Customer Churn PredictionProject description She designed an innovative machine learningbased tool to predict which Telecom customers will churn. Role Data ScientistResponsibilities She applied extensive data cleaning and random undersampling to highly imbalanced data. To model this data she implemented Extreme Gradient Boosting and Neural Network in R and Python to identify the customer who will churn. She visualized these results in a dashboard in Shiny R.Skills Machine Learning, Telecom, R, Neural Networks, Python, Prediction, Data Cleaning, Big Data, Data Exploration, Deep Learning09.2018  01.2019 Grundfos AS, Inventory managementProject description Project in Operations Analysis to identify opportunities for improvement in inventory management. Using data for one component, she investigated inventory management methods to optimize current solution.Role Data ScientistResponsibilities Developed Categorized products with the kmeans clustering method, and evaluated different inventory strategies such as SilverMeal, Part Period Balancing, and Order Up to Level are used on deterministic and probabilistic demand. Performed steadystate analysis of the service level. Skills Product Inventory Management, Clustering, Data Cleaning, Data Analysis, Statistical Calculations, Time Series ModellingEDUCATION2015  2018 BSc in MathematicsEconomicsAalborg University2018  2020 MSc in MathematicsEconomics, Operational ResearchAalborg UniversityCERTIFICATIONS09.2022 Google Project Management Certificate04.2021 Azure AI Fundamentals01.2022 Machine Learning Engineering for Production MLOps07.2021 Azure Data Scientist Associate09.2021 Certified SAFe Scaled Agile Framework SAF06.2021 Azure Fundamentals01.2021 DA100 Microsoft Azure Data Analyst10.2020 Azura Data Fundamentals12.2020 Machine Learning with PythonCV  Kristina Kjr Hedegaard   2022 Capgemini. All rights reserved. 34"
Kristina_Kj_r_Hedegaard,4,10.2020 Python for Data Science and AISKILLSMachine LearningR Programming LanguageData AnalysisStatistical CalculationsMATLABSQLNeural NetworksPythonPredictionData CleaningBig DataRData ExplorationClusteringPlotly DashData WarehousingApache SparkProject ManagementAzureJupyter NotebooksPandasDataData CollectionData EngineeringData ExtractionUnderstanding of Machine learning algorithmsAWSAWS S3AWS GluePlanningEMPLOYMENTS11.2018  07.2020 Centrica Energy Trading AS11.2016  12.2018 Centrica Energy Trading ASLANGUAGESDanish Mother tongueEnglish FluentCV  Kristina Kjr Hedegaard   2022 Capgemini. All rights reserved. 44
Ksheeraja_Vinjanampati_,1,Ksheeraja Vinjanampati ConsultantCV  Ksheeraja Vinjanampati    2022 Capgemini. All rights reserved. 11
Lee_Ann_Zambrano_Larsen,1,"LeeAnn Zambrano LarsenData ScientistENGAGEMENTS02.2022   Volvo Trucks, PL Data StrategyProject description Enterprise datahub Role Scrum MasterResponsibilities  Successful applying transparency, inspection, and adaptation in all Scrum events Ensuring the removal of impediments through successful facilitation Successfully helping the team deliver at least one retrospective action every sprint that supports continuous improvement Ensuring teams and leaders are meeting the quality standards as set in the Definition of DoneRole Product OwnerResponsibilities  Product Backlog Management   Creating product roadmaps  Stakeholder Management  Defining business requirements Role Data EngineerResponsibilities  Designed and implemented highly performant data ingestion pipelines from multiple sources using Azure Databricks.  Integrating the endtoend data pipeline to take data from source systems to target data repositories ensuring the quality and consistency of data is maintained at all times Developing scalable and reusable frameworks for ingesting data10.2021  01.2022 Danish Prison and Probation Service DPPSProject description The DPPS Contributes to strengthening the level of security and the ability to handle incidents that threaten the order and security situation for both the employees and Danishsociety in general. Role Security and Intelligence AnalystResponsibilities LeeAnn analyzed business needs, defined requirements and performed CV  LeeAnn Zambrano Larsen   2022 Capgemini. All rights reserved. 12"
Lee_Ann_Zambrano_Larsen,2,"development using IBMs i2 security platform. 01.2021  08.2021 Saxo Bank AS, Financial Crime Improvement of AntiMoney Laundering monitoring systemProject description The investment Bank, wished to improve the accuracy, in their Rulebased monitoring system. They wanted to improve their system by adding capabilities from machine learning in the transaction monitoring.  Role Data ScientistResponsibilities LeeAnn role was to design and test several machine learning models, that could increase the accuracy and efficiency in the current monitoring system. This included training Supervised , Semisupervised and unsupervised machine learning models. Skills AntiMoney Laundering, Python, Model Development, Compliance, Machine Learning, Financial Crime DetectionEDUCATION2019  2021 MSc in Business Administration and Data ScienceCopenhagen Business School2015  2019 BSc in Business Administration and Information TechnologyCopenhagen Business School2014  2015 1 year Chinese Language and Culture ProgrammeBeijing Language and Culture UniversityCOURSESIntroduction to Cloud ComputingGDPR Regulation, Governance, Security, Privacy and EthicsFoundations of Data Science Programming and Linear AlgebraInnovation and Strategy in the Digital EconomyVisual AnalyticsData Mining, Machine Learning, and Deep LearningNatural Language Processing and Text AnalyticsPredictive AnalyticsData Scientist with PythonLANGUAGESDanish Mother tongueEnglish FluentSwedish Good CommandChinese Basic knowledgeSpanish Basic knowledgeCV  LeeAnn Zambrano Larsen   2022 Capgemini. All rights reserved. 22"
Line_Bruun,1,"Line BruunAssociate Consultant  Analytics  AILine is an enthusiastic Data Analyst with a passion for applying the newest technologies to address complex business problems and create real value. By combining her strong business understanding with technical expertise within Data Analytics, she is eager to understand and solve clients problems. Driven by transforming data into valuable business insights, Lines skill set comprises Power BI reporting and dashboarding. Being ambitious and hardworking is part of Lines DNA. She is proactive, organized and strives to always challenge the status quo. She thrives in dynamic environments with diverse tasks and team members. ENGAGEMENTS12.2020  01.2021 Danish Financial Service Company , Operating Model  IT Service ManagementProject description Collecting and analyzing business requirements related to IT Service Management. Creating business value by making IT Service Management processes incident, problem, change, release data driven. Delivering data insights and dashboards that enable greater effectiveness and efficiency in incident and problem management. 01.2020  06.2020 Danish Software Service Company, Machine learning for predictive maintenanceProject description Machine learning for predictive maintenance in the construction equipment industry. Building a supervised machine learning model to classify the health of cranking batteries.Creating business value by enabling a transition from run2failure maintenance to predictive maintenance. Addressing the overall problem of downtime in the construction equipment industry. EDUCATION2018  2020 MSc in IT, Communication and OrganizationAarhus School of Business Aarhus BSS2015  2018 BA in International Business CommunicationAarhus School of Business Aarhus BSSCV  Line Bruun   2022 Capgemini. All rights reserved. 13"
Line_Bruun,2,COURSES01.2020 AWS Certified Data AnalyticsCERTIFICATIONS10.2020 Introduction to Cloud Computing10.2020 Introduction to Power BI05.2020 Supervised Learning with Scikitlearn06.2018 SQL for Data Science06.2018 Python for Data ScienceSKILLSPythonNumpyBUSINESS SKILLSBusiness AnalysisBusiness ConsultingProject ManagementIT Service ManagementData AnalysisPandasSQLTECHNICAL SKILLS Data CleaningData ExplorationMachine LearningMatplotlibScikitlearnPower BIAWSEMPLOYMENTS08.2019  02.2020 Aarhus BSS  Aarhus University01.2020  06.2020 TrackunitLANGUAGESEnglish FluentCV  Line Bruun   2022 Capgemini. All rights reserved. 23
Line_Bruun,3,Danish Mother tongueCV  Line Bruun   2022 Capgemini. All rights reserved. 33
Mohd_Arshad,1,Mohd ArshadCV  Mohd Arshad   2022 Capgemini. All rights reserved. 11
Mohit_Kumar_Bhati,1,"Mohit Kumar BhatManaging Solution Architect  Data AnalyticsSoluton Architect, Data Architect, Senior Data Engineer, Problem Solver, TeamOriented and CollaboratveMohit has multiple years of experience across the disciplines of Engineering and Big Data Analytics  all rooted in an unwavering passion for data.With his diverse job experiences Healthcare, Finance, Logistics and Retails, certifications and coursework, he has developed a broad skill set in business intelligence, data analytics and gained proficiency in Hadoop, Spark, Cloud, SQL, Python, Scala, Kafka.A typical day at work includes querying petabytes of data for analysis, metric developmentfeature engineering as per business use cases, automation and reporting.Highlights Having experience on Big Data Stack Spark, Scala, Hive, HDFS, Sqoop, Oozie, Apache Kafka using Cloud Services AWS S3, EMR, EC2, Amazon Redshift and Microsoft Azure Databricks, Data Factory, Data Lake Store, USQL, Azure SQL, HDInsight. Experience in designing and implementing Big Data projects using Hadoop Ecosystems. Strong knowledge of Hadoop HDFS architecture and MapReduce Framework. Involved in data ingestion framework for largescale Datalake systems. Developed Linux Shell Scripts to Schedule Hadoop Jobs.  Handson working experience with AWS EC2, S3, EMR. Proficiency in Core Java, Python, Scala, and SQL. Worked extensively on performance optimization  automation.ENGAGEMENTS03.2020   Capgemini Danmark AS, DGMFRole Managing Solution ArchitectResponsibilites  Hands on contribution in design and development of data platform services which include various data services e.g. CDC Incremental load, Streaming load, Schema resolver, dynamic pipeline creation, etc Project and data governance including standardization of metadata, processes and code reviews Designing the complete solution using Azure IaaS, PaaS and SaaS capabilities.12.2018  03.2020 A.P Moller Maersk, Maestro Datalake EngineeringProject descripton Maestro big data and data analytics platform which serves as the foundation CV  Mohit Kumar Bhati   2022 Capgemini. All rights reserved. 14"
Mohit_Kumar_Bhati,2,"of Digital Products by centralizing data access and developer tooling. It powers internal and external capabilities to enable the acceleration of new products and facilitates compounding on previous efforts. Role Senior Data EngineerResponsibilites  Hands on contribution in design and development of data platform services which include various data services e.g. CDC Incremental load, Streaming load, Schema resolver, dynamic pipeline creation, etc Development of Data assets in the Data lake by ingestion, cleansing and processing data to create canonical models Project and data governance including standardization of metadataRole Data ArchitectResponsibilites  Hands on contribution in design and development of data platform services which include various data services e.g. CDC Incremental load, Streaming load, Schema resolver, dynamic pipeline creation, etc Designing the complete solution using Azure IaaS, PaaS and SaaS capabilities. Design the Delta Lake along with the infrastructure and application securitySkills Spark Streaming, Apache PySpark, Scala, Azure Cosmos DB, Azure Data Factory, Azure Databricks, Azure Functions, Azure HDInsight, HadoopHIVE, HadoopHDFS, JavaScript, Python03.2017  12.2018 Cerner Healthcare Pvt Limited, Bangalore, Data AnalytcsProject descripton Worked in data analytics team where we have to create centralized datalake store.Ingest the data using big data tools both batch and streaming.Run the spark jobs to transform data and create report out of it.Role  Senior Big Data EngineerResponsibilites  Ingest the data from all the sources by different approaches Run the USQL Transformation on the different columns to compare the data on the basis of IP address and Serial Number Creating the pipelines in Azure Data Factory which run on the daily basis Load the data into Azure SQL DB Create a tableau reports from this data by comparing different sourcesSkills Azure Event Hub, Apache Hadoop, Kafka, Azure Data Factory, Azure Data Lake, Azure Databricks, JavaScript, Scala, Python10.2015  03.2017 Envestnet Yodlee, Panel GeneratonProject descripton Creating panels bank data flow which involves taking the data from Multipledatabases and then use Sqoop to load this data into the HDFS.Use of Spark for extracting the valuable panel needed information.Sending this data to AWS clusters for PII Masking and Deep Cleaning.Use of  Amazon Redshift  for doing analytics on the data.Role Hadoop DeveloperCV  Mohit Kumar Bhati   2022 Capgemini. All rights reserved. 24"
Mohit_Kumar_Bhati,3,"Responsibilites Responsibilities Involved in loading data into Hadoop cluster. Writing Code in Spark and Scala to extract and transformation in the panel files. Developed Sqoop queries in the process of loading RDBMS into Hadoop cluster Developed and build Hive tables with partitions for better performance Tuned Hive queries to get the best performance. Deployed the jobs on AWS, creating a datalake on S3 and doing further analytics on AWS Redshift. Skills Apache Hadoop, Big Data, Apache Hive, Oozie, Sqoop, Python, Apache PySpark, Scala, AWS,AWS EC2, AWS Redshift, AWS Lambda, AWS S3EDUCATION2011  2015 BSc in TechnologySRMS College of Engineering  Technology, BareillyCERTIFICATIONS07.2018 IC Agile Certified Professional04.2020 Python Basics04.2020 Data Collection and Processing in Python12.2015 Red Hat Certified Engineer12.2020 Apache Spark for Data AnalysisDATA ENGINEERINGAzureBig DataOozieSqoopSpark StreamingApache HadoopApache PySparkHadoopHIVEKafkaHadoopHDFSSVNSQLAWS S3Azure Event HubAzure FunctionsAzure HDInsightCLOUDAzure DatabricksAzure Data FactoryCV  Mohit Kumar Bhati   2022 Capgemini. All rights reserved. 34"
Mohit_Kumar_Bhati,4,"AWS LambdaAWS RedshiftAWS EC2AWSAzure Data LakeUSQLLogic AppsEventHubAzure SQL DWAzure Resource Manager ARMSOFTWARE DEVELOPMENTScalaDEVOPS, CICD, AGILEGITGitlabJenkinsAzure DevOpsTest AutomationAgile ScrumScrum MasterSKILLSJavaScriptPythonAzure Cosmos DBEMPLOYMENTS03.2020   Capgemini Danmark AS10.2015  03.2017 Envestnet Yodlee03.2017  12.2018 Cerner Corporation12.2018  03.2020 A.P Moller MaerskLANGUAGESDanish Basic knowledgeHindi Mother tongueEnglish FluentCV  Mohit Kumar Bhati   2022 Capgemini. All rights reserved. 44"
Mostafa_Ellabaan,1,"Mostafa EllabaanData Science and EngineeringSenior Software Engineer and Data Science Consultant with exceptional experience in the field of data science and engineering and largescale data processing and analytics. He developed several platforms for analyzing complex data setsfor the discovery of antibiotic resistance genes, their dissemination pattern, and their future dissemination with the Novo Nordisk Foundation Center for Biosustainability. He also helped the National Institute of Health in the USA to understand the aging immune systems and develop systems to predict the aging cells. The consultant uses several programming languages such as Java, Python, Perl and, R. He uses several data streaming tools such as Spark and Kafka and infrastructure management systems such as Docker and Kubernetes. With More than 15 years of experience with database systems include MySQL and Oracle databases and SQL. At his latest project, the consultant used Apache spark to manage and execute large scale data analysis and machine learning algorithms.The consultant is use to collaborating with many different stakeholders and has collaborated with several scientists worldwide in projects related to coronavirus, aging disease and diabetes, allowing them to develop largescale cloudnative systems to help humankind fighting epidemic and agingrelated diseases.ENGAGEMENTS09.2019  02.2021 The Novo Nordisk Foundation Center for Biosustainability Freelance, Senior Data Science ConsultantProject description The consultants actionsresponsibilities were Provide consultation for both public and private sectors Architect and design data infrastructure using different platforms, including AWS, Microsoft Azure, and Google Cloud Apply machine learning algorithms to extract knowledge and insights from data Develop novel computational platform Use Apache spark to manage and execute large scale data analysis and machine learning algorithmsAmazon Web Services AWS  AWS Glue  Cloud  Python  R language  SQL  Docker  JavaScript  Java  S3  Redshift  Big Data Analysis  Parallel Processing  Apache Spark  EMR  Amazon DynamoDB  Shiny  RStudio  DevOps  Continuous Integration CI  Continuous Deployment CD  Fullstack UI  Web Apps  RStudio connect  databases  data wrangling R  health care data  regulatory industry  Atlassian Bamboo  Apache Spark  09.2020  09.2021 NIH, Freelancing Data Science ConsultantProject description The consultants actionsresponsibilities were Architecting the pipeline for analyzing the human transcriptomic data Identify key genetic markers for immune cells in an aging population Provide recommendations regarding containers and DevOps technologies and the best practices. Provide consultation regarding Unit testing and testdriven development Provide recommendations regarding data visualization using different platforms such as shiny, Power BI, and Tableau.CV  Mostafa Ellabaan   2022 Capgemini. All rights reserved. 19"
Mostafa_Ellabaan,2," Provide recommendations regarding largescale machine learning and models. Synthetic data generation for comprehensive pipeline testing and quality assurance.Agile Software Development  Amazon S3  Amazon Redshift  Amazon Web Services AWS  Docker  Docker Swarm  Artificial Intelligence AI  Apache Kafka  TestDriven Development TDD  Unit Testing  C  Java  Python  Big Data  Machine Learning  Tableau  Power BI  01.2008  07.2012 NTU, Identification of stable and transition states using Computational intelligence and evolutionary computation. Project description The consultants actionsresponsibilities were Developing machine learning tools and platform for mining complex large data sets and optimization of complex systems Developing machine learning tools and platforms for mining complex large data sets and optimization of complex systems Identify different stable and metastable structures for glutamate Study structure variation of glutamate on the function and dysfunction of CNS Identify stable states and transition states of small water clusters using Quantum mechanics, evolutionary optimization, AI, and data miningPython  Matlab  C  Java  Torque  SQL  AI  Big Data  Molecular Structure  Gussian  Firstprincipal Calculation  Evolutionary Optimization  Computational Intelligence  Parallel Processing  Distributed computing  Novo Nordisk Founcation Center for Biosustainability, Discovery of Collateral sensitivity profiles for intelligent drug cycling. EDUCATION2008  2012 PhD in Computer Science and EngineeringNanyang Technological University2005  2006 MSc in Computer ScienceUniversity of Nottingham1999  2003 BSc in Computer ScienceCairo UniversityCERTIFICATIONS02.2022 Azura Data Fundamentals02.2022 Azure AI FundamentalsAzure AI Engineer AssociateCLOUDGoogle Cloud Risk Protection ProgramCV  Mostafa Ellabaan   2022 Capgemini. All rights reserved. 29"
Mostafa_Ellabaan,3,Google Cloud Secret ManagerGoogle Cloud SecurityGoogle Cloud Security and IdentityGoogle Cloud Security centerGoogle Cloud Security Command CenterGoogle Cloud Service DirectoryGoogle Cloud Shielded VMsGoogle Cloud Soletenant NodesGoogle Cloud Speech to TextGoogle Cloud Spot VMsGoogle Cloud SQL Server onGoogle Cloud Storage Transfer ServiceGoogle Cloud TektonGoogle Cloud TensorFlow EnterpriseGoogle Cloud Terraform onGoogle Cloud Text to SpeechGoogle Cloud Titan Security KeyGoogle Cloud Tools for EclipseGoogle Cloud Tools for PowerShellGoogle Cloud Serverless ComputingGoogle Cloud Traffic DirectorGoogle Cloud Transcoder APIGoogle Cloud reCAPTCHA EnterpriseGoogle Cloud VaultGoogle Cloud Vertex AIGoogle Cloud Vertex AI WorkbenchGoogle Cloud Vertex Data LabelingGoogle Cloud Video AIGoogle Cloud Virtual Private Cloud VPCGoogle Cloud VirusTotalGoogle Cloud Vision AIGoogle Cloud VPC Service ControlsGoogle Cloud Web RiskGoogle Cloud WorkflowsGoogle Data StudioGoogle Distributed CloudGoogle Kubernetes Engine GKEGoogle Marketing PlatformGoogle MeetGoogle WorkspaceGoogle Cloud Transfer ApplianceGoogle Cloud User Protection ServicesGoogle Cloud VM ManagerGoogle Cloud VMware EngineMicrosoft GenomicsGoogle Cloud AI InfrastructureGoogle CloudGoogle Cloud AI building blocksGoogle Cloud API GatewayGoogle Cloud Access TransparencyGoogle Cloud Advanced Protection ProgramGoogle Cloud Analytics HubGoogle Cloud AnthosGoogle Cloud Anthos Config ManagementGoogle Cloud Anthos Service MeshCV  Mostafa Ellabaan   2022 Capgemini. All rights reserved. 39
Mostafa_Ellabaan,4,Google Cloud Apigee API ManagementGoogle Cloud Apigee API PlatformGoogle Cloud Apigee HybridGoogle Cloud Apigee IntegrationGoogle Cloud Apigee Open Banking APIxGoogle Cloud Apigee SenseGoogle Cloud Apigee healthcare APIxGoogle Cloud App EngineGoogle Cloud AppSheetGoogle Cloud AppSheet AutomationGoogle Cloud Application migrationGoogle Cloud Artifact RegistryGoogle Cloud Assured WorkloadsGoogle Cloud AutoMLGoogle Cloud AutoML TablesGoogle Cloud BeyondCorp EnterpriseGoogle Cloud BigQuery Data Transfer ServiceGoogle Cloud Binary AuthorizationGoogle Cloud Carbon FootprintGoogle Cloud Certificate Authority ServiceGoogle Cloud ChronicleGoogle Cloud Cloud APIsGoogle Cloud Cloud ArmorGoogle Cloud Cloud Asset InventoryGoogle Cloud Cloud BigtableGoogle Cloud Cloud BuildGoogle Cloud Cloud CDNGoogle Cloud Cloud CodeGoogle Cloud Cloud ConsoleGoogle Cloud Cloud DNSGoogle Cloud Cloud Data FusionGoogle Cloud Cloud Data Loss PreventionGoogle Cloud Cloud DebuggerGoogle Cloud Cloud DomainsGoogle Cloud Cloud EndpointsGoogle Cloud Cloud Foundation ToolkitGoogle Cloud Cloud FunctionsGoogle Cloud Cloud GPUsGoogle Cloud Cloud Healthcare APIGoogle Cloud Cloud IDSGoogle Cloud Cloud IdentityGoogle Cloud Cloud Inference APIGoogle Cloud Cloud Key ManagementGoogle Cloud Cloud Life SciencesGoogle Cloud Cloud Load BalancingGoogle Cloud Cloud LoggingGoogle Cloud Cloud Mobile AppGoogle Cloud Cloud MonitoringGoogle Cloud Cloud NATGoogle Cloud Cloud ProfilerGoogle Cloud Cloud RunGoogle Cloud Cloud Run for AnthosGoogle Cloud Cloud SDKGoogle Cloud Cloud Natural LanguageGoogle Cloud Cloud SQLCV  Mostafa Ellabaan   2022 Capgemini. All rights reserved. 49
Mostafa_Ellabaan,5,Google Cloud Cloud ShellGoogle Cloud Cloud Source RepositoriesGoogle Cloud Cloud SpannerGoogle Cloud Cloud StorageGoogle Cloud Cloud Storage for FirebaseGoogle Cloud Cloud TPUGoogle Cloud Cloud TasksGoogle Cloud Cloud TraceGoogle Cloud Cloud TranslationGoogle Cloud Compute EngineGoogle Cloud Confidential ComputingGoogle Cloud Config ConnectorGoogle Cloud Container RegistryGoogle Cloud Container SecurityGoogle Cloud Cost ManagementGoogle Cloud Data AnalyticsGoogle Cloud Data CatalogGoogle Cloud DataflowGoogle Cloud DataplexGoogle Cloud DataprepGoogle Cloud DataprocGoogle Cloud DatastreamGoogle Cloud Deep Learning ContainersGoogle Cloud Deep Learning VM ImageGoogle Cloud DeployGoogle Cloud Deployment ManagerGoogle Cloud Developer ToolsGoogle Cloud DialogflowGoogle Cloud Edge TPUGoogle Cloud Endpoint ManagementGoogle Cloud FilestoreGoogle Cloud Firebase CrashlyticsGoogle Cloud Firebase Test LabGoogle Cloud FirestoreGoogle Cloud FunctionGoogle Cloud Game ServersGoogle Cloud Gradle App Engine PluginGoogle Cloud HealthAPIxGoogle Cloud Healthcare Natural Language AIGoogle Cloud Healthcare and Life SciencesGoogle Cloud Hybrid ConnectivityGoogle Cloud Hybrid and MulticloudGoogle Cloud Identity PlatformGoogle Cloud Identity and AccessGoogle Cloud Identity and Access ManagementGoogle Cloud IdentityAware ProxyGoogle Cloud Internet of Things IoTGoogle Cloud IoT CoreGoogle Cloud KnativeGoogle Cloud Kubernetes Engine MonitoringGoogle Cloud LookerGoogle Cloud Managed Service for Microsoft Active DirectoryGoogle Cloud Management ToolsGoogle Cloud FirewallsGoogle Cloud Maven App Engine PluginCV  Mostafa Ellabaan   2022 Capgemini. All rights reserved. 59
Mostafa_Ellabaan,6,Google Cloud Media TranslationGoogle Cloud Media and GamingGoogle Cloud MemorystoreGoogle Cloud Migrate for AnthosGoogle Cloud Migrate for Compute EngineGoogle Cloud MigrationGoogle Cloud Network Connectivity CenterGoogle Cloud Network Intelligence CenterGoogle Cloud Network Service TiersGoogle Cloud Network TelemetryGoogle Cloud NetworkingGoogle Cloud OpenCueGoogle Cloud OperationsGoogle Cloud Packet MirroringGoogle Cloud Policy IntelligenceGoogle Cloud Private CatalogGoogle Cloud Private Service ConnectGoogle Cloud RecommenderGoogle Cloud Resource ManagerAzure Data CatalogAzure Data ArchitectureAzure Data ExplorerAzure Data FactoryAWS CloudAzure CycleCloudAzure Spring CloudCloud ServicesDATABASESGoogle Cloud Archive StorageGoogle BigQueryAzure Database Migration ServiceAzure Database for MariaDBAzure Database for MySQLAzure Database for PostgreSQLAzure SQL databaseGoogle Cloud Database Migration ServiceGoogle Cloud Firebase Realtime DatabasePython SqlAlchemy  Database MigrationsFRAMEWORKSFRAMEWORKSGOOGLE CLOUD CV  Mostafa Ellabaan   2022 Capgemini. All rights reserved. 69
Mostafa_Ellabaan,7,JavaScriptApache KafkaMicrosoft Visual CAWS S3Power BIGoogle App EngineAzure GatewayAzure InfrastructureGoogle AI HubAzure Data LakeAzure DatabricksBatchAzure DevOpsAzure Cosmos DBAzure Devtest LabsAzure SQLComputer VisionAzure Cosmos DBGoogle AutoML Natural LanguageGoogle AutoML Video IntelligenceAzure Data Lake Storage Gen1Azure Data ShareAzure Open DatasetsData CatalogData FactoryData Lake AnalyticsData Migration ValidationData Science Virtual MachinesAzure Application RegistrationAzure SQL EdgeAzure SQL Managed InstancePersonalizerPLSQL DeveloperAzure Analysis ServicesAzure App ServiceAzure API ManagementSQL Server on Virtual MachinesSQL Server on Virtual MachinesTable StorageAzure Load TestingAzure Applied AI ServicesAzure BastionAzure Bot ServicesAzure Cache for RedisAzure Cognitive SearchAzure Cognitive ServicesAzure Confidential LedgerAzure Container AppsAzure Container InstancesAzure Container RegistryApp ServiceAzure Cost ManagementAzure Dedicated HostAzure Event GridAzure FirewallAzure Form RecognizerAzure GovernanceAzure FunctionsCV  Mostafa Ellabaan   2022 Capgemini. All rights reserved. 79
Mostafa_Ellabaan,8,Azure IOTAzure Immersive ReaderAzure Kubernetes Service AKSAzure Lab ServicesAzure Machine LearningAzure Managed Instance for Apache CassandraAzure Metrics AdvisorAzure OpenAI ServiceAzure PerceptAzure PipelinesAzure PurviewAzure Quantum PREVIEWAzure Red Hat OpenShiftAzure Service FabricAzure Spot Virtual MachinesAzure Stream AnalyticsAzure Synapse AnalyticsAzure VM Image BuilderAzure VMware SolutionAzure Video AnalyzerAzure Virtual DesktopAzure Virtual Machines  LinuxAzure Virtual Machines  WindowsLanguage ServiceHealth BotConversational Language UnderstandingAZURE CLOUD TECHNOLOGYAzure API GatewayAzure Resource Manager ARMAzure DatabricksAzure DatalakeAzure BLOB StorageProject Bonsai PREVIEWR Server for HDInsightSpeak RecognitionKinect DKPower BI EmbeddedCustom VisionFace APISpeech translationSpeech to TextText to SpeechQnA MakerContent ModeratorHDInsightTranslatorAnomaly DetectorEvent HubsStatic Web AppsLinux Virtual MachinesWeb App for ContainersVirtual MachinesCV  Mostafa Ellabaan   2022 Capgemini. All rights reserved. 89
Mostafa_Ellabaan,9,Virtual Machine Scale SetsEMPLOYMENTS12.2021   Capgemini05.2021   Intelligent Data Driven Feeding09.2020  09.2021 NIH09.2019  12.2021 Self employed09.2019  02.2021 The Novo Nordisk Foundation Center for Biosustainability Freelance09.2012  09.2019 DTU and Novo Nordisk foundation Center for biosustainability09.2011  01.2012 Boston University 01.2008  07.2012 NTU10.2006  01.2008 Pulse09.2005  08.2006 ITI  The University of Nottingham 01.2004  08.2005 Pulse LANGUAGESEnglish FluentDanish Basic knowledgeArabic Mother tongueCV  Mostafa Ellabaan   2022 Capgemini. All rights reserved. 99
Olivia_Essen,1,"Olivia EssenData ScientistOlivia is an ambitious, solutionoriented Data Scientist, who has expertise in data analysis, requirements engineering, machine learning and database management. She has strong programming skills in Python, SQL and experience in model development, data cleaning, data exploration, feature engineering, regression, classification and clustering algorithms. Olivia brings work expertise from previous assignments which allows her to combine her project management skills with her technical knowhow. Olivia is positive, curious and prides herself in being well organized. ENGAGEMENTS02.2022   Federal Police, Smart BordersProject description With the Smart Borders project, the EU is aiming for the standardization and digitization of border control management. Through the development of one central system, implementation of uniform interfaces, secure communication channels and IT infrastructures, the EU strives for modern IT systems and processes. Based on the EU directive, the German Federal Police is tasked with implementing their part of the solution to the multinational IT and communication infrastructure. Role Solution Architect Interface SpecialistResponsibilities As part of the solution architecture team, Olivia helped the client analyze, derive and document interface and data flow adjustments in their IT processing chain. Based on businessprocesses, future needs and the existing IT infrastructure, Olivia facilitated discussions with stakeholders to specify requirements and model interface definitions and operations. Furthermore, Olivia assisted in expanding the technical and professional error handling at the interface. Skills Solution Design, Requirements Specification, Requirement Analysis, Requirements Definition, Data Modelling10.2021  02.2022 Nuuday, Nuuday Transformation ProgramProject description Nuuday called for an ambitious transformation moving from an outdated technology stack, legacy systems and products towards a more modern, simplified and agile system and offering. Product simplification, the stream Olivia was part of,  was a key prerequisite for the business transformation. It is vital that the transformation program is provided with a solid foundation through a very simple product portfolio, reducing the product complexity, business rules, and IT requirements to reduce the risk of the implementation and later migration.CV  Olivia Essen   2022 Capgemini. All rights reserved. 14"
Olivia_Essen,2,"Role Business AnalystResponsibilities As part of the product simplification, Olivia analyzed the clients product portfolio, assisted in creating a simplified portfolio and the migration mapping, calculated and assessed the financial as well as customer impact of the migration and provided actionable insightand guidance to the client. By implementing an iterative approach which allowed the client to make datadriven decisions, Olivia enabled the client to significantly simplify their product offering.Skills Impact Assessment, Data Analysis, Business Change Management01.2021  06.2021 Nordea, Responsible Investment AnalysisProject description Nordea wanted to incorporate biodiversity into their investment decisions. The challenge was to find a solution that would accurately capture biodiversity performance whileallowing for computational efficiency. Role Data ScientistResponsibilities As part of a thesis project, Olivia analyzed how one can use clustering of time series data as a basis for forecasting to decrease computational complexity while maintaining accurate prediction results. To accomplish this, Olivia extracted relevant data, conducted data preprocessing i.e. descriptive analysis, outlier detection, imputing missing values based on statistical and business input and data validation conducted pattern recognition analysis and unsupervised learning to better assess the data relevance and finding relevant correlation utilized clustering of time series data as a basis for forecasting to decrease computational complexity while maintaining accurate prediction results. Furthermore, implemented a mix of machine learning algorithms to group similar companies based their performance and characteristicsSkills Time Series Modelling, Clustering, Neural Networks, SciPy, Data Analysis05.2020  06.2021 Siteimprove AS, Datadriven Product and Workflow OptimizationProject description Siteimproves goal was to move towards a more datadriven approach in bothdeveloping their new product suite as well as understanding their customer needs. The project entailed understanding the existing software and utilizing it to support product development and customer success in understanding the status quo, pain points, and optimization potential throughdata insights.Role Data AnalystResponsibilities Olivia was responsible for settingup, analyzing and communicating the data collection and insights. This involved collaborating with different stakeholders within the organization to understand their needs, extracting the relevant data from various sources for data analysis, analyzing the data and withdrawing actionable insights and communicating those back tothe client via dashboards and reports. Skills Data Analysis, User Experience Design UX, Product DevelopmentCV  Olivia Essen   2022 Capgemini. All rights reserved. 24"
Olivia_Essen,3,"03.2019  08.2019 Microsof, DevOps Education RollOutProject description Microsoft started an educational initiative to market their Azure service. Olivia took on the project lead role managing the agile rollout, using SCRUM methodologies to align within the project team, overviewing the educational sessions and taking charge of the logistical requirements.Role Project LeadResponsibilities As the project lead, Olivia was in charge of the planning, execution and followup. This included creating budgets, sprint planning and monitoring of identified goals, costs, and time frame.Role  Coordinator and advisory project managerSkills Project Management, Scrum Agile Project ManagementEDUCATION2019  2021 MSc in Sofware Development DesignITUniversity of Copenhagen2013  2017 BSc in Economics and PhilosophyBayreuth UniversityCOURSES07.2020 Database Management01.2021 Data Mining01.2020 Software Engineering01.2021 Big Data Management07.2020 Algorithms and Data Structures07.2020 Introduction to AI09.2020 Applied Information SecurityDiscrete MathematicsCERTIFICATIONS2021 Epic Research Clinical2020 Learning Python10.2021 Cloud Computing Core05.2022 Azure Fundamentals05.2022 ArchiMate 3 PractitionerTECHNICAL SKILLSSciPyJavaMachine LearningCV  Olivia Essen   2022 Capgemini. All rights reserved. 34"
Olivia_Essen,4,SQLData AnalysisBusiness Change ManagementClusteringNeural NetworksTime Series ModellingSolution DesignRequirements SpecificationRequirements DefinitionData ModellingEMPLOYMENTS09.2021   Capgemini09.2019  07.2021 Siteimprove 01.2018  08.2019 Lighthouse Labs09.2017  01.2018 Digital Finance Institute09.2016  08.2017 Tennet TSO LANGUAGESEnglish FluentGerman Mother tongueDanish Basic knowledgeSpanish Basic knowledgeCV  Olivia Essen   2022 Capgemini. All rights reserved. 44
Peter_Damm,1,"Peter DammHead of Public AI  EthicsThe common thread in my work has always been to ensure the best foundation for AI, partly by ensuring that data is used properly and put in context, partly by ensuring that the latest research in AI algorithms is used and by ensuring the right standards, interfaces and platforms that make the technology easily accessible and credible.ENGAGEMENTS01.2021   CBS, Guest LecturerProject description Guest lecturer on Trustworthy AI and Data Ethics in highly regulated marketsSkills Educator01.2021   Aarhus University, Guest LecturerProject description Guest lecturer on Trustworthy AI and Data Ethics in highly regulated marketsSkills Educator06.2020  04.2022 KMD AS, Advisory DirectorApplied Research DirectorProject description Driving the agenda for Trustworthy AI, Digital Twins, Data Spaces, Data Fabric,Synthetic data and Data Ethics in KMD by using a combination of both technology push and market pull for a commercial transformation and by maintaining relationships with NEC Labs around the world and with Danish Universities to find and promote technology matches within the business interests of the KMD group and by identifying businessrelevant research projects and organize KMDs participation in cooperation with BUs and identify businessrelevant publiclyfunded innovation programs, and organize KMDs participation in cooperation with BUs. Support BUs in finding and applying for relevant public grant funding for innovation initiatives.Skills STStrategy  Advisory, Advisory Director, Applied Research Director06.2018  06.2020 KMD AS, Head of Center for Applied AIProject description Heading the new Center for Applied AI in KMD to ensure the right competences, tools, data science pipelines and MLOps platform for business critical solutions and heading KMDs engagement in research projects on AI for the public sector in Denmark incl. EcoKnow.org but also by utilizing the Explainable AI technologies from universities and NEC Labs around the world.Skills Data Science Leader, Head of Data Science, Head of COE, Data science, MLOps10.2021   Aarhus Kommune, Twin4BuildCV  Peter Damm   2022 Capgemini. All rights reserved. 14"
Peter_Damm,2,"Project description Decision support based on AI and digital twins for energy optimization and operation of buildings. Demonstration project funded by the Danish Energy Agency. I am the WP lead on several packages with competencies in relation to digital twins, ontologies, MDM, Context information management and platform.Role Business Analysis  Business Process Functional AnalystResponsibilities In this project several stakeholders have different goals, some purely research oriented, my role was to ensure that the project had a commercial focus and that the outcome of the project could be commercialized according to the market strategy in KMD.Role  Coordinator and advisory project managerResponsibilities I am the Work Package Lead for 2 major work packages, coordinating and advising project members on the overall goal of the work packages.Role Data architect  Data OfficerResponsibilities An essential part of digital twins and context information managementMDM is choosing the right data model and here I did the research needed for defining and finding the right ontology and data model and writing the requirement specification document on data models.Role AI solution architectResponsibilities Both as bid support and for the requirement specification I had the responsibilityfor researching and describing the best architecture for digital twins.Role Bid SupportResponsibilities I contributed to writing the application for funding by the Energy Agency. My expert contribution related to MDM, digital twins and digital twin platforms.02.2021  06.2021 Digital Research Centre Denmark, Explainable AIProject description Explorer project at the Digital Research Centre Denmark DIREC on the challenge that Artificial intelligence systems, in particular systems based on neural networks e.g. as in deep learning, do not offer a humanunderstandable explanation to the answers given. Lack of explanation is not necessarily a problem, e.g. if the correctness of an answer can be easily validated, such as automatic character recognition subsequently validated by a human. However, in some situations, a lack of explanation may pose severe problems, and may even be illegal as it isthe case for governmental decisions. The project purpose was to ensure better support from the AI research communities in DK so that the business potential is secured, as desired by the European Commission. httpsdirec.dktestexplainableaiRole Data ScientistResponsibilities Researching and discussing the stateofart algorithms for explainable AI with AI experts from universities in Denmark, focusing on the ability to provide an explanation for the enduser nontechnical.04.2018  09.2021 Gladsaxe Kommune, Jobcenter, EcoKnowCV  Peter Damm   2022 Capgemini. All rights reserved. 24"
Peter_Damm,3,"Project description The project focus on case management processes in local government. These processes are characterized by having deep consequences for the lives of citizens, having high and unpredictable costs and being subject to complex, changing legal regulations. The basic hypothesisis that the challenges can be overcome by combining adaptive case management technologies based on declarative DCR Graph process notation with machine learning, informed by ethnographical studies of case work in practice and multimodal empirical studies of the modelling of regulations by endusers. KMD and my team had the responsibility for the data science activities with a special focus on explainability.Role  Coordinator and advisory project managerResponsibilities I was the work package lead  for KMD activities. Planning and following up on data science activities.Role AI Solution ArchitectResponsibilities Research and choice of data science and MLOps platform for the project. Azure MLOps was selected.Role SupervisorResponsibilities I acted as external supervisor for the PhD student employed by KMD for this project.Role Data ScientistResponsibilities Researching relevant models to use for AI in the public sectorregulated sector incombination with process mining, explainable AI, graphbased AI and knowledge graphs, RNNs, LSTMs, GNNs and Transformer models. Researching and identifying the right models, but not implementingRole Data ethics advisorResponsibilities This project used personal information from citizens to create machine learning models to recommend access to specific public services. This will be regarded high risk AI in the upcoming AI regulation and hence we had to focus on many ethical challenges including unwanted BIAS.Role Process miningResponsibilities As part of understanding the data in context of processes, I have helped the data scientist in understanding and applying standard process mining techniques, coming from raw application data to a master event log.02.2018  06.2020 KMD AS, Head of DevelopmentProject description Heading software development in agile scrum teams in KMD including development of Speech Recognition  Voice Technologies in KMD. By summer 2019 I focus fully on the Center for Applied AI.Skills Development Methodology, DevOps Leadership, DevOps Foundation09.2020  12.2020 InfinIT, Synthetic dataCV  Peter Damm   2022 Capgemini. All rights reserved. 34"
Peter_Damm,4,"Project description Project on the advantages on creating synthetic data from real data to ensure privacy and unwanted bias in original personal information, especially when data is used for machine learning in regulated sectors.Role AI solution architectResponsibilities My role was to both highlight the challenges in using personal information in machine learning in regulated sectors and also the inverse relationship between privacy versus information quality. The solution presented was transforming the personal information to synthetic data with the same statistical properties and use this for machine learning.EDUCATION1989  1998 BSc in Astrophysics and Computer ScienceAarhus University1999  2002 Master of Industrial Information TechnologyAalborg UniversityCOURSES06.2013 Strategy and Business development in praxisCERTIFICATIONSCertified ScrumMasterEMPLOYMENTS04.2022   Capgemini06.2020  04.2022 KMD01.2021   CBS01.2021   Aarhus University06.2018  06.2020 KMD02.2018  06.2020 KMDLANGUAGESDanish Mother tongueEnglish FluentCV  Peter Damm   2022 Capgemini. All rights reserved. 44"
Prashanthy_Ramanan,1,"Prashanthy RamananConsultantENGAGEMENTS01.2020  07.2020 Unilever, Data and Tools AnalystProject description Gathered requirements from the clients.Designed and developed visualizations and dashboards of sentiment, reviews and review topics oneCommerce websites in PowerBI.Supported in data modelling and analysing requirements.Identified, analysed and interpreted trends or patterns in complex data sets by finding correlationsand visualizing with charts. Aided in the technical development using Dataiku and Python for data gathering.Updated, maintained and tested data in dashboards based on client feedback.Skills DataIku, Python, Power BI, MS Excel09.2020  12.2020 EDF Energy, Information EngineerProject description Wrote technical architecture documentation and data migration specification.Developed and tested the system to transfer data from an Access database into an Azure Database.Simplified and grouped the SQL queries into packages and created data flows in SSIS.Wrote TSQL queries for retrieval of data.Skills gained information architecture, solution architecture, Microsoft Access Database, SQL Server, Data Factory.Skills SSIS package, Information Architecture, Solution Architecture, SQL, Excel macroEDUCATION2015  2019 MSc in Software EngineeringLancaster UniversityCERTIFICATIONSCV  Prashanthy Ramanan   2022 Capgemini. All rights reserved. 12"
Prashanthy_Ramanan,2,10.2021 Microsoft Certified Data Analyst AssociateAzure FundamentalsSKILLSTeam PlayerTeam PlayerSSIS packageInformation ArchitectureSolution ArchitectureExcel macroDataIkuPythonPower BISQLMS ExcelData CleaningVisualizationReports  Dashboard DevelopmentSOFT SKILLSCommunicationTeam MotivationReport WritingDocumentationLANGUAGESEnglish Mother tongueFrench Basic knowledgeTamil Mother tongueDanish Basic knowledgeCV  Prashanthy Ramanan   2022 Capgemini. All rights reserved. 22
Rajitha_Dodda,1,"Rajitha DoddaETL devloperRajitha is an professional ETL Developer with 11 years of experience in banking and contact center area. She has experience in building large scale data warehouse, data migration, and performance optimization. Rajitha is able to understand complex business logic and transform it into database stored procedure and scripts. Rajitha is highly skilled in ETL, SQL, SSIS, Tableau. Other than that, she has strong analytical thinking with a resultoriented working attitude. She was awarded with the Gold Coin award for Wells Fargo top performer and Wells Fargo Conclave award, which is the most prestigious award in the company.ENGAGEMENTS04.2011  09.2021 Wellsfargo, Enterprise Contact Center and Operational StatisticsECCOSProject description ECCOS is a data capture, compilation and storage system for most aspects of the Wells Fargo call centers. Captures data from all stages of the customer contact and brings the parts together to form a comprehensive record of the customer contact. Pulling Contact Center historical and near realtime statistics and distributes the data across various Datamarts and reports.Role ETL DevloperResponsibilities Creation of SSIS packages to pull data from various source systems to ECCOS servers.Creation of SQL stored procedures and functions Creation of SQL Jobs to run the packages.Created utilities to efficiently transfer large data in near realtime with parallel processing and automated data validation.Handling Technology BCP Business Continuity Plan events for seamless fail over and failback mechanism keeping 100 data integrity and high availability.Creation of temporary tools for data reloads.Process near realtime and historical data on customer interaction and generate statistical reports for Contact Centre supervisors.Role Tier3 supportResponsibilities Rajitha has to work on problem tickets and job monitoring.She also  worked on many data reloads , JIRA tickets.she always used to find the root cause of the job failures and worked on fixing issues permanently.she worked on SQL query performance issues ,space issues ,.Net application issues and Tableau report issues etc.she also handled windows patchings and post validations.Role Implementation CV  Rajitha Dodda   2022 Capgemini. All rights reserved. 12"
Rajitha_Dodda,2,"Responsibilities She is part of the implementation team and used to deploy the SSIS packages and SQL objects through Change Management.Deployed SDLC items through Udeploy tool.Skills SQL, Microsoft SQL Server Integration Services SSIS, Hyperion, Tableau, .NET, Microsoft SQL Server Reporting Services SSRSEDUCATION2005  2007 MSc in MathematicsOsmania UniversityCOURSES07.2005 MathematicsLANGUAGESEnglish FluentTelugu Mother tongueCV  Rajitha Dodda   2022 Capgemini. All rights reserved. 22"
Rakesh_Ghosh,1,Rakesh GhoshCV  Rakesh Ghosh   2022 Capgemini. All rights reserved. 11
Rasmus_Rosenmeyer_Poulsen,1,"Rasmus Rosenmeyer PoulsenAssociate ConsultantData visualizations to drive strategic insights, Data exploration deep dives to ensure data quality, Efficient data modellingRasmus has an affinity for anything related to data and has spent 2 years working in Data Analytics. He strives to learn about the newest cutting edge technologies and apply it where he sees opportunities. By combining his strong business mindset with technical expertise within the fields of Data Analytics, Rasmus is eager to understand and solve clients problems. Driven by transforming data into valuable business insights, Rasmus skill set comprises Power BI reporting and dashboarding, as well as SQL database deep dives that ensure data quality and enrichment. Additionally, he is capable of overcoming problems he has never encountered, by having the perseverance of learning things rapidly as well as teaching himself the necessary capabilities to solve such new challenges.Solving challenges is part of Rasmus DNA and he works hard on any challenge that he meets. He is proactive and thrives in dynamic environments with diverse tasks and team members.ENGAGEMENTS09.2020  05.2022 InsurTech Company, International Expansion of Reporting SystemProject description Due to an expressed interest from offices not located in Denmark, Rasmus began to work with the offices based in Germany and Sweden to tailor reporting systems for their individual needs. Each of these markets have their own respective needs, which is why close cooperation was needed to tailor the reporting system to their needs.Role Data AnalystResponsibilities In order to complete this project, Rasmus used his preexisting experience in Power BI to expand the reporting system to the two new countries. Furthermore, data validation, data exploration and data transformation were important parts of extracting new data points to facilitate new KPIs. All of this was accomplished using mainly SSMS and extensive SQL querying toensure data quality and enrichment.03.2019  09.2020 InsurTech Company, Migration of Data Analytics from Legacy System to Microsoft Power BIProject description The company started out with a lowtech solution to facilitate their data analysis needs, but wanted to take their Data Analytics to the next level by using Power BI for salesrelated, but also internal KPI measuring purposes. The aim of the project was to build a complete overhaul of their internal Data Analytics, so their customers would gain trust through sales meetings and to create an internal KPI and measuring tool.CV  Rasmus Rosenmeyer Poulsen   2022 Capgemini. All rights reserved. 13"
Rasmus_Rosenmeyer_Poulsen,2,"Role Data AnalystResponsibilities As a Data Analyst, Rasmus role was to establish a direct reporting system from their Azure SQL Database with visualized dashboards and reports in Power BI. By working closely with the stakeholders internally, he managed to iteratively establish the reporting system from scratch and elevate the data analytics from their outdated excel reports, to Power BI reports that were customized for their respective use cases.EDUCATION2019  2021 MSc in Business Administration and Information SystemsCopenhagen Business School2016  2019 BSc in Business Administration and Information TechnologyCopenhagen Business SchoolCOURSES03.2019 Analyzing and Visualizing data with Power BICERTIFICATIONS06.2022 DP203 Data Engineering on Microsoft Azure05.2022 Azure Fundamentals05.2022 Azure Data FundamentalsSKILLSAPI Data ExtractionData ValidationDATA ANALYTICSPower BIAzure CloudData CleaningPythonSQLDAXAzure SQL databaseData ExplorationData ModellingEMPLOYMENTSCV  Rasmus Rosenmeyer Poulsen   2022 Capgemini. All rights reserved. 23"
Rasmus_Rosenmeyer_Poulsen,3,08.2021  05.2022 Claiton03.2019  08.2021 Claiton06.2017  07.2018 Mrsk TankersLANGUAGESEnglish FluentDanish Mother tongueGerman Basic knowledgeCV  Rasmus Rosenmeyer Poulsen   2022 Capgemini. All rights reserved. 33
Saket_Kumar,1,"Saket KumarSenior consultantSenior Consultant, Cloud Data Engineer, Architect, AccountabilityEnthusiastic Data Engineer with experience in implementing Bigdata and machine learning and solutions in collaboration with Cloud Architect, Subject Matter Experts and Line of business.Expert in handling batch and streaming data using various tools. Proficient in designing and developing secured and costeffective data solutions for clients consist of Data Lake, Data Warehouse, Streaming Analytics and Data Pipelines. Adept in delivering performant solutions using Agile methodology and SAFE.Experienced Azure Associate,with a deep understanding of security, high availability, and big data analytics applications onAzure.Ability to process data in Terrabytes and Petabytes within sustainable time and compute resources with the use of Serverless technology native to Azure. Experienced in building up a cloud account from scratch using infrastructure as code.Key Highlights Experience in handling streaming and batch big data using cloudnative services and on premises infrastructure 5 years of experience in Software Development, Data Warehousing, and Data Analysis Skilled in programming languages like Python, Scala, Java with proficiency in Spark, Kafka, , Data Brick, HDInsight etc. Experienced in working with Agile methodologies on SAFE Developed reusable Terraform modules and ARM Templates for building infrastructure on Azure Skilled in Data Migration for Oracle, Postgres, Teradata, MySQL, Redshift, Snowflake, Glue, Hadoop, etc Highly motivated, resultsoriented, and take pride in being a problem solverENGAGEMENTS06.2019  12.2020 Global Payment Company, Advance Analysis Portal Project description Data Driven insight for Merchant services business groups in Cloud applications , Data Ingested from multiple data sources and transformations on data based on KPIs  and processing in Data Bricks while the reports were delivered using webPortals and mobileapps and Customers access it.Role Cloud Data EngineerResponsibilities Data ingestion from different source system  into cloud platform Data Transformation based on KPIs in Azure Data Bricks using python Automated end to end pipeline in Azure Data Factory Created business requirement documents and mappings for the solutions in project confluence pageRole Cloud ArchitectResponsibilities Designed and developed a faulttolerant architecture for ingesting dataDesigned Reporting layers in downstream applications to maintain high availability of Views for webportals and mobile apps Closely worked with Business users to outline the new analytical cases providing different KPIsOptimized the complete solutions by integrating new tools for reporting purpose with NOSQL.Skills Azure Data Architecture, Azure Databricks, Azure Data Factory, Python, Scala, SQL AzureCV  Saket Kumar   2022 Capgemini. All rights reserved. 13"
Saket_Kumar,2,"07.2017  02.2019 JCI, Customer Intelligence Project description Transformed onpremises services onto cloud and  migration for all on premises applications to azure cloud applications. Derive KPIs to understand customers enabling leaders to take decisions on business steering according to accurate, relevant, and timely data.Role Data EngineerResponsibilities Ingested data from various data sources into Azure HDInsight Hadoop platform.Created mappings and transformations and stored in  Hive database and those tables were movedin Azure Sqldw with Data Factory.Cubes were created in Analysis services and  with DAX queries reporting done through PowerBI.Worked with SIT and production Deployment activitiesOptimized Spark jobs to run efficientlyRole Data ArchitectResponsibilities Did reverse engineering of onpremises data flowsDesigned Architecture to ingest and transform big data using microbatches and batches on AZURE using cloudnative services.Closely working with stake holders to create KPIs for reporting with customersDesigned and developed  Data cleansing and quality framework along with Audit , Balance and control framework for data flow.Skills Azure Data Factory, DAX, Azure HDInsight, SSAS, Spark, Apache Hive02.2016  07.2017 Hewlett P, EDW Migration Project description The project entails at migrating legacy database to Bigdata platform for all Business units .The data ingestion and processing on premise cluster for historical data and movedlast 2 years of data from onprem to Azure cloud data base for reporting purposes Role Data EngineerResponsibilities Completing Fitgap analysis on various existing data warehousing applicationsDeveloped Reverse engineering tool to understand the mapping and flows of existing jobs in legacy databaseCreated ETL jobs in Talend bigdata studioMoving Data from onprem cluster to Azure sqldw using data factory and polybase Designed Audit,Balancing and control framewrok to monitor the ETL job flows Skills Talend, Apache Hive, Microsoft Power BI, Python02.2012  01.2016 Best Buy , Data Lake creation Project description Multiple projects were implemented for creation of data lake in Hadoop and revamp of existing data platforms on new technologies .enhancement of Oracle tool Oracle Secure Global Desktop. Previously there was not a common platform to access LinuxUnixMacPAC platforms.Role Data EngineerCV  Saket Kumar   2022 Capgemini. All rights reserved. 23"
Saket_Kumar,3,"Responsibilities Loading from Disparate Datasets and Development of Hadoop Map reduce programs in HivePerforming analysis of vast data stored and uncovers insights.Sharing Daily Reports Generated with Clients on daily basis in Tableau.Skills Oracle, Tableau, MapReduce, Business AnalysisEDUCATION2007  2011 BSc in Mechanical EngineeringNagpur UniversityCOURSES01.2020 Serverless Machine Learning with Tensorflow on Google Cloud PlatformFRAMEWORKSCLOUDAzure Data ArchitectureAzure Data FactoryEMPLOYMENTS02.2012  01.2016 Infosys Limited02.2016  07.2017 Deloitte Consulting 07.2017  02.2019 Accenture Services02.2019  12.2020 Larsen  Toubro InfotechLANGUAGESEnglish FluentHindi Mother tongueCV  Saket Kumar   2022 Capgemini. All rights reserved. 33"
Samay_Mir,1,"Samay MirPrinciple Data Operating Model , Cloud Azure, AWS, ETL migration to cloud , Machine learning and deep learning, Data Engineering , Leading technical and nontechnical teams A dynamic handson analytics leader who has extensive experience in creating unified delivery platform for big data projects, developed and implemented operating model for data governance, analytics and data engineering. An handson practitioner who has implemented machine learning and deep learning algorithms in production. A trusted advisor to senior executive team focused on generating revenue, optimizing assets, increasing productivity and improving cost.   ENGAGEMENTS10.2020   Insurance Company, Migrating informatica ETL from onpremise to Azure Cloud Project description The client wishes to migrate their onprem DWH to Azure cloud. The migration will not be a simple liftshift, but a rewriting and optimizing with new ETLELT tools databricks, optimized storage and embracement of analytics. The platform must support the corporations data needs on continuous basis.  Role Tech leadResponsibilities Created the technical roadmap for ETL migration. A trusted advisor to the client with regards to data ingestion, data processing, ETL optimization, building framework and owned the delivery of onsite and nearshore teams. Skills Azure, ETL  informatics, Azure Data Factory, Azure Databricks, Migration Framework10.2019  04.2020 Multinational Enginnering Company , IoT Process Optimization Project description Improve product utilization and enable valueadded services by providing remote monitoring, predictive maintenance, and automated support before equipment fails. Combining cloud platform, machine learning algorithms and interactive dashboards through apps to provide realtime insights regardless of operators location.Role Analytics ExpertResponsibilities Developed the IoT architecture by ingesting data from devices to Azure cloud platform. Supported the data cleaning and processing process. Actively advising and building machine learning algorithms to predict equipment failure. Owned the delivery of the End2End CV  Samay Mir   2022 Capgemini. All rights reserved. 13"
Samay_Mir,2,"implementation of the IoT setup and process data and algorithms and visualized in realtime the prediction in apps.  Skills IoT, Azure, Azure SQL, Python Notebook, Power BI, R Programming Language03.2019  07.2019 Global Furniture Manufacturer, Marketing Analytics Project description Clients wanted to fulfilling needs of their consumers by analyzing and understanding their behavior through   market basket and crossshopping analysis from transaction database file. Furthermore, the client ambition was to develop complex business problems, including customer behavioral segmentation and media mix modeling by applying machine learning algorithms for factbased decision making. Role Analytics ExpertResponsibilities Acted as single point of contact for marketings advanced analytic needs. Createdand supervised analytics modeling building and helping client to make fact based decisions based on the algorithm output. Initiated a framework for a global rollout of the solution. Skills R Programming Language, Market Basket Analysis, Marketing Mix Modeling, Data driven decision making framework01.2019  03.2019 Global Biotech Company, Chemical Yield optmization Project description Extract realtime data from chemical production sites fermentation, recovery,granulation and correlate it with various master data and derived chemical formulas to better predict the yield using machine learning algorithms on cloud. Role Principle and Analytics ExpertResponsibilities Design the architecture, implemented data ingestion, staging, storage. Advised on machine learning algorithm creation and strategic advisor to clients leadership team. Skills AWS, ETL, SQL, Machine Learning, Data Architecture, Data Cleaning, VisualizationEDUCATION2009  2010 MSc in Investment and EconometricsLondon South Bank UniversityCLOUDAzure Data FactoryTOOLSData ArchitectureCV  Samay Mir   2022 Capgemini. All rights reserved. 23"
Samay_Mir,3,FRAMEWORKSData driven decision making frameworkMigration FrameworkLANGUAGESDanishEnglishCV  Samay Mir   2022 Capgemini. All rights reserved. 33
Sara_Vera_Marjanovi_,1,"Sara Vera MarjanoviData ScientistData scientistSara is a driven data scientist with a particular specialty in Machine Learning, Deep learning, and Natural Language Processing. She has endtoend experience with wrangling a wide variety of different data sources from free text to biometric data to create either simple e.g. clustering, regression and complex models e.g. Generative Adversarial Models in the production pipeline. Therefore, she is wellversed in ideation, data collection, data wrangling and exploration, as well as model development and troubleshooting and is comfortable with Python especially the libraries Numpy, Pandas, Tensorflow, Pytorch as well as SQL, R, and Azure DevOps.Within her model creation and data exploration, Sara takes special care to limit bias within the dataset and model output, and to ensure interpretability of the results. She is diligent and conscientious with her data storytelling and data visualization, making her a skilled communicator and heads into each project with energy and enthusiasm. She is capable of collaborating within a team as well as leading assignments even on unfamiliar terrain as she is a quick and independent learner.ENGAGEMENTS10.2021  06.2022 Mental Health Consulting Firm, Personalized InsightsProject description The client aimed to provide their endclients with personalized understandingof their workplace stressors. Biometric data from wearable Garmin devices was combined with Outlook calendar data to find correlations and predictive features of high stress personalized to each endclient.Role AI EngineerResponsibilities Sara solely developed the final solution for this project. She wrangled biometric, free text and boolean data from the various data sources to select relevant features for the model.She implemented an automated notifications system on the clients app to notify endclients of personalized correlations to high stress.Skills Python, Azure Functions, Feature Engineering, Digital Signal Processing, API Integration, SQL, Natural Language Processing, Azure Cloud10.2021  06.2022 Mental Health Consulting Firm, Insights ReportsProject description This client provided a mental healthrelated consulting services to their endclients this service was supplemented with regular reports showing the progression of the program and its effect on various data points e.g. measured stress levels, recorded sleep duration, reported feedback, app usage.CV  Sara Vera Marjanovi   2022 Capgemini. All rights reserved. 16"
Sara_Vera_Marjanovi_,2,"Role Data AnalystResponsibilities Sara designed and regularly created a monthly report for the client to use and present to endclients. She generated easily understood data visualizations and highlighted key figures and outliers to guide conversation between the client and endclient.Role Product developerResponsibilities Sara optimized the quality of the monthly reports for the endclient utilizing approaches from design thinking.  She created and tested prototypes using both user interviews and nonattended user testing.  She used both quantatitive and qualitative methods to analyze theresults of these tests to drive further development. Skills Data Visualization, Interdiciplinary Communication, Reporting  Dashboards, Storytelling, Python, Design Thinking, Product Testing, User Interviewing, Figma, Qualitative and Quantitative Methods, NVivo, Business Intelligence, SQL10.2021  06.2022 Mental Health Consulting Firm, Customer analyticsProject description The client aimed to increase endclient usage of various features within their application. Customer behaviour, measured in events across the clients various platforms, was tracked and analyzed across segments to measure and drive engagement.Role Data AnalystResponsibilities Sara assessed and reported customer engagement via funnels, trends, user flows, and AB tests. She determined appropriate user segments and helped the client understandendclient behavior by creating an interactive dashboard. She also handcreated reports for the client for special events e.g. feature launches, AB testingSkills Reporting  Dashboards, Data Analytics, Customer Data Analytics, AB Testing, Business Intelligence, SQL01.2021  09.2021 The University of Copenhagen, Gender Bias in Political DiscussionProject description This project investigated how gender biases appear in political discussion. 10 million Reddit comments about politicians were extracted from 2 years of data. In the data exploration stage, various statistical methods were used to assess for gender disparities with consideration of other confounding variables. Finally, a model was created to identify the subject gender using only biases.Role Data ScientistResponsibilities In addition to collecting 10 million comments from Reddit referring to public politicians, Sara designed and executed all methods used to outline gender biases in the discussion related to politician coverage, relation, nomination, sentiment, and descriptor use.  In these investigations, she utilized relevant lexica and pretrained models. Given disparities in the datasets distribution, Sara applied nonparametric methods and modified traditional techniques to limit confounds within the data.Role AI ArchitectCV  Sara Vera Marjanovi   2022 Capgemini. All rights reserved. 26"
Sara_Vera_Marjanovi_,3,"Responsibilities To showcase the extent of these linguistic biases, Sara trained a model to be ableto predict the subject gender of a comment. To ensure this model worked on the biases, she removed all overt indicators of gender, and used a GANlike training method to deprioritize covert indicators of the comments subject but not their gender. To showcase this models ability to detect bias, she then used transfer learning to test its ability on sexist datasets.Skills Sentiment Analysis, Network Analysis, Graph Theory, Pointwise Mutual Information, Information Theory, Data Collection, Generative Adversarial Networks, Deep Learning, Natural Language Processing, LSTM, Transfer Learning, Big Data, Academic Research, Academic Writing03.2020  09.2021 The HOPE Project, Misinformation TransmissionProject description In this project, teams from multiple universities collaborated to assess how the transmission of coronavirusrelated misinformation on Twitter differed in dynamics from the transmission of other kinds of misinformation.Role Data ScientistResponsibilities From the collected Twitter data, Sara constructed graphs representing the transmission of retweets following time, with consideration of Twitter account following relationships. She collaborated with other researchers to find differences of interest in the graph features between misinformation and information graphs.Skills Directed Acyclic Graphs DAGs, Graph Theory, Network analysis  design, Modelling Graphs09.2020  03.2021 The HOPE Project, Facemask SentimentsProject description In coordination with the Danish Public Health Authority, a team investigated how Facebook users interacted with the Danish Public Health Authority with questions about facemasks. Quantitative in Python and qualitative in NVivo analyses assessed changes in citizenand the health authoritys sentiment over time.Role Data ScientistResponsibilities Sara conducted the quantitative analyses to understand the changes in sentiment in both the original posts and the associated comments in the original Danish, with consideration of emoji use. These results were then confirmed and augmented with indepth qualitative analyses by her collaborators. She also created the necessary visualizations and statistical calculations to assess the significance of these changes.Skills Python, Sentiment Analysis09.2020  12.2020 University of Copenhagen, Introduction to Social Data ScienceProject description This course introduced first semester students in the MSc Social Data Science program to Python programming and relevant data science skills for the program, as many came from social science backgrounds without technical experience.Role Teaching AssistantResponsibilities Sara provided regular, simplified and relevant, tutorials for python programming CV  Sara Vera Marjanovi   2022 Capgemini. All rights reserved. 36"
Sara_Vera_Marjanovi_,4,"lessons in Jupyter Notebook. She also helped students with their independent projects and aided regular quantitative analysis workshops to introduce students to the statistical techniques.Skills Jupyter Notebooks, Data Scraping, Twitter API, Twitter Streaming API, Web Scraping, Teaching, Quantitative Analysis, Python, Data Science, Natural Language Processing, Pyhton Natural Language Processing library Nltk module, Sentiment Analysis, Interdiciplinary Communication04.2020  06.2020 Large American Retailer, M5 ForecastingProject description This project aimed to predict item sales as organized by item type at stores in various locations for a 28day time period.Role Data ScientistResponsibilities Sara collaborated in a team of other AI engineers to create the most accurate features and model to forecast the expected sales. Skills Time Series Modelling, Convolutional Neural Network, Gradient Boosted Machines GBMs, Team Collaboration, Forecasting03.2020  12.2021 The HOPE Project, Misinformation Response and NarrativesProject description In this project, teams from multiple universities collaborated to find themes in popular coronavirus misinformation narratives on Danish Twitter and assess patterns in how others respond to this misinformation.Role StatisticianResponsibilities Sara used text analysis to identify tweets relevant to the preselected misinformation narratives. After these tweets were annotated by student volunteers, she performed the statistical analyses on the results.Role Project communicatorResponsibilities In addition to writing the article used to disseminate the findings of this article, Sara was also responsible for all external communication in the conduction of the research. This involved communicating with other teams to legally acquire data and providing regular reports to the other teams involved in the project.Skills Communication, Project Coordination, Academic Research, Academic Writing, Statistical Analysis, Text Analysis09.2015  06.2016 McGill University, Estrogen on EOD SignalsProject description This investigation assessed the effect of hormone administration on the electronic organ discharge EOD of juvenile weakly electric fish, B. gauderio, as measured by 2 electrodes situated in the tank.Role Data ScientistResponsibilities Sara recorded the electronic activity of the signal using electrodes isolated CV  Sara Vera Marjanovi   2022 Capgemini. All rights reserved. 46"
Sara_Vera_Marjanovi_,5,"features of interest in the signals using MATLAB. She then assessed for statistically significant changes in the signal given hormonal administration.Skills signal processing, MATLABEDUCATION2019  2022 MSc in IT and CognitionUniversity of Copenhagen2012  2016 BSc in NeuroscienceMcGillSKILLSBig DataData VisualizationNatural Language ProcessingSentiment AnalysisAzure FunctionsFeature EngineeringDigital Signal ProcessingAPI IntegrationDesign ThinkingUsability TestingProduct TestingUser InterviewingQualitative and Quantitative MethodsData AnalyticsAB TestingBusiness IntelligenceData CollectionReport WritingJupyter NotebooksTwitter Streaming APITeachingQuantitative AnalysisData SciencePyhton Natural Language Processing library Nltk moduleLSTMImage ProcessingAcademic ResearchConvolutional Neural NetworkTeam CollaborationForecastingNetwork analysis  designTest analysisLogistic RegressionData ExplorationData CleaningData TransformationMachine LearningCV  Sara Vera Marjanovi   2022 Capgemini. All rights reserved. 56"
Sara_Vera_Marjanovi_,6,Outlier DetectionEMPLOYMENTS10.2021  06.2022 FocusWRX AS03.2020  03.2022 The University of Copenhagen10.2016  09.2019 The University of British ColumbiaLANGUAGESEnglish Mother tongueDanish Good CommandBosnian FluentFrench Good CommandCV  Sara Vera Marjanovi   2022 Capgemini. All rights reserved. 66
Shabina_Bibi,1,Shabina BibiOperation LeadEDUCATION2010  2013 MSc in International BusinessCopenhagen Business SchoolLANGUAGESDanish Mother tongueEnglish Good CommandHindi FluentUrdu FluentCV  Shabina Bibi   2022 Capgemini. All rights reserved. 11
Shari_Kizhakke_Neelamana,1,"Shari Kizhakke NeelamanaAssociate consultantAn astute and competent graduate Engineering professional from Mahatma Gandhi University, India with excellent academic in Engineering background. Persuasive communicator with good analytical, logical and multitasking skills. Possess strong interpersonal communication skills and knowledge of structured project methodology, highly ethical, trustworthy and discreet. Currently staying in Copenhagen.ENGAGEMENTS01.2015  09.2017 The Hartford, PLDWProject description Me and my team were responsible for the creation , maintenance and support of the data warehousing section using SQL , ETL tools like informatica and SSIS. Creating reports for the customers using POWER BI for their analysis. Also answering customer adhoc questions. Followed Agile methodology in the project.Role Business AnalystResponsibilities 1Gathering business data and mapping those into logical enterprise model. 2Performed data extraction, data mapping and data profiling using various tools3Analyzing the customer requirements and translating the requirement into design4Performing impact analysis, design preparation, peer code review, test case preparation, unit testing  releasing5Formulating technical design document, test case document6Recommending appropriate as well as technologybased solutions for enhancing functional efficiency of the organization and achieving business excellenceRole ETL DeveloperResponsibilities 1Data warehouse management using ETL tools like informatica  SSIS2Developing SQL Scripts as per the customer requirement Formulating functions, procedures, packages  triggers as per the requirement 3Data modeling using Toad software4Autosys JIL scripts for new box jobs 5Implementing UNIX scripts 6Experience in different data format like JSON and XMLCV  Shari Kizhakke Neelamana   2022 Capgemini. All rights reserved. 12"
Shari_Kizhakke_Neelamana,2,"EDUCATION2010  2014 BSc in Engineering and TechnologyMahatma Gandhi UniversityCOURSESAzure Fundamentals AZ900Microsoft Azure Data Fundamentals DP900Microsoft Azure Data Engineering DP203CERTIFICATIONS01.2022 Azure Fundamentals03.2022 DP203 Data Engineering on Microsoft Azure03.2022 Azure Data FundamentalsSKILLSMicrosoft SQL Server Integration Services SSISSQLConsulting  Business Analysis, RequirementsData ModellingEMPLOYMENTS01.2015  08.2017 Cognizant LANGUAGESEnglish FluentDanish Good CommandCV  Shari Kizhakke Neelamana   2022 Capgemini. All rights reserved. 22"
Shivam_Singh,1,"Shivam SinghConsultantShivam is a Machine learning engineer with 7 years of experience and expertise in turning data into insights and actionable strategies. Shivam can lead and develop teams of data scientists, analysts, and engineers. Adept at working with business stakeholders to identify opportunities and solve complex business problems. Shivam has been working across many industries Retail, CPG, Media, Finance, insurance, public systems, and AutomobileENGAGEMENTS01.2018   Volvo, ModelOpsProject description 1. Developed scalable, modular, reusable container architecture to deploy AIML applications in private andor public cloud environmentBuilt overall structure of the data pipeline and ML pipeline through Kubernetes, Kubeflow, MLflow,and Airflow can be designed and implemented at the production level.2. Worked with the Data Scientist to design and implement training and deployment approaches for data Science and machine learning model components.3. Developed and delivered a CICD pipeline for ML projects4. Developed tools and libraries that will enable rapid and scalable development5. Successfully devised and implemented strategies to ensure ML heavy systems operate with highaccuracy in Production and adapt to discovered needs.6. Managed the infrastructure and pipelines needed to bring models and code into production.7. Researched and implement best practices to improve existing machine learning infrastructure.8. Collaborated with Lead data engineers, application programmers, and data scientistsRole Machine Learning EngineerSkills MLFlow, Kubernetes, Apache Airflow, Python, R Programming Language, SAS, SQL, Tableau, MATLAB, JavaScript, TensorFlow, TensorFlow Extended TFX, Keras, PyTorch, Sklearn, Pyhton Natural Language Processing library Nltk module, OpenCV, Numpy, Pandas, Prophet, Spacy, Xgboost, PyMC3, pgmpy, bnlearn, pmdarima, Matplotlib, Statsmodels, Plotly, Seaborn, Google Kubeflow, Spark, Azure, AWS, GCP Cloud AI, Azure Databricks, GIT, GitOps, Azure DevOps, Agile Scrum01.2018  10.2021 Fractal AIProject description Invoice delay prediction Developed  Deployed Machine learning solution to identify the purchase order with risk of getting delayed in processing for Procure toPay process resulting 6 improvement in Payment on Time kpi.Cashflow forecasting Implemented time series forecasting models to predict amount of cash and cash equivalents entering and leaving company at component level resulting better visibility to manages its cash position how well the company generates cash to pay its debt obligations and fund its operating expenses.OCR Developed OCR solution for health technology company to extract information from Invoicesreceived by finance department Procuretopay.CV  Shivam Singh   2022 Capgemini. All rights reserved. 13"
Shivam_Singh,2,"Market Mix Modeling Performed Market Mix Modeling to quantitatively estimate the effectiveness of various marketing elements and developed models to quantify marketing and pricing strategies for fortune 500 companies. Model optimization and performance improvement is performed by resolving the issues of Multicollinearity Adstocking, Saturation, Penalized Regression, Ridge VIFs, Bayesian Penalized Regression, Interactions PHacking, Bayesian Belief Networks Continuous  Discrete, Endogeneity Instrumental Variables  Latent Instrumental Variables and Cannibalization three stage least squares ModelRole Senior Data Scientist02.2018  11.2018 Quantiphi Inc., Athenas OwlProject description FIFA world cup 2018Detection of FIFA partners, sponsors  national supporters at an instance during matches  leveraging the data to identify the screen presence of brand during entire match  high points. Built case study for FIFA Partnerssponsors based on the multiple factors that affects the promotion screen time of the brands during the FIFA world cup 2018 Built multiclass entity detection models for detecting the logo screen time and locations for different brandsGolf ChannelContent curation by creating tags  suggestion based on golfers profile to acknowledge golfers problem Built multiclass entity detection, locale classification  face detection models to generate meta data tags for content curation Keyword detection to classify instructional content to suggest better content to acknowledge golfers problemRole Data Scientist07.2015  01.2018 Equifax Inc.Project description Customer segmentation schemes and profiling Leverage Customer demographic and purchase data to build multipleTypes of shopper cluster based on their recency, frequency, Sales trends over time, Average order gap, Headroom space category preferenceStoreGeo Clustering Clustering of stores to identify causes of dormancy of stores and design storespecific campaign or clusterspecific campaigns contributing to increase in Incremental revenue w.r.t last financial year. Geomatic store clustering for measuring the impact of competition on business  finding the area of opportunity based on catchment analysisCLTV Customer lifetime value Model Model that predicts the probability of shoppers shifting from existing stage toother defined stages helped to identify about to churn shopper  helped to extend lifetime for 5of churning baseBrochure Optimization Logistic Regression to understand the importance of different factors in influencing the sales ofSKUcategory pertaining to brochure  improving the process of product selection for the brochure and display ofbrochure by measuring sales uplift of SKUCategoryCV  Shivam Singh   2022 Capgemini. All rights reserved. 23"
Shivam_Singh,3,"Business reporting Automation  generation of all reports that provides the overall view, surge ordormancy inbusinessMarketing Campaigns Driving marketing campaigns by targeting shoppers based on shoppers profiles. Tracking andImproving Campaign performance  strategizing on multiple campaign models directly with the clients, generating therevenue of multi million AED.Role ConsultantEDUCATIONB. Tech. in Computer Science  Information TechnologyDr. A.P.J. Abdul Kalam Technical UniversityCERTIFICATIONSAzure Solutions Architect ExpertAzure AI Engineer AssociateMachine Learning Engineering for Production MLOpsDeep Learning SpecializationLANGUAGESEnglish Good CommandHindi Mother tongueCV  Shivam Singh   2022 Capgemini. All rights reserved. 33"
Simon_Troelsg_rd,1,"Simon TroelsgrdData EngineerApplied mathematics, Machine learningAs an civil engineer, in applied mathematics from DTU, Simon has a broad knowledge about applied mathematics and computer science. He can contribute with programming skills in PythonMatlabCR combined with an analytical mindset for solving mathematical problems or gaining new insights. He has previously worked within technical areas such as algorithms and data structures, optimization problems, machine learning, image analysis,  statistics, differential equations,numerical methods and mathematical modelling in general. Simon is a responsible person and enjoy collaboration. ENGAGEMENTS09.2021  01.2022 Zero North, Route planning for vessels using AIS dataProject description Master thesis at DTU in collaboration with Zero North A shipping company. It was on graph modelling and algorithms for best route for vessels using solemnly AIS data. Role Data ScientistResponsibilities Simon worked on the project and shaped it together with his supervisors and didthe implementations and the data engineering part.Skills Python, Writing Documentation, Report Writing, Data Modelling, Modelling Graphs09.2021  09.2021 Copenhagen Adventure Sport, Part of organizational team for an adventure race Eagle RaceProject description Simon was part of the team organizing an adventure race for 150 people withthree different distances. Role Project CoordinatorResponsibilities Simon helped organized and coordinated the adventure race Eagle race. Skills Planning and Organising01.2018  07.2019 DTU, Teaching AssistantProject description Simon taught first year students in discrete mathematics and corrected homework assignments.Role Teaching Assistant CV  Simon Troelsgrd   2022 Capgemini. All rights reserved. 13"
Simon_Troelsg_rd,2,"Responsibilities Simon taught first year students in discrete mathematics and corrected homework assignments.Skills Communication, TeachingEDUCATION2020  2022 MSc Mathematical modelling and computationTechnical University of Denmark DTU2016  2020 BSc Mathematics and technologyTechnical University of Denmark DTUCOURSESAlgorithms and data structures 212.2020 Machine learning for Signal Processing06.2021 Convex optimization01.2021 High performance computingDiscrete MathematicsCERTIFICATIONS09.2022 Azure Fundamentals AZ90009.2022 Azure Data Fundamentals DP900SKILLSTeachingReport WritingData ModellingOptimization modelsSQLWriting DocumentationCommunicationPROGRAMMING LANGUAGESPythonMATLABCREMPLOYMENTSCV  Simon Troelsgrd   2022 Capgemini. All rights reserved. 23"
Simon_Troelsg_rd,3,01.2018  07.2019 DTU09.2021   Copenhagen Adventure SportLANGUAGESDanish Mother tongueEnglish FluentGerman Basic knowledgeCV  Simon Troelsgrd   2022 Capgemini. All rights reserved. 33
Steen_Ostersen,1,"Steen OstersenConsultant Data and InsightExperienced Information Technology Specialist with a demonstrated history of working in the both the private and government administration industry. Experince with both Oracle and SQL Server Databases, Data Warehousing,Master data. Strong information technology professional with a Master IT focused on Databases, Datawarehouse and Data miningfrom Aalborg UniversityENGAGEMENTS01.2022   Nortura Norway, NorturaProject description Experience with   SSAS   ,SQL  Server  ,Dimensional modeling ,SISS ,Data warehouse11.2019  01.2022 Aarhus MunicipalityProject description SQL Server  ,SISS ,SASS , PowerShell  ,API ,  Reporting Services ,Azure09.2018  11.2019 Aarhus UniversityProject description SQL server   ,SSAS,  Powershell ,DBA  ,Azure01.2015  01.2018 Copenhagen municipalityProject description ETL , Data warehouse  ,Power BI , OBIIE , Warehouse Builder Dimension modeling , Oracle04.2007  09.2014 BestsellerProject description Database  ,Performance   . Data warehouse   ,ERP  ,Deployment ,Oracle  .SQL Server12.1999  12.2006 Arla Food  IngredientsProject description Dairy Engineering, Project management , Product  development,  Data analysis   , Multivariate analysis  ,IT , CV  Steen Ostersen   2022 Capgemini. All rights reserved. 13"
Steen_Ostersen,2,"12.1991  12.1999 Research  Center FoulomProject description Data analysis, SAS ,IT  , statistics , Dairy engineer04.1988  12.1999 APV PasilacProject description Project management , Data analysis  ,Dairy engineering02.1987  04.1988 Arla FoodsProject description Dairy Engineering  ,IT  ,Production , Quality ControlEDUCATION2017  2018 Master IT  introduction to data scienceAalborg University2014  2015 Master it datawarehouse ,OLAP and dataminingAalborg University2009  2010 IT Master Reliable software Test, Aarhus Universitet ,AarhusAarhus University2007  2008 MSc in DatabasesAalborg University1994  1996 Ph D. kurser basal og multivariate statistik ,Landbohjskolen ,CopenhagenUniversity of Copenhagen1981  1986 MSc in Dairy EngineerUniversity of CopenhagenCOURSES08.2022 Advanced DAX for Microsoft Power BI Desktop06.2022  Microsoft Power BI Certification DA100  PL300 Exam Prep02.2022 Securing SSAS Models01.2022 Building Multidimensional Models in SSAS01.2022 Managing SSAS Models01.2021 Microsoft Power BI  Up  Running With Power BI Service 20212021 Microsoft Azure Data Engineering DP2032021 Azure Databricks and Spark Core For Data EngineersPythonSQL2021 Microsoft Azure Data Engineering DP2032021 Azure SQL Server for Beginners Part 1 of 22021 Azure SQL Server for Beginners Part 2 of 22020 Azure Data Engineer Technologies for Beginners Bundle2019 Mastering SQL Server 2016 Integration Services SSISPart 22019 Microsoft Azure Solutions Exam 70533  9 Course BundleCV  Steen Ostersen   2022 Capgemini. All rights reserved. 23"
Steen_Ostersen,3,04.2018 Microsoft Power BI  The Practical Guide2018 SQL Server Administration Part 32018 Mastering SQL Server 2016 Integrating Services SISS2018 Microsoft Power BI  A Complete Introduction2018 Spark and Python for Big Data with PySpark2017 SQL Server Administration Part 22017 SQL Server Administration Part 12017 DAT207x Analyzing and Visualizing Data With Power BI2017 DAT225x Developing a SQL Server Analysis Services Tabular Data Model2017 SQL Server Reporting Services Part 22016 SQL Server Reporting Services Part 1CERTIFICATIONS05.2022 Azure Database Administrator Associate02.2022 Azure Data Engineer Associate01.2022 Azure Fundamentals06.2021 Azure Data Fundamentals04.2022 Azure AI FundamentalsMICROSOFT  BI AND  SQL SERVER DATABASEMicrosoft SQL Server Transact SQL TSQLSQL ServerPower BIData ModellingAzurePowershell ScriptingData MiningSQL Server Integration Services  SSISSQL Server Analysis Services  SSASEMPLOYMENTS2022   Capgemini2019  2022 Aarhus Municipality2018  2019 Aarhus University2015  2018 Copenhagen  Municipality2007  2014 Bestseller1998  2006 Arla Foods Ingrediens1991  1997 Reseach Center Foulom1988  1990 APV Pasilac1987  1988 ArlaLANGUAGESDanish FluentEnglish FluentCV  Steen Ostersen   2022 Capgemini. All rights reserved. 33
S_ren_Andersen,1,Sren AndersenCV  Sren Andersen   2022 Capgemini. All rights reserved. 11
Theresa_Claudia_Eschelbach,1,"Theresa Claudia EschelbachAssociate ConsultantWith a background in Data Science, Business Administration and Computer Science, Theresa has a broad knowledge in Data Engineering, Machine Learning, Deep Learning, Natural Language Processing and Visual Analytics.She has strong programming skills in Python, and R and is experienced in  data cleaning, data exploration, data engineering, neural networks, classification and stateoftheart NLP tools such as transformer architectures.She uses her analytical mindset and solution oriented thinking in combination with these technical qualifications to deliver highquality solutions to her clients problems.ENGAGEMENTS01.2021  04.2022 Novo Nordisk AS, Supply Chain and Capacity AnalysisProject description The project aimed at analysing the onsite supply chain and recurring capacity issues. During the project, Theresa was the lead analyst and managed in close collaboration with factories and supply chain teams to identify bottlenecks, and proposed solution approaches basedon historical data and an ideal environment simulation. Role Data AnalystResponsibilities As data analyst in this project, Theresas tasks included  data collection and aggregation data exploration data analysis presentation of bottlenecks and recommendationsSkills Data Exploration, Data Collection, Data Transformation, Programming, Python, Alteryx, Manufacturing Processes, Chemicals07.2022  09.2022 Novo Nordisk AS, Technical Warehouse Database and KPI VisualizationProject description The technical warehouse of Novo Nordisk wanted to create a holistic database of all material movement in and out of the warehouse and visualize important KPIs on non slow and fastmovers.Role Data EngineerResponsibilities Theresa was mainly responsible for data collection, aggregation, cleaning and thefinal dataset creation. This was done using various internal databases, SQL and Alteryx. Role Business AnalystResponsibilities Development and design of a comprehensive dashboard including all relevant CV  Theresa Claudia Eschelbach   2022 Capgemini. All rights reserved. 12"
Theresa_Claudia_Eschelbach,2,"KPIs for various materials and movement types within both selling and purchasing activities.Skills SQL, Alteryx, Alteryx Connect, Alteryx Server, Tableau, Reporting  Dashboards, Material Management, Supply ChainEDUCATION2016  2020 BSc in Business Administration and InformaticsTechnical University of Munich TUM2020  2022 MSc Data Science  Business AdministrationCopenhagen Business SchoolCOURSESDatafication Regulation, Governance, Security, Privacy and EthicsNatural Language Processing and Text AnalyticsSKILLSPythonAlteryxMarket analysisSQLMachine LearningJavaScriptPandasDataData ExplorationData CollectionData TransformationAlteryx ConnectAlteryx ServerEMPLOYMENTS02.2018  08.2018 Infineon Technologies07.2019  03.2020 Munich Re11.2020  05.2021 TwentyThree05.2021  09.2022 Novo NordiskLANGUAGESGerman Mother tongueEnglish FluentDanish Basic knowledgeSwedish Basic knowledgeCV  Theresa Claudia Eschelbach   2022 Capgemini. All rights reserved. 22"
Ting_Yu__Terry__Kuo,1,"TingYu Terry KuoData EngineerTerry has working experience in both a fastpaced business environment and academic research. He is able to deploy strictscientific methods under business conditions. Terry has fundamental knowledge in the cloud environment and is certified in Azure AZ900. He has strong analytical thinking with a resultoriented working style. He is skilled in the data pipeline, analysis, and machine learning, including Python, Numpy, Pandas, Tensorflow, SQL, BigQuery.ENGAGEMENTS02.2021  08.2021 Neurons Inc., Audiovisual saliency mapProject description Master thesis cooperation with Neurons Inc. The project aims to improve the currently running model in Neurons Inc. by incorporating multimodality information. Role Machine Learning InternResponsibilities  Improved the existing model by adding audio extraction capabilities Data preprocessing on large scale video dataset Built and optimized ML pipeline with Python, TensorFlow, and Google Cloud PlatformSkills Python, TensorFlow, Google Cloud Storage06.2018  04.2019 Tsinghua University, Computational Neuroscience on Cocktail EffectProject description A multidisciplinary project of computer science and neuroscience that aims tosimulate a human cognitive function called cocktail effect by a deep neural network. Role Research AssistantResponsibilities  Participated in a joint research project in cognitive science and deep learning Assisted deep learning model implementation by Python and PyTorch Audio and image data preprocessingSkills Python, PyTorchEDUCATIONCV  TingYu Terry Kuo   2022 Capgemini. All rights reserved. 13"
Ting_Yu__Terry__Kuo,2,"2019  2021 MSc in IT and CognitionUniversity of Copenhagen2009  2013 BSc in PsychologyNational Taiwan UniversityCOURSES12.2021 Building Batch Data Pipelines on GCP12.2021 Modernizing Data Lakes and Data Warehouses with GCP12.2021 Google Cloud Big Data and Machine Learning Fundamentals09.2021 Microsoft Azure Fundamentals AZ90009.2021 Microsoft Azure Developer AZ20409.2021 DevOps Foundations Continuous Integration and Continuous Delivery09.2021 Terraform for Beginners09.2021 BigQuery Basics for Data Analysts09.2021 SQL for Data Science12.2020 Natural Language Processing in Tensorflow12.2020 Convolutional Neural Networks in Tensorflow04.2018 Neural Networks and Deep Learning04.2018 Improving Deep Neural Networks Hyper Parameter Tuning, Regularization and Optimization05.2018 Structuring Machine Learning ProjectsCERTIFICATIONS09.2021 Azure FundamentalsCLOUDGoogle Cloud StorageSKILLSPythonDeep LearningTensorFlowNumpySQLMatplotlibSeabornFigmaData AnalysisPyTorchBigQueryTerraformCICDCV  TingYu Terry Kuo   2022 Capgemini. All rights reserved. 23"
Ting_Yu__Terry__Kuo,3,EMPLOYMENTS09.2021   Capgemini02.2021  08.2021 Neurons Inc.06.2019  08.2021 Bruce HR Consulting parttime05.2018  06.2019 Tsinghua University03.2015  03.2018 Adecco LANGUAGESChinese Mother tongueEnglish Good CommandDanish Basic knowledgeCV  TingYu Terry Kuo   2022 Capgemini. All rights reserved. 33
Varun_Singh,1,"Varun SinghConsultantAzure Databricks, Azure DataLake, Azure Data Factory, Apache Spark, Pyspark, SparkSQLVarun  is an ambitious, solutionoriented Data Engineer, with excellent programming skill. He is wellversed in building ETL data pipelines, working with complex data transformations, and an experienced in cloud solutions such as Azure Data Factory, Azure Databricks, Azure Data lake and Azure SQL.He can easily communicate within both technical and nontechnical stakeholders and enjoy working in agile setup. He is a problem solver, possessing an extensive analytical skills, strong attention to detail and enjoy working in international teams. ENGAGEMENTS08.2021  02.2022 Truck Manufacturer, Migration of EDP to CloudProject description Worked for a globally renowned Truck Manufacturer as a Data Engineer. The daytoday tasks included gathering the requirements from the client and performing tasks to achieve the targeted goals.Role Data EngineerResponsibilities  Setting up data pipelines using ADF and Databricks Ingested data from desperate data sources such as Azure SQL DB, JSON and CSV files to create views for BI tools like Tableau Maintained datapipelines uptime of 99.9 while ingesting data across different primary data sources using Spark, Python and Databricks Optimizing the pipelines to achieve better performance, hence, cost reduction.Skills Apache Spark, Azure Data Factory, Spark SQL, Apache PySpark, Azure Data Lake07.2019  06.2021 Healthcare Provider, Migration of EDP to CloudRole Data EngineerResponsibilities  Designed and implemented data pipeline to process structured and semistructured data by integrating 100 million raw records from disparate sources using Spark and stored the processed data in the Databricks platform  Loading the transformed and cleansed data to the Azure SQL database07.2017  08.2019 Global Consumer Product CompanyCV  Varun Singh   2022 Capgemini. All rights reserved. 12"
Varun_Singh,2,"Role Junior Data EngineerResponsibilities  Ingesting the data from disparate data sources into the Azure Data Lake Creating and monitoring the date pipelines in Azure Data factory Loading the cleaned and transformed data into Azure SQL databaseSkills Apache Spark, Azure Data Factory, Apache PySpark, Spark SQL, Azure Data LakeEDUCATION2011  2015 BTech in Electronics  CommunicationSRMS College of Engineering  TechnologyCOURSES12.2021 Azure Databricks and Spark Core For Data EngineersPythonSQL08.2021 Azure Data Factory for Data Engineers01.2021 Machine Learning AZ HandsOn Python In Data ScienceCERTIFICATIONS02.2022 Azure Data Engineer AssociateEMPLOYMENTS08.2021  02.2022 Global Truck Manufacturer06.2019  07.2021 Global Healthcare Provider07.2017  05.2019 Global Consumer Product CompanyLANGUAGESEnglish FluentHindi Mother tongueCV  Varun Singh   2022 Capgemini. All rights reserved. 22"
Verma_Kanika,1,Verma KanikaCV  Verma Kanika   2022 Capgemini. All rights reserved. 11
Vicky_Singh_Kumar,1,Vicky Singh KumarCV  Vicky Singh Kumar   2022 Capgemini. All rights reserved. 11
Viktor_Ekstr_m,1,"Viktor EkstrmData EngineerViktor is a Data Engineer consultant with a strong passion for engineering, data, and business. Core values that drive him are innovation, learning and knowledgesharing, and synergistic collaboration. He has practical experience working with a team using agile methodology to solve data problems using Python and SQL. He is very clientfocused and always strives to create the utter best business value for his clients.ENGAGEMENTS06.2021  09.2021 Alfa Laval, Data VerificationProject description The Data Verification project was an internal project where Viktor analyzed the quality and integrity of data extracted from various data sources. The extracted data was explored, transformed, and ultimately presented with clear documentation in various formats requested by different stakeholders.Role Project LeadResponsibilities As the project lead, Viktor was in charge of designing the framework through which the project would be executed. He was also solely responsible for the execution of the project as well as following up on its results. Viktor worked in an agile manner by continuously having discussions with different stakeholders and subjectmatter experts regarding the insights and results learned along the way.Role Data EngineerResponsibilities As the data engineer of this project, Viktor leveraged Python to extract, transform, and load data ETL so that all insights and vital information obtained throughout the project could be easily accessed and understood by many different stakeholders.Skills ETL, MS PowerPoint, Communication, MS Excel, Python, Pandas, Numpy, MatplotlibCV  Viktor Ekstrm   2022 Capgemini. All rights reserved. 14"
Viktor_Ekstr_m,2,"07.2021  09.2021 Alfa Laval, Analysis of Field Service DataProject description The project Analysis of Field Service Data aimed to solve the problem of estimating the duration a specific type of service job would take. Viktor took on the role as a data scientist to collect field service data, communicate with subjectmatter experts, analyze the dataRole Data ScientistResponsibilities As a Data Scientist in this project, Viktor collaborated with subjectmatter expertsand joined data fetched from various departments and performed exploratory data analysis, data cleaning, data wrangling, feature engineering, natural language processing, among other things, on the data. The insights from the analysis was then presented to stakeholders.08.2021  09.2021 Alfa Laval, Automated Translation PrototypeProject description Being a company that is located in many different countries, it is necessary to have information translated into a variety of languages. Manually translating each piece of information is a tedious and timeconsuming task which is why the need for an automated solution was highly sought after.Role Software DeveloperResponsibilities As software developer in this project, Viktor wrote the code for both the frontend and backend of the prototype software.Role Project LeadResponsibilities Viktor planned and structured the solution for how to build a prototype softwarethat could automate the process of translating information to and from a desired language. He also created thorough documentation for how to use the software.Skills Selenium, RPA, Python, Pandas, Web Scraping10.2021  12.2021 Alfa Laval, Automated Data IngestionProject description The project Automated Data Ingestion involved designing an Excel workbooksuch that it could automate data ingestion. Prior to the solution for automating data ingestion, every field containing some type of data had to be filled in manually which was a very timeconsuming process. Thus, there was a need to automate data entry to as many fields as possible.Role Data EngineerResponsibilities As a Data Engineer, Viktor created the logic and translated it into formulas in Excel which, consequently, enabled the an automated data ingestion for most fields.Skills MS ExcelEDUCATION2017  2022 Master of Science in Engineering NanoscienceCV  Viktor Ekstrm   2022 Capgemini. All rights reserved. 24"
Viktor_Ekstr_m,3,Lund UniversityCOURSES08.2022 Introduction to Airflow in Python08.2022 Introduction to Bash Scripting07.2022 ObjectOriented Programming in Python07.2022 Unit Testing for Data Science in Python07.2022 Data Processing in Shell07.2022 Introduction to Shell06.2022 Writing Efficient Python Code06.2022 Streamlined Data Ingestion with pandas06.2022 Introduction to Data Engineering06.2022 Understanding Data Engineering09.2021 Intermediate Importing Data in Python10.2021 Machine Learning with TreeBased Models in Python02.2022 Linear Classifiers in Python01.2022 Machine Learning for Time Series Data in Python10.2021 Case Study School Budgeting with Machine Learning in Python10.2021 Unsupervised Learning in Python10.2021 Machine Learning with scikitlearn09.2021 Statistical Thinking in Python Part 109.2021 Statistical Thinking in Python Part 209.2021 Analyzing Police Activity with pandas09.2021 Exploratory Data Analysis in Python09.2021 Writing Functions in Python09.2021 Working with Dates and Times in Python09.2021 Cleaning Data in Python09.2021 Introduction to Importing Data in Python09.2021 Intermediate Data Visualization with Seaborn09.2021 Python Data Science Toolbox Part 209.2021 SQL for Joining Data09.2021 Data Analysis in Spreadsheets09.2021 Introduction to Data Visualization with Seaborn09.2021 Introduction to Data Visualization with Matplotlib09.2021 Web Scraping in Python09.2021 Intermediate SQL Queries09.2021 Python Data Science Toolbox Part 107.2021 Joining Data with pandas07.2021 Data Manipulation with pandas06.2021 Intermediate Python06.2021 Introduction to PythonCERTIFICATIONS09.2022 Microsoft Certified Azure Data Fundamentals DP90009.2022 Microsoft Certified Azure Fundamentals AZ900SQLCV  Viktor Ekstrm   2022 Capgemini. All rights reserved. 34
Viktor_Ekstr_m,4,PythonAzureDatabricksSnowflakePandasNumpySklearnRPAEMPLOYMENTS06.2021  01.2022 Alfa LavalLANGUAGESEnglish FluentSwedish Mother tongueCV  Viktor Ekstrm   2022 Capgemini. All rights reserved. 44
Yumeng_Ming,1,"Yumeng MingSenior consultantProject management , Business Intelligence, ETL design and development, Data Warehouse modelling and designENGAGEMENTS01.2022  12.2022 Nets, PSD2 reporting refactoring projectProject description Review the existing logic and solution for PSD2 reporting, find the pain points,design the solution to refactor the code and improve the data quality. Role Data consultantRole Project LeadSkills Apache PySpark, Spark, GIT, Scala, Apache Hive, Shell Script05.2021  12.2021 Evida , MS Dynamic365 migration project for Evida DKProject description MS Dynamic365 data migration project for Evida DKRole Senior data consultantResponsibilities Responsible for data migration ETL design and development as well as requirement clarifications.02.2021  04.2021 UK NHS, NHSX data diveProject description Covid19 Vaccination data dive projectRole Data ScientistResponsibilities Discover and delivery machine learning models to improve UK Covid19 vaccination rollout plan.01.2021  02.2021 Skatteministeriet, SKAT DWH projectProject description Implement a new DWH for SKATRole Senior data consulantResponsibilities ETL solution design and development07.2017  12.2020 Telenor AS, BSS Transformation program, Optimus Prime DWHBI extension projectsCV  Yumeng Ming   2022 Capgemini. All rights reserved. 14"
Yumeng_Ming,2,"Project description Telenor DK   Netezza DWH Model extension divided to many change requestsRole DWH architectResponsibilities Data Warehouse solution design data modelling, ETL solution design and test. Transfer business needs to  actionable solution to support business intelligence reporting and advanced analytics.Role Project ManagerResponsibilities Responsible for Endtoend delivery, including project management, requirements clarification as well as delivery process quality control. 2017  2018 Telenor AS, BSS Transformation program, Optimus PrimeTelenor DK big data project DWH transformation on hadoopProject description Telenor DK  DWH transformation on hadoopRole DWH architectResponsibilities Mainly focus on DWH model design in Hive and DWH data migration onto Hadoop.05.2016  07.2017 Telenor AS, BSS Transformation program, Optimus Prime DWH stabilizationProject description Stabilization phase since the source system and DWH golive.Role Team lead Project managerResponsibilities Responsible for operation management, task management as well as bug analysis.08.2015  12.2016 Telenor AS, BSS Transformation program, Optimus PrimeDigital Campaign management projectProject description Telenor  DK and Teleor Hungary digital campaign management projectRole Project manager and solution architectResponsibilities Work on ETL mapping design and test responsible for delivery and project management.08.2014  04.2016 Telenor AS, BSS Transformation program, Optimus PrimeProject description Telenor DK and Teleor Hungary Netezza DWH projectRole Data Engineer and DWH consultantResponsibilities Responsible for requirement analysis, model design,  ETL implementation and test.CV  Yumeng Ming   2022 Capgemini. All rights reserved. 24"
Yumeng_Ming,3,"12.2013  06.2015 Telenor AS, BSS Transformation program, Optimus Prime Machine learning Churn prediction modelsProject description Delivery the data mining models Customer Churn prediction Models for Telenor DKRole Data ScientistResponsibilities Request analysis, model design, partial development.EDUCATION2011  2014 MSc in MathematicsEconomicsUniversity of CopenhagenCERTIFICATIONS06.2020 Machine Learning by Stanford UniversityPROGRAMMING LANGUAGESMicrosoft SQL Server Transact SQL TSQLDATA WAREHOUSE  DATABASEIBM NetezzaMS SQL ServerApache HiveIBM Data StageIBM InfoSphere Data AchitectureMicrosoft SQL Server Integration Services SSISSQLSparkShell ScriptEMPLOYMENTS01.2022   Capgemini01.2021  12.2021 Netcompany 12.2013  12.2020 Asiainfo Denmerk ApSLANGUAGESEnglish FluentCV  Yumeng Ming   2022 Capgemini. All rights reserved. 34"
Yumeng_Ming,4,Danish Basic knowledgeChinese Mother tongueCV  Yumeng Ming   2022 Capgemini. All rights reserved. 44
Zhong_Guan,1,"Zhong GuanSenior ConsultantSenior Data Scientist, Machine Learning, Natural Language ProcessingProven record of applying machine learning and AI techniques in the business. Zhong Guan has extensive handson experiences within RD area from both industry and consulting perspective. HIGHLIGHTS Anomaly Detection through analyzing realtime sensor data processed by serverless Azure functions and visualized usingPlotly Dash and Power BI. IoT  Modelling and optimization of chemical processes using machine learning in order to achieve higher yield. Text mining using Natural Language Processing and Deep Learning algorithms on Chinese and English based commercial sites. Digital marketing through sentiment analysis, user activities and campaign monitoring with Google Analytics, customer segmentation and descriptive, predictive modelling.ENGAGEMENTS03.2019  09.2019 Global Manufacturing Company, IoT Anomaly DetectionProject description Building IoT sensor to cloud pipeline and anomaly detection models for streaming, processin, analysing and monitoring production area status in realtime.Role Data ScientistResponsibilities Designed and developed a nearreal time IOT anomaly detection pipeline in Azure using Steam Analytics, Blob Storage, Azure Function Python, Azure SQL, and visualized in Power BI. This pipeline queries, merges, cleans and outputs millions of data points per day, provides interactive visualizations and rootcauseanalysis for production area.Skills Machine Learning, Azure Databricks, Azure, Jupyter Notebooks, Data Analysis, Data Cleaning, Data Engineering, UI, Python, SQL, Plotly Dash, Power BI2018  2019 Global Biotech Company, Scientific Database Mgt.Project description Extract and index knowledge from scientific notebooks and documents, create network maps of experiments, discoveries and products that links with each other for inspiring potential research areas.Role Data ScientistResponsibilities Developed Minimum Viable Products MVP in close collaboration with subject CV  Zhong Guan   2022 Capgemini. All rights reserved. 13"
Zhong_Guan,2,"matter experts.Developed automated data extraction pipelines form various databases. The solution enabled scientists to compile and share knowledge across the organization in an interactive framework.Skills Sklearn, Machine Learning, Plotly Dash, Jupyter Notebooks, Data Analysis, Data Engineering, Data Exploration12.2019  05.2020 Global Chemical Company, Scalable UIProject description UI with ability to connect with data sources and machine learning pipeline that can easily being cloned and applied to new production sites. Role Data ScientistResponsibilities Given different data sources and user requirements, implemented a Scalable UI that could allow users to point to different sources, production sites and models. The solution wasimplemented in Python. The UI also monitored user activities, and run selfdiagnosis check.Skills Machine Learning, Data Analysis, Data Cleaning, User Interface Design UI, Python, Gitlab, Anaconda, Jupyter Notebooks, SQL, SQL Management Studio, Plotly Dash, FlaskEDUCATION2013  2016 MSc in IT and CognitionUniversity of CopenhagenCOURSES06.2018 Python and Django Full Stack Web Developer Bootcamp06.2019 Predictive Analytics for IoT SolutionsCERTIFICATIONS04.2018 Convolutional Neural Networks04.2018 Deep Learning04.2018 Sequence Models11.2017 Structuring Machine Learning Projects01.2017 Improving Deep Neural Networks Hyperparameter tuning, Regularization and Optimization10.2017 Neural Networks and Deep Learning10.2017 Google Analytics Individual Qualification IQSKILLSMachine LearningUser Interface Design UIAzureData EngineeringKerasCV  Zhong Guan   2022 Capgemini. All rights reserved. 23"
Zhong_Guan,3,AnacondaGitlabAzure DatabricksSQLUISklearnPlotly DashDeep LearningMultitask LearningRepresentation LearningJupyter NotebooksSQL Management StudioFlaskPower BIData MiningPythonTwitter Streaming APIData AnalysisNatural Language ProcessingSentiment AnalysisEMPLOYMENTS06.2020   Capgemini2017  2019 Accenture2015  2017 NovozymesLANGUAGESEnglish FluentChinese Mother tongueCV  Zhong Guan   2022 Capgemini. All rights reserved. 33
