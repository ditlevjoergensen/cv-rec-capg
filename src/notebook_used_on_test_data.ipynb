{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\4063275191.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_jobs['Company'] = final_jobs['Company'].replace(['Genesis Health Systems'], 'Genesis Health System')\n",
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\4063275191.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_jobs['Empl_type']=final_jobs['Empl_type'].fillna('Full-Time/Part-Time')\n",
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\4063275191.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_jobs[\"pos_com_city_empType_jobDesc_title\"] = final_jobs[\"Position\"].map(str) + \" \" + final_jobs[\"Company\"] +\" \"+ final_jobs[\"City\"]+ \" \"+final_jobs['Empl_type']+\" \"+final_jobs['Job_Description']+\" \" + final_jobs['Title']\n",
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\4063275191.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  final_jobs['pos_com_city_empType_jobDesc_title'] = final_jobs['pos_com_city_empType_jobDesc_title'].str.replace('[^a-zA-Z \\n\\.]',\" \").str.lower()\n",
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\4063275191.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_jobs['pos_com_city_empType_jobDesc_title'] = final_jobs['pos_com_city_empType_jobDesc_title'].str.replace('[^a-zA-Z \\n\\.]',\" \").str.lower()\n",
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\4063275191.py:51: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  poi = poi.drop('Updated.At', 1)\n",
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\4063275191.py:52: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  poi = poi.drop('Created.At', 1)\n",
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\4063275191.py:55: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  poi['Position.Of.Interest']=poi['Position.Of.Interest'].str.replace('[^a-zA-z \\n\\.]',\"\")\n",
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\4063275191.py:70: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  exper_applicant['Position.Name'] = exper_applicant['Position.Name'].str.replace('[^a-zA-Z \\n\\.]',\"\").str.lower()\n",
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\4063275191.py:71: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  exper_applicant['Job.Description'] = exper_applicant['Job.Description'].str.replace('[^a-zA-Z \\n\\.]',\"\").str.lower()\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'C:\\Projects\\Staffing')\n",
    "\n",
    "#-----------------\n",
    "# Job Descriptions\n",
    "#-----------------\n",
    "jf_df = pd.read_csv(\"C:\\Projects\\Staffing/data/Combined_Jobs_Final.csv\")\n",
    "\n",
    "cols = ['Job.ID', 'Title', 'Position', 'Company', 'City', 'State.Name', 'Job.Description', 'Employment.Type', 'Education.Required']\n",
    "final_jobs = jf_df[cols]\n",
    "final_jobs.columns = ['Job.ID', 'Title', 'Position', 'Company', 'City', 'State Name', 'Job_Description', 'Empl_type', 'Edu_req']\n",
    "\n",
    "#replacing nan with thier headquarters location\n",
    "final_jobs['Company'] = final_jobs['Company'].replace(['Genesis Health Systems'], 'Genesis Health System')\n",
    "final_jobs.loc[final_jobs.Company == 'CHI Payment Systems', 'City'] = 'Illinois'\n",
    "final_jobs.loc[final_jobs.Company == 'Academic Year In America', 'City'] = 'Stamford'\n",
    "final_jobs.loc[final_jobs.Company == 'CBS Healthcare Services and Staffing ', 'City'] = 'Urbandale'\n",
    "final_jobs.loc[final_jobs.Company == 'Driveline Retail', 'City'] = 'Coppell'\n",
    "final_jobs.loc[final_jobs.Company == 'Educational Testing Services', 'City'] = 'New Jersey'\n",
    "final_jobs.loc[final_jobs.Company == 'Genesis Health System', 'City'] = 'Davennport'\n",
    "final_jobs.loc[final_jobs.Company == 'Home Instead Senior Care', 'City'] = 'Nebraska'\n",
    "final_jobs.loc[final_jobs.Company == 'St. Francis Hospital', 'City'] = 'New York'\n",
    "final_jobs.loc[final_jobs.Company == 'Volvo Group', 'City'] = 'Washington'\n",
    "final_jobs.loc[final_jobs.Company == 'CBS Healthcare Services and Staffing', 'City'] = 'Urbandale'\n",
    "\n",
    "# add data into last NAN's\n",
    "final_jobs['Empl_type']=final_jobs['Empl_type'].fillna('Full-Time/Part-Time')\n",
    "\n",
    "# Creating the corpus of the jobs\n",
    "final_jobs[\"pos_com_city_empType_jobDesc_title\"] = final_jobs[\"Position\"].map(str) + \" \" + final_jobs[\"Company\"] +\" \"+ final_jobs[\"City\"]+ \" \"+final_jobs['Empl_type']+\" \"+final_jobs['Job_Description']+\" \" + final_jobs['Title']\n",
    "\n",
    "#removing unnecessary characters and convert to lowercase\n",
    "final_jobs['pos_com_city_empType_jobDesc_title'] = final_jobs['pos_com_city_empType_jobDesc_title'].str.replace('[^a-zA-Z \\n\\.]',\" \").str.lower() \n",
    "\n",
    "#print(final_jobs['pos_com_city_empType_jobDesc_title'].head(1000))\n",
    "final_jobs = final_jobs[['Job.ID', 'pos_com_city_empType_jobDesc_title']]\n",
    "\n",
    "# Creating the corpus of the applications\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\2164845249.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  poi = poi.drop('Updated.At', 1)\n",
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\2164845249.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  poi = poi.drop('Created.At', 1)\n",
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\2164845249.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  poi['Position.Of.Interest']=poi['Position.Of.Interest'].str.replace('[^a-zA-z \\n\\.]',\"\")\n",
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\2164845249.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  exper_applicant['Position.Name'] = exper_applicant['Position.Name'].str.replace('[^a-zA-Z \\n\\.]',\"\").str.lower()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applicant.ID       0\n",
      "Position.Name      0\n",
      "Job.Description    0\n",
      "dtype: int64\n",
      "(5668, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\2164845249.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  exper_applicant['Job.Description'] = exper_applicant['Job.Description'].str.replace('[^a-zA-Z \\n\\.]',\"\").str.lower()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3259, 2)\n",
      "   Applicant.ID                                       poi_pos_desc\n",
      "0            96  server cashietwaiter cashier receptionist plac...\n",
      "1           153  barista host server sales rep customer service...\n",
      "2           256  host production area sales rep customer servic...\n",
      "3           438       customer service rep barista host server    \n",
      "4           568  receptionist customer service rep book keeper ...\n"
     ]
    }
   ],
   "source": [
    "#-----------------\n",
    "# Position of interest\n",
    "#-----------------\n",
    "poi = pd.read_csv(\"C:\\Projects\\Staffing/data/Positions_Of_Interest.csv\", sep=',')\n",
    "poi = poi.sort_values(by='Applicant.ID')\n",
    "# drop unneeded columns\n",
    "poi = poi.drop('Updated.At', 1)\n",
    "poi = poi.drop('Created.At', 1)\n",
    "\n",
    "#cleaning the text\n",
    "poi['Position.Of.Interest']=poi['Position.Of.Interest'].str.replace('[^a-zA-z \\n\\.]',\"\")\n",
    "poi['Position.Of.Interest']=poi['Position.Of.Interest'].str.lower()\n",
    "poi = poi.fillna(\" \")\n",
    "#print(poi.head(20))\n",
    "\n",
    "poi = poi.groupby('Applicant.ID', sort=True)['Position.Of.Interest'].apply(' '.join).reset_index()\n",
    "#print(poi.head(20))\n",
    "\n",
    "# Experiences\n",
    "exper_applicant = pd.read_csv(\"C:\\Projects\\Staffing/data/Experience.csv\")\n",
    "#print(exper_applicant.head())\n",
    "#taking only Position\n",
    "exper_applicant = exper_applicant[['Applicant.ID','Position.Name', 'Job.Description']]\n",
    "\n",
    "exper_applicant.dropna(axis=0,inplace=True)\n",
    "print(exper_applicant.isnull().sum())\n",
    "print(exper_applicant.shape)\n",
    "#cleaning the text\n",
    "exper_applicant['Position.Name'] = exper_applicant['Position.Name'].str.replace('[^a-zA-Z \\n\\.]',\"\").str.lower()\n",
    "exper_applicant['Job.Description'] = exper_applicant['Job.Description'].str.replace('[^a-zA-Z \\n\\.]',\"\").str.lower()\n",
    "\n",
    "#print(exper_applicant.head())\n",
    "\n",
    "exper_applicant = exper_applicant.sort_values(by='Applicant.ID')\n",
    "exper_applicant = exper_applicant.fillna(\" \")\n",
    "\n",
    "#print(exper_applicant.head())\n",
    "\n",
    "#adding same rows to a single row\n",
    "exper_applicant_position = exper_applicant.groupby('Applicant.ID', sort=False)['Position.Name'].apply(' '.join).reset_index()\n",
    "exper_applicant_desc = exper_applicant.groupby('Applicant.ID', sort=False)['Job.Description'].apply(' '.join).reset_index()\n",
    "#print(exper_applicant_position.head(20))\n",
    "#print(exper_applicant_desc.head(20))\n",
    "data_frames = [poi, exper_applicant_position, exper_applicant_desc]\n",
    "final_experience = reduce(lambda  left, right: pd.merge(left,right,on=['Applicant.ID'],\n",
    "                                            how='outer'), data_frames).fillna(\" \")\n",
    "\n",
    "final_experience[\"poi_pos_desc\"] = final_experience[\"Position.Of.Interest\"].map(str) + \" \" + final_experience[\"Position.Name\"] +\" \"+ final_experience[\"Job.Description\"]\n",
    "final_experience = final_experience[['Applicant.ID', 'poi_pos_desc']]\n",
    "print(final_experience.shape)\n",
    "print(final_experience.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\772136335.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_jobs[\"pos_com_city_empType_jobDesc_title\"] = final_jobs[\"pos_com_city_empType_jobDesc_title\"].astype(str)\n",
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\772136335.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_jobs[\"text\"] = only_text_jobs\n"
     ]
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "final_experience[\"poi_pos_desc\"] = final_experience[\"poi_pos_desc\"].astype(str)\n",
    "final_jobs[\"pos_com_city_empType_jobDesc_title\"] = final_jobs[\"pos_com_city_empType_jobDesc_title\"].astype(str)\n",
    "\n",
    "# for experiences \n",
    "only_text_experience = final_experience[\"poi_pos_desc\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "only_text_experience = only_text_experience.apply(lambda x : filter(None,x.split(\" \")))\n",
    "#stemmer =  PorterStemmer()\n",
    "#only_text_experience = only_text_experience.apply(lambda x : [stemmer.stem(y) for y in x])\n",
    "only_text_experience = only_text_experience.apply(lambda x : \" \".join(x))\n",
    "final_experience[\"text\"] = only_text_experience\n",
    "\n",
    "# for jobs \n",
    "only_text_jobs = final_jobs[\"pos_com_city_empType_jobDesc_title\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "only_text_jobs = only_text_jobs.apply(lambda x : filter(None,x.split(\" \")))\n",
    "#stemmer =  PorterStemmer()\n",
    "#only_text_jobs = only_text_jobs.apply(lambda x : [stemmer.stem(y) for y in x])\n",
    "only_text_jobs = only_text_jobs.apply(lambda x : \" \".join(x))\n",
    "\n",
    "\n",
    "final_jobs[\"text\"] = only_text_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Job.ID                 pos_com_city_empType_jobDesc_title  \\\n",
      "0     111  server tacolicious palo alto part time tacolic...   \n",
      "1     113  kitchen staff chef claude lane san francisco p...   \n",
      "2     117  bartender machka restaurants corp. san francis...   \n",
      "3     121  server teriyaki house brisbane part time    se...   \n",
      "4     127  kitchen staff chef rosa mexicano   sunset los ...   \n",
      "\n",
      "                                                text  \n",
      "0  server tacolicious palo alto part time tacolic...  \n",
      "1  kitchen staff chef claude lane san francisco p...  \n",
      "2  bartender machka restaurants corp. san francis...  \n",
      "3  server teriyaki house brisbane part time serve...  \n",
      "4  kitchen staff chef rosa mexicano sunset los an...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\djorgens\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "print(final_jobs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(final_jobs[\"text\"].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "\n",
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "\n",
    "\n",
    "#print(tagged_data)\n",
    "\n",
    "model = Doc2Vec(vector_size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=100,\n",
    "                dm =1)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(tagged_data) # tagged_data\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data, # tagged_data\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.epochs)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\djorgens\\AppData\\Local\\Temp\\ipykernel_17496\\3847254524.py:27: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  best_jobs = model.docvecs.similar_by_vector(test)\n"
     ]
    }
   ],
   "source": [
    "# Test inferencing:\n",
    "\n",
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "print(\"Model loaded!\")\n",
    "\n",
    "#inferred_vectors_test = [model.infer_vector(doc) for doc in word_tokenize(final_experience[\"text\"])]\n",
    "inferred_vectors_test = []\n",
    "for doc in final_experience[\"text\"].tolist():\n",
    "    inferred_vectors_test.append(model.infer_vector(word_tokenize(doc)))\n",
    "\n",
    "# now we have a vector for each test-document (All the Applicant experiences!)\n",
    "#print(inferred_vectors_test)\n",
    "import csv\n",
    "\n",
    "\n",
    "with open(\"doc2vec_jobmatchings.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    #print(tagged_data[10])\n",
    "    #print(final_jobs[\"pos_com_city_empType_jobDesc_title\"][10])\n",
    "    #print(final_jobs[\"Job.ID\"][10])\n",
    "    csv_input = ['match_pct','Job.ID','pos_com_city_empType_jobDesc_title' , 'poi_pos_desc']\n",
    "    writer.writerows([csv_input])\n",
    "\n",
    "    applicant = 0\n",
    "    for test in inferred_vectors_test:\n",
    "        best_jobs = model.docvecs.similar_by_vector(test)\n",
    "        best_match = best_jobs[0]\n",
    "        #print(best_match)\n",
    "        #print(final_jobs[\"pos_com_city_empType_jobDesc_title\"][int(best_match[0])])\n",
    "        csv_input = [str(best_match[1]), str(best_match[0]), f\"{final_jobs['text'][int(best_match[0])]}\", f\"{final_experience['text'][applicant]}\"]\n",
    "        \n",
    "        writer.writerows([csv_input])\n",
    "        applicant +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 41881)\t0.06109257352435258\n",
      "  (0, 29266)\t0.05223200207781344\n",
      "  (0, 45241)\t0.051986473404771964\n",
      "  (0, 41468)\t0.11452622039386127\n",
      "  (0, 12164)\t0.10452184584098292\n",
      "  (0, 7903)\t0.06968300001929177\n",
      "  (0, 28984)\t0.04061333598167795\n",
      "  (0, 6632)\t0.10569960514866913\n",
      "  (0, 492)\t0.08409004000047433\n",
      "  (0, 26302)\t0.07095302471785131\n",
      "  (0, 34750)\t0.050396037022325486\n",
      "  (0, 10449)\t0.042067526139897074\n",
      "  (0, 13247)\t0.1420593777145455\n",
      "  (0, 16928)\t0.08038712091445505\n",
      "  (0, 39813)\t0.06505131370808943\n",
      "  (0, 37724)\t0.0990607682290021\n",
      "  (0, 48678)\t0.03315715511256172\n",
      "  (0, 43416)\t0.22328322655140706\n",
      "  (0, 25615)\t0.17378690885952303\n",
      "  (0, 19748)\t0.06515641021738212\n",
      "  (0, 36251)\t0.08279681880931611\n",
      "  (0, 30669)\t0.06582819439127076\n",
      "  (0, 42317)\t0.062407659487140166\n",
      "  (0, 16582)\t0.07476217646452103\n",
      "  (0, 44643)\t0.02874471822006935\n",
      "  :\t:\n",
      "  (84088, 43714)\t0.04018960689076876\n",
      "  (84088, 6181)\t0.05617621468473928\n",
      "  (84088, 43449)\t0.06084095104263497\n",
      "  (84088, 12501)\t0.11863771843955294\n",
      "  (84088, 16517)\t0.07109535250476214\n",
      "  (84088, 17204)\t0.11276044739504275\n",
      "  (84088, 38903)\t0.08811159737630704\n",
      "  (84088, 7428)\t0.1350964012789386\n",
      "  (84088, 7903)\t0.06706144128098081\n",
      "  (84088, 37724)\t0.28600194695975684\n",
      "  (84088, 48678)\t0.06381948567110586\n",
      "  (84088, 44643)\t0.027663307155545047\n",
      "  (84088, 31846)\t0.02990946944005173\n",
      "  (84089, 23627)\t0.7455561422531196\n",
      "  (84089, 23376)\t0.19900857439468517\n",
      "  (84089, 45296)\t0.13639009375076463\n",
      "  (84089, 25542)\t0.07345918670757227\n",
      "  (84089, 30921)\t0.09305321993034972\n",
      "  (84089, 26108)\t0.07046531235130232\n",
      "  (84089, 43449)\t0.09759097600335392\n",
      "  (84089, 38903)\t0.1413340297580587\n",
      "  (84089, 6632)\t0.4895018416846431\n",
      "  (84089, 37724)\t0.3058379667460386\n",
      "  (84089, 44643)\t0.044372895205046496\n",
      "  (84089, 31846)\t0.047975816688856296\n"
     ]
    }
   ],
   "source": [
    "#initializing tfidf vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_jobid = tfidf_vectorizer.fit_transform((final_jobs['text'])) #fitting and transforming the vector\n",
    "print(tfidf_jobid)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "user_tfidf = tfidf_vectorizer.transform(final_experience['text'])\n",
    "output = map(lambda x: cosine_similarity(user_tfidf, x), tfidf_jobid)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "output2 = list(output)\n",
    "len(output2)\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "\n",
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random user\n",
    "u = 300\n",
    "\n",
    "#getting the job id's of the recommendations\n",
    "top = sorted(range(len(output2)), key=lambda i: output2[i], reverse=True)[:50]\n",
    "recommendation = pd.DataFrame(columns = ['ApplicantID', 'JobID', 'pos_com_city_empType_jobDesc_title'])\n",
    "count = 0\n",
    "for i in top:\n",
    "    recommendation.set_value(count, 'ApplicantID', u)\n",
    "    recommendation.set_value(count,'JobID' ,final_jobs['Job.ID'][i])\n",
    "    recommendation.set_value(count,'JobID' ,final_jobs['pos_com_city_empType_jobDesc_title'][i])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ApplicantID, JobID, pos_com_city_empType_jobDesc_title]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(recommendation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbc881801efdacea0e7b752b334635ef300e91ebf40f63c0f3e5b421e2de0c51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
